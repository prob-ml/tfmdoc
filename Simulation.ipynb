{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import scipy.stats\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "from torch import distributions\n",
    "import pymc3 as pm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ Z_{it}|Z_{i,t-1}$ ~ $\\ N$($\\Omega Z_{i,t-1}$, $\\ I$\\)\\\n",
    "$\\ X_{it}|Z_{i,t}$ ~ $Categorical$($\\Psi Z_{it}$)\n",
    "\n",
    "Theoretical derivation gives:\\\n",
    "$\\ Z_{it}|X_{i,t}$ ~ $\\ N$($\\Omega Z_{i,t-1} + \\Psi^T e_{X_{it}}^T$, $\\ I$\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'zit' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-e7c797b0461a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mZ_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mZ_posterior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_posterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-172-e7c797b0461a>\u001b[0m in \u001b[0;36mposterior_i\u001b[0;34m(x, omega, Psi)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mzi0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'zit' referenced before assignment"
     ]
    }
   ],
   "source": [
    "N = 500 # num patients\n",
    "T = 10 # num of hospital visits for each patients\n",
    "random.seed(53)\n",
    "zdim = 1\n",
    "xdim = 100\n",
    "\n",
    "Z = torch.zeros((N, T, zdim)) # latent\n",
    "logPZ = torch.zeros((N, T)) \n",
    "X = torch.zeros((N, T)) # observed\n",
    "PX = torch.zeros((N, T, xdim)) \n",
    "logPX = torch.zeros((N, T, xdim))\n",
    "d = torch.ones(zdim,requires_grad = True) \n",
    "omega = torch.diag(d) \n",
    "Psi = torch.randn((xdim,zdim),requires_grad = True)\n",
    "\n",
    "\n",
    "for i in range(N): \n",
    "    '''\n",
    "    I tried to find a way to get rid of outer loop but it turns out that although \n",
    "    I could calculate mean by mean = torch.matmul(omega,Z[:,t-1]) which allows me\n",
    "    to remove this loop, I still need to loop again in torch.distributions, it seems\n",
    "    this function doesn't support the input argument 'mean' to be a matrix aggregating\n",
    "    all the means?\n",
    "    '''\n",
    "    mean = torch.zeros((zdim))\n",
    "    cov = torch.eye(zdim)\n",
    "    Zi0 = torch.distributions.multivariate_normal.MultivariateNormal(mean,cov)\n",
    "    Z[i,0] = Zit.sample()\n",
    "    for t in range(1,T):\n",
    "        # Zit|Zi,t-1\n",
    "        mean = torch.matmul(omega,Z[i,t-1])\n",
    "        cov = torch.eye(zdim)*(1e-3)\n",
    "        Zit = torch.distributions.multivariate_normal.MultivariateNormal(mean,cov)\n",
    "        Z[i,t] = Zit.sample()\n",
    "        logPZ[i,t] = Zit.log_prob(Z[i,t])\n",
    "\n",
    "        #Xit|Zit\n",
    "        Psi_z = torch.matmul(Psi,Z[i,t])\n",
    "        logPX[i,t] = Psi_z - torch.logsumexp(Psi_z,0,keepdim=True)\n",
    "        PX[i,t] = torch.exp(logPX[i,t])\n",
    "        Xit = torch.distributions.multivariate_normal.MultivariateNormal(PX[i,t])\n",
    "        X[i,t] = Xit.sample()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "def posterior_i(x,omega,Psi):\n",
    "    n,t = x.size()\n",
    "    z = torch.zeros((n,t,zdim))\n",
    "    e = torch.zeros((n,t,xdim))\n",
    "    logpz = torch.zeros((n, t)) \n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        mean = torch.zeros((zdim))\n",
    "        cov = torch.eye(zdim)\n",
    "        zi0 = torch.distributions.multivariate_normal.MultivariateNormal(mean,cov)\n",
    "        z[i,0] = zit.sample()\n",
    "        for j in range(1,t):\n",
    "            e[i,j,int(x[i,j])] = 1 \n",
    "            mean = torch.matmul(omega,z[i,j-1]) + torch.matmul(Psi.t(),e[i,j].t())\n",
    "            cov = torch.eye(zdim)*(1e-3)\n",
    "            zit = torch.distributions.multivariate_normal.MultivariateNormal(mean,cov)\n",
    "            z[i,j] = zit.sample()\n",
    "            logpz[i,j] = zit.log_prob(z[i,j])\n",
    "    return z, logpz\n",
    "        \n",
    "\n",
    "    \n",
    "Z_posterior = torch.zeros((N, T, zdim))\n",
    "Z_posterior,log_posterior = posterior_i(X,omega,Psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((Z-Z_posterior)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Z[0,T-1,0].detach().numpy(),Z[:,T-1,0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000],\n",
       "         [-1.0158],\n",
       "         [-1.1527],\n",
       "         ...,\n",
       "         [ 0.0353],\n",
       "         [-0.2036],\n",
       "         [ 2.1340]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.5678],\n",
       "         [ 0.2047],\n",
       "         ...,\n",
       "         [-2.2459],\n",
       "         [-1.7722],\n",
       "         [-3.2543]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.2982],\n",
       "         [ 0.1043],\n",
       "         ...,\n",
       "         [-1.0452],\n",
       "         [ 0.0255],\n",
       "         [-0.5496]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.3345],\n",
       "         [ 1.1453],\n",
       "         ...,\n",
       "         [-2.4516],\n",
       "         [-1.4917],\n",
       "         [-1.2832]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 1.5428],\n",
       "         [ 1.0803],\n",
       "         ...,\n",
       "         [ 2.5984],\n",
       "         [ 5.5063],\n",
       "         [ 8.3393]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.2435],\n",
       "         [ 2.2407],\n",
       "         ...,\n",
       "         [ 2.6283],\n",
       "         [ 3.2842],\n",
       "         [ 3.7031]]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000],\n",
       "         [ 0.4734]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [ 0.4552]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [-0.2342]],\n",
       "\n",
       "        [[ 0.0000],\n",
       "         [-0.2104]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
