{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.distributions.binomial import Binomial\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, BertForMaskedLM, BertModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "from causal_bert import load_data, load_model\n",
    "from causal_bert import true_casual_effect, est_casual_effect, show_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_BERT = '/nfs/turbo/lsa-regier/bert-results/results/behrt/MLM/merged/unidiag/checkpoint-6018425/'\n",
    "\n",
    "a = BertModel.from_pretrained(TRAINED_BERT)\n",
    "b = BertForMaskedLM.from_pretrained(TRAINED_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_embed = a.get_input_embeddings()\n",
    "b_embed = b.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(b_embed.weight == a_embed.weight).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = 'ate'\n",
    "estimation = 'q'\n",
    "\n",
    "effect = effect.lower()\n",
    "estimation = estimation.lower()\n",
    "assert effect in ['att', 'ate'], f'Wrong effect: {effect}...'\n",
    "assert estimation in ['q', 'plugin'], f'Wrong estimation: {estimation}...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 256\n",
    "epoch = 800\n",
    "hidden_size = 64\n",
    "lr = 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training set in 70.73 sec\n",
      "Load validation set in 68.07 sec\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.25\n",
    "beta = 5.\n",
    "c = 0.2\n",
    "i = 0.\n",
    "\n",
    "train_loader, test_loader = load_data(alpha, beta, c, i, bsz, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: [effect: ate], [estimation: q], [value: 0.06024]\n",
      "Unadjusted: [value: 0.1403]\n"
     ]
    }
   ],
   "source": [
    "real_att_q = true_casual_effect(test_loader)\n",
    "\n",
    "print(f'Real: [effect: ate], [estimation: q], [value: {real_att_q:.5f}]')\n",
    "print(f'Unadjusted: [value: {(test_loader.dataset.response[test_loader.dataset.treatment == 1].mean() - test_loader.dataset.response[test_loader.dataset.treatment == 0].mean()).item():.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model='bow', hidden_size=hidden_size, device=device)\n",
    "\n",
    "pos_portion = train_loader.dataset.treatment.mean()\n",
    "pos_weight = (1 - pos_portion) / pos_portion\n",
    "\n",
    "epoch_iter = len(train_loader)\n",
    "total_steps = epoch * epoch_iter\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)\n",
    "\n",
    "q_loss = nn.BCELoss()\n",
    "prop_score_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 800, time cost: 44.17 sec, \n",
      "          Loss: [Train: p = 1.00257, q = 1.12357], \n",
      "          Loss: [Test: p = 1.02248, q = 1.35162],\n",
      "          Effect: [ate-q], [train: 0.06151], [test: 0.06278]\n",
      "********************************************************************************\n",
      "epoch: 2 / 800, time cost: 43.48 sec, \n",
      "          Loss: [Train: p = 1.00255, q = 1.12346], \n",
      "          Loss: [Test: p = 1.02250, q = 1.35017],\n",
      "          Effect: [ate-q], [train: 0.08083], [test: 0.08209]\n",
      "********************************************************************************\n",
      "epoch: 3 / 800, time cost: 41.60 sec, \n",
      "          Loss: [Train: p = 1.00252, q = 1.12362], \n",
      "          Loss: [Test: p = 1.02251, q = 1.35224],\n",
      "          Effect: [ate-q], [train: 0.05869], [test: 0.05998]\n",
      "********************************************************************************\n",
      "epoch: 4 / 800, time cost: 40.77 sec, \n",
      "          Loss: [Train: p = 1.00246, q = 1.12286], \n",
      "          Loss: [Test: p = 1.02251, q = 1.35211],\n",
      "          Effect: [ate-q], [train: 0.06097], [test: 0.06222]\n",
      "********************************************************************************\n",
      "epoch: 5 / 800, time cost: 43.42 sec, \n",
      "          Loss: [Train: p = 1.00247, q = 1.12310], \n",
      "          Loss: [Test: p = 1.02249, q = 1.35233],\n",
      "          Effect: [ate-q], [train: 0.06083], [test: 0.06213]\n",
      "********************************************************************************\n",
      "epoch: 6 / 800, time cost: 43.62 sec, \n",
      "          Loss: [Train: p = 1.00241, q = 1.12206], \n",
      "          Loss: [Test: p = 1.02245, q = 1.35231],\n",
      "          Effect: [ate-q], [train: 0.05856], [test: 0.05978]\n",
      "********************************************************************************\n",
      "epoch: 7 / 800, time cost: 40.14 sec, \n",
      "          Loss: [Train: p = 1.00231, q = 1.12282], \n",
      "          Loss: [Test: p = 1.02244, q = 1.35030],\n",
      "          Effect: [ate-q], [train: 0.07171], [test: 0.07294]\n",
      "********************************************************************************\n",
      "epoch: 8 / 800, time cost: 38.47 sec, \n",
      "          Loss: [Train: p = 1.00232, q = 1.12245], \n",
      "          Loss: [Test: p = 1.02246, q = 1.35274],\n",
      "          Effect: [ate-q], [train: 0.05715], [test: 0.05840]\n",
      "********************************************************************************\n",
      "epoch: 9 / 800, time cost: 44.40 sec, \n",
      "          Loss: [Train: p = 1.00248, q = 1.12196], \n",
      "          Loss: [Test: p = 1.02244, q = 1.35365],\n",
      "          Effect: [ate-q], [train: 0.05589], [test: 0.05717]\n",
      "********************************************************************************\n",
      "epoch: 10 / 800, time cost: 43.40 sec, \n",
      "          Loss: [Train: p = 1.00223, q = 1.12231], \n",
      "          Loss: [Test: p = 1.02247, q = 1.35143],\n",
      "          Effect: [ate-q], [train: 0.06822], [test: 0.06944]\n",
      "********************************************************************************\n",
      "epoch: 11 / 800, time cost: 40.63 sec, \n",
      "          Loss: [Train: p = 1.00230, q = 1.12191], \n",
      "          Loss: [Test: p = 1.02245, q = 1.35374],\n",
      "          Effect: [ate-q], [train: 0.05499], [test: 0.05625]\n",
      "********************************************************************************\n",
      "epoch: 12 / 800, time cost: 41.02 sec, \n",
      "          Loss: [Train: p = 1.00221, q = 1.12185], \n",
      "          Loss: [Test: p = 1.02241, q = 1.35258],\n",
      "          Effect: [ate-q], [train: 0.06019], [test: 0.06144]\n",
      "********************************************************************************\n",
      "epoch: 13 / 800, time cost: 40.19 sec, \n",
      "          Loss: [Train: p = 1.00226, q = 1.12173], \n",
      "          Loss: [Test: p = 1.02240, q = 1.35400],\n",
      "          Effect: [ate-q], [train: 0.05387], [test: 0.05515]\n",
      "********************************************************************************\n",
      "epoch: 14 / 800, time cost: 41.07 sec, \n",
      "          Loss: [Train: p = 1.00222, q = 1.12165], \n",
      "          Loss: [Test: p = 1.02241, q = 1.35195],\n",
      "          Effect: [ate-q], [train: 0.06360], [test: 0.06485]\n",
      "********************************************************************************\n",
      "epoch: 15 / 800, time cost: 43.40 sec, \n",
      "          Loss: [Train: p = 1.00215, q = 1.12183], \n",
      "          Loss: [Test: p = 1.02238, q = 1.35223],\n",
      "          Effect: [ate-q], [train: 0.06381], [test: 0.06502]\n",
      "********************************************************************************\n",
      "epoch: 16 / 800, time cost: 44.48 sec, \n",
      "          Loss: [Train: p = 1.00226, q = 1.12132], \n",
      "          Loss: [Test: p = 1.02241, q = 1.35269],\n",
      "          Effect: [ate-q], [train: 0.06124], [test: 0.06254]\n",
      "********************************************************************************\n",
      "epoch: 17 / 800, time cost: 42.10 sec, \n",
      "          Loss: [Train: p = 1.00212, q = 1.12158], \n",
      "          Loss: [Test: p = 1.02238, q = 1.35240],\n",
      "          Effect: [ate-q], [train: 0.06390], [test: 0.06520]\n",
      "********************************************************************************\n",
      "epoch: 18 / 800, time cost: 40.42 sec, \n",
      "          Loss: [Train: p = 1.00224, q = 1.12134], \n",
      "          Loss: [Test: p = 1.02235, q = 1.35165],\n",
      "          Effect: [ate-q], [train: 0.07120], [test: 0.07243]\n",
      "********************************************************************************\n",
      "epoch: 19 / 800, time cost: 41.39 sec, \n",
      "          Loss: [Train: p = 1.00213, q = 1.12104], \n",
      "          Loss: [Test: p = 1.02238, q = 1.35144],\n",
      "          Effect: [ate-q], [train: 0.05786], [test: 0.05907]\n",
      "********************************************************************************\n",
      "epoch: 20 / 800, time cost: 44.75 sec, \n",
      "          Loss: [Train: p = 1.00208, q = 1.12102], \n",
      "          Loss: [Test: p = 1.02235, q = 1.34970],\n",
      "          Effect: [ate-q], [train: 0.06859], [test: 0.06980]\n",
      "********************************************************************************\n",
      "epoch: 21 / 800, time cost: 43.36 sec, \n",
      "          Loss: [Train: p = 1.00211, q = 1.12093], \n",
      "          Loss: [Test: p = 1.02232, q = 1.34965],\n",
      "          Effect: [ate-q], [train: 0.07399], [test: 0.07525]\n",
      "********************************************************************************\n",
      "epoch: 22 / 800, time cost: 41.02 sec, \n",
      "          Loss: [Train: p = 1.00197, q = 1.12072], \n",
      "          Loss: [Test: p = 1.02231, q = 1.35427],\n",
      "          Effect: [ate-q], [train: 0.04777], [test: 0.04899]\n",
      "********************************************************************************\n",
      "epoch: 23 / 800, time cost: 42.51 sec, \n",
      "          Loss: [Train: p = 1.00197, q = 1.12053], \n",
      "          Loss: [Test: p = 1.02234, q = 1.35067],\n",
      "          Effect: [ate-q], [train: 0.07091], [test: 0.07217]\n",
      "********************************************************************************\n",
      "epoch: 24 / 800, time cost: 44.20 sec, \n",
      "          Loss: [Train: p = 1.00198, q = 1.12042], \n",
      "          Loss: [Test: p = 1.02232, q = 1.35391],\n",
      "          Effect: [ate-q], [train: 0.04833], [test: 0.04960]\n",
      "********************************************************************************\n",
      "epoch: 25 / 800, time cost: 43.11 sec, \n",
      "          Loss: [Train: p = 1.00190, q = 1.11994], \n",
      "          Loss: [Test: p = 1.02230, q = 1.35056],\n",
      "          Effect: [ate-q], [train: 0.07589], [test: 0.07714]\n",
      "********************************************************************************\n",
      "epoch: 26 / 800, time cost: 42.57 sec, \n",
      "          Loss: [Train: p = 1.00186, q = 1.12041], \n",
      "          Loss: [Test: p = 1.02227, q = 1.35202],\n",
      "          Effect: [ate-q], [train: 0.06120], [test: 0.06239]\n",
      "********************************************************************************\n",
      "epoch: 27 / 800, time cost: 40.09 sec, \n",
      "          Loss: [Train: p = 1.00186, q = 1.12008], \n",
      "          Loss: [Test: p = 1.02230, q = 1.35257],\n",
      "          Effect: [ate-q], [train: 0.05797], [test: 0.05922]\n",
      "********************************************************************************\n",
      "epoch: 28 / 800, time cost: 42.06 sec, \n",
      "          Loss: [Train: p = 1.00195, q = 1.11978], \n",
      "          Loss: [Test: p = 1.02225, q = 1.35519],\n",
      "          Effect: [ate-q], [train: 0.04462], [test: 0.04584]\n",
      "********************************************************************************\n",
      "epoch: 29 / 800, time cost: 42.31 sec, \n",
      "          Loss: [Train: p = 1.00188, q = 1.11944], \n",
      "          Loss: [Test: p = 1.02227, q = 1.35185],\n",
      "          Effect: [ate-q], [train: 0.06432], [test: 0.06556]\n",
      "********************************************************************************\n",
      "epoch: 30 / 800, time cost: 47.74 sec, \n",
      "          Loss: [Train: p = 1.00187, q = 1.11925], \n",
      "          Loss: [Test: p = 1.02223, q = 1.35150],\n",
      "          Effect: [ate-q], [train: 0.06806], [test: 0.06926]\n",
      "********************************************************************************\n",
      "epoch: 31 / 800, time cost: 41.71 sec, \n",
      "          Loss: [Train: p = 1.00175, q = 1.11953], \n",
      "          Loss: [Test: p = 1.02219, q = 1.35013],\n",
      "          Effect: [ate-q], [train: 0.07785], [test: 0.07907]\n",
      "********************************************************************************\n",
      "epoch: 32 / 800, time cost: 40.73 sec, \n",
      "          Loss: [Train: p = 1.00176, q = 1.11923], \n",
      "          Loss: [Test: p = 1.02224, q = 1.35132],\n",
      "          Effect: [ate-q], [train: 0.06495], [test: 0.06616]\n",
      "********************************************************************************\n",
      "epoch: 33 / 800, time cost: 46.38 sec, \n",
      "          Loss: [Train: p = 1.00170, q = 1.11878], \n",
      "          Loss: [Test: p = 1.02224, q = 1.35214],\n",
      "          Effect: [ate-q], [train: 0.06439], [test: 0.06558]\n",
      "********************************************************************************\n",
      "epoch: 34 / 800, time cost: 44.65 sec, \n",
      "          Loss: [Train: p = 1.00172, q = 1.11881], \n",
      "          Loss: [Test: p = 1.02224, q = 1.35077],\n",
      "          Effect: [ate-q], [train: 0.07958], [test: 0.08081]\n",
      "********************************************************************************\n",
      "epoch: 35 / 800, time cost: 43.02 sec, \n",
      "          Loss: [Train: p = 1.00166, q = 1.11902], \n",
      "          Loss: [Test: p = 1.02219, q = 1.35157],\n",
      "          Effect: [ate-q], [train: 0.07259], [test: 0.07377]\n",
      "********************************************************************************\n",
      "epoch: 36 / 800, time cost: 45.18 sec, \n",
      "          Loss: [Train: p = 1.00172, q = 1.11863], \n",
      "          Loss: [Test: p = 1.02222, q = 1.35525],\n",
      "          Effect: [ate-q], [train: 0.05146], [test: 0.05269]\n",
      "********************************************************************************\n",
      "epoch: 37 / 800, time cost: 40.54 sec, \n",
      "          Loss: [Train: p = 1.00163, q = 1.11886], \n",
      "          Loss: [Test: p = 1.02224, q = 1.35139],\n",
      "          Effect: [ate-q], [train: 0.07904], [test: 0.08028]\n",
      "********************************************************************************\n",
      "epoch: 38 / 800, time cost: 41.64 sec, \n",
      "          Loss: [Train: p = 1.00164, q = 1.11863], \n",
      "          Loss: [Test: p = 1.02222, q = 1.35225],\n",
      "          Effect: [ate-q], [train: 0.06771], [test: 0.06893]\n",
      "********************************************************************************\n",
      "epoch: 39 / 800, time cost: 46.12 sec, \n",
      "          Loss: [Train: p = 1.00155, q = 1.11860], \n",
      "          Loss: [Test: p = 1.02222, q = 1.35111],\n",
      "          Effect: [ate-q], [train: 0.07877], [test: 0.08000]\n",
      "********************************************************************************\n",
      "epoch: 40 / 800, time cost: 40.89 sec, \n",
      "          Loss: [Train: p = 1.00166, q = 1.11822], \n",
      "          Loss: [Test: p = 1.02218, q = 1.35181],\n",
      "          Effect: [ate-q], [train: 0.06738], [test: 0.06862]\n",
      "********************************************************************************\n",
      "epoch: 41 / 800, time cost: 42.88 sec, \n",
      "          Loss: [Train: p = 1.00146, q = 1.11834], \n",
      "          Loss: [Test: p = 1.02219, q = 1.35549],\n",
      "          Effect: [ate-q], [train: 0.05525], [test: 0.05648]\n",
      "********************************************************************************\n",
      "epoch: 42 / 800, time cost: 43.42 sec, \n",
      "          Loss: [Train: p = 1.00149, q = 1.11813], \n",
      "          Loss: [Test: p = 1.02219, q = 1.35251],\n",
      "          Effect: [ate-q], [train: 0.06785], [test: 0.06904]\n",
      "********************************************************************************\n",
      "epoch: 43 / 800, time cost: 43.94 sec, \n",
      "          Loss: [Train: p = 1.00146, q = 1.11804], \n",
      "          Loss: [Test: p = 1.02217, q = 1.35398],\n",
      "          Effect: [ate-q], [train: 0.05790], [test: 0.05911]\n",
      "********************************************************************************\n",
      "epoch: 44 / 800, time cost: 43.09 sec, \n",
      "          Loss: [Train: p = 1.00142, q = 1.11776], \n",
      "          Loss: [Test: p = 1.02217, q = 1.35337],\n",
      "          Effect: [ate-q], [train: 0.05973], [test: 0.06098]\n",
      "********************************************************************************\n",
      "epoch: 45 / 800, time cost: 41.78 sec, \n",
      "          Loss: [Train: p = 1.00146, q = 1.11735], \n",
      "          Loss: [Test: p = 1.02212, q = 1.35270],\n",
      "          Effect: [ate-q], [train: 0.07087], [test: 0.07208]\n",
      "********************************************************************************\n",
      "epoch: 46 / 800, time cost: 40.45 sec, \n",
      "          Loss: [Train: p = 1.00135, q = 1.11747], \n",
      "          Loss: [Test: p = 1.02214, q = 1.35515],\n",
      "          Effect: [ate-q], [train: 0.05542], [test: 0.05668]\n",
      "********************************************************************************\n",
      "epoch: 47 / 800, time cost: 40.60 sec, \n",
      "          Loss: [Train: p = 1.00143, q = 1.11722], \n",
      "          Loss: [Test: p = 1.02216, q = 1.35290],\n",
      "          Effect: [ate-q], [train: 0.06301], [test: 0.06423]\n",
      "********************************************************************************\n",
      "epoch: 48 / 800, time cost: 41.34 sec, \n",
      "          Loss: [Train: p = 1.00132, q = 1.11698], \n",
      "          Loss: [Test: p = 1.02210, q = 1.35207],\n",
      "          Effect: [ate-q], [train: 0.07474], [test: 0.07594]\n",
      "********************************************************************************\n",
      "epoch: 49 / 800, time cost: 43.11 sec, \n",
      "          Loss: [Train: p = 1.00131, q = 1.11732], \n",
      "          Loss: [Test: p = 1.02214, q = 1.35437],\n",
      "          Effect: [ate-q], [train: 0.05392], [test: 0.05508]\n",
      "********************************************************************************\n",
      "epoch: 50 / 800, time cost: 47.14 sec, \n",
      "          Loss: [Train: p = 1.00133, q = 1.11673], \n",
      "          Loss: [Test: p = 1.02211, q = 1.35306],\n",
      "          Effect: [ate-q], [train: 0.06962], [test: 0.07079]\n",
      "********************************************************************************\n",
      "epoch: 51 / 800, time cost: 45.74 sec, \n",
      "          Loss: [Train: p = 1.00127, q = 1.11672], \n",
      "          Loss: [Test: p = 1.02212, q = 1.35330],\n",
      "          Effect: [ate-q], [train: 0.06571], [test: 0.06693]\n",
      "********************************************************************************\n",
      "epoch: 52 / 800, time cost: 41.03 sec, \n",
      "          Loss: [Train: p = 1.00131, q = 1.11670], \n",
      "          Loss: [Test: p = 1.02204, q = 1.35420],\n",
      "          Effect: [ate-q], [train: 0.06277], [test: 0.06399]\n",
      "********************************************************************************\n",
      "epoch: 53 / 800, time cost: 40.42 sec, \n",
      "          Loss: [Train: p = 1.00126, q = 1.11658], \n",
      "          Loss: [Test: p = 1.02207, q = 1.35561],\n",
      "          Effect: [ate-q], [train: 0.05338], [test: 0.05459]\n",
      "********************************************************************************\n",
      "epoch: 54 / 800, time cost: 44.25 sec, \n",
      "          Loss: [Train: p = 1.00122, q = 1.11628], \n",
      "          Loss: [Test: p = 1.02208, q = 1.35323],\n",
      "          Effect: [ate-q], [train: 0.06750], [test: 0.06870]\n",
      "********************************************************************************\n",
      "epoch: 55 / 800, time cost: 40.93 sec, \n",
      "          Loss: [Train: p = 1.00123, q = 1.11645], \n",
      "          Loss: [Test: p = 1.02204, q = 1.35493],\n",
      "          Effect: [ate-q], [train: 0.05907], [test: 0.06025]\n",
      "********************************************************************************\n",
      "epoch: 56 / 800, time cost: 41.76 sec, \n",
      "          Loss: [Train: p = 1.00113, q = 1.11628], \n",
      "          Loss: [Test: p = 1.02206, q = 1.35436],\n",
      "          Effect: [ate-q], [train: 0.06053], [test: 0.06175]\n",
      "********************************************************************************\n",
      "epoch: 57 / 800, time cost: 40.33 sec, \n",
      "          Loss: [Train: p = 1.00111, q = 1.11620], \n",
      "          Loss: [Test: p = 1.02202, q = 1.35444],\n",
      "          Effect: [ate-q], [train: 0.06012], [test: 0.06131]\n",
      "********************************************************************************\n",
      "epoch: 58 / 800, time cost: 46.28 sec, \n",
      "          Loss: [Train: p = 1.00114, q = 1.11612], \n",
      "          Loss: [Test: p = 1.02205, q = 1.35420],\n",
      "          Effect: [ate-q], [train: 0.06051], [test: 0.06176]\n",
      "********************************************************************************\n",
      "epoch: 59 / 800, time cost: 44.45 sec, \n",
      "          Loss: [Train: p = 1.00119, q = 1.11615], \n",
      "          Loss: [Test: p = 1.02198, q = 1.35445],\n",
      "          Effect: [ate-q], [train: 0.06342], [test: 0.06458]\n",
      "********************************************************************************\n",
      "epoch: 60 / 800, time cost: 42.40 sec, \n",
      "          Loss: [Train: p = 1.00100, q = 1.11575], \n",
      "          Loss: [Test: p = 1.02203, q = 1.35586],\n",
      "          Effect: [ate-q], [train: 0.05447], [test: 0.05566]\n",
      "********************************************************************************\n",
      "epoch: 61 / 800, time cost: 40.58 sec, \n",
      "          Loss: [Train: p = 1.00097, q = 1.11528], \n",
      "          Loss: [Test: p = 1.02198, q = 1.35519],\n",
      "          Effect: [ate-q], [train: 0.05828], [test: 0.05953]\n",
      "********************************************************************************\n",
      "epoch: 62 / 800, time cost: 42.93 sec, \n",
      "          Loss: [Train: p = 1.00095, q = 1.11566], \n",
      "          Loss: [Test: p = 1.02200, q = 1.35454],\n",
      "          Effect: [ate-q], [train: 0.06435], [test: 0.06553]\n",
      "********************************************************************************\n",
      "epoch: 63 / 800, time cost: 44.35 sec, \n",
      "          Loss: [Train: p = 1.00098, q = 1.11562], \n",
      "          Loss: [Test: p = 1.02199, q = 1.35324],\n",
      "          Effect: [ate-q], [train: 0.07182], [test: 0.07308]\n",
      "********************************************************************************\n",
      "epoch: 64 / 800, time cost: 44.83 sec, \n",
      "          Loss: [Train: p = 1.00099, q = 1.11513], \n",
      "          Loss: [Test: p = 1.02198, q = 1.35497],\n",
      "          Effect: [ate-q], [train: 0.05967], [test: 0.06083]\n",
      "********************************************************************************\n",
      "epoch: 65 / 800, time cost: 40.17 sec, \n",
      "          Loss: [Train: p = 1.00101, q = 1.11506], \n",
      "          Loss: [Test: p = 1.02198, q = 1.35376],\n",
      "          Effect: [ate-q], [train: 0.07076], [test: 0.07190]\n",
      "********************************************************************************\n",
      "epoch: 66 / 800, time cost: 39.84 sec, \n",
      "          Loss: [Train: p = 1.00090, q = 1.11469], \n",
      "          Loss: [Test: p = 1.02198, q = 1.35445],\n",
      "          Effect: [ate-q], [train: 0.06657], [test: 0.06773]\n",
      "********************************************************************************\n",
      "epoch: 67 / 800, time cost: 41.01 sec, \n",
      "          Loss: [Train: p = 1.00094, q = 1.11486], \n",
      "          Loss: [Test: p = 1.02200, q = 1.35560],\n",
      "          Effect: [ate-q], [train: 0.06186], [test: 0.06304]\n",
      "********************************************************************************\n",
      "epoch: 68 / 800, time cost: 43.28 sec, \n",
      "          Loss: [Train: p = 1.00089, q = 1.11507], \n",
      "          Loss: [Test: p = 1.02196, q = 1.35669],\n",
      "          Effect: [ate-q], [train: 0.05322], [test: 0.05442]\n",
      "********************************************************************************\n",
      "epoch: 69 / 800, time cost: 41.23 sec, \n",
      "          Loss: [Train: p = 1.00085, q = 1.11470], \n",
      "          Loss: [Test: p = 1.02192, q = 1.35392],\n",
      "          Effect: [ate-q], [train: 0.06753], [test: 0.06869]\n",
      "********************************************************************************\n",
      "epoch: 70 / 800, time cost: 41.70 sec, \n",
      "          Loss: [Train: p = 1.00081, q = 1.11442], \n",
      "          Loss: [Test: p = 1.02191, q = 1.35266],\n",
      "          Effect: [ate-q], [train: 0.08151], [test: 0.08264]\n",
      "********************************************************************************\n",
      "epoch: 71 / 800, time cost: 44.79 sec, \n",
      "          Loss: [Train: p = 1.00083, q = 1.11454], \n",
      "          Loss: [Test: p = 1.02190, q = 1.35480],\n",
      "          Effect: [ate-q], [train: 0.06907], [test: 0.07024]\n",
      "********************************************************************************\n",
      "epoch: 72 / 800, time cost: 40.65 sec, \n",
      "          Loss: [Train: p = 1.00072, q = 1.11408], \n",
      "          Loss: [Test: p = 1.02194, q = 1.35599],\n",
      "          Effect: [ate-q], [train: 0.05795], [test: 0.05916]\n",
      "********************************************************************************\n",
      "epoch: 73 / 800, time cost: 43.47 sec, \n",
      "          Loss: [Train: p = 1.00076, q = 1.11409], \n",
      "          Loss: [Test: p = 1.02189, q = 1.35436],\n",
      "          Effect: [ate-q], [train: 0.07161], [test: 0.07283]\n",
      "********************************************************************************\n",
      "epoch: 74 / 800, time cost: 44.19 sec, \n",
      "          Loss: [Train: p = 1.00070, q = 1.11409], \n",
      "          Loss: [Test: p = 1.02192, q = 1.35555],\n",
      "          Effect: [ate-q], [train: 0.06572], [test: 0.06690]\n",
      "********************************************************************************\n",
      "epoch: 75 / 800, time cost: 41.55 sec, \n",
      "          Loss: [Train: p = 1.00064, q = 1.11352], \n",
      "          Loss: [Test: p = 1.02189, q = 1.35359],\n",
      "          Effect: [ate-q], [train: 0.08144], [test: 0.08265]\n",
      "********************************************************************************\n",
      "epoch: 76 / 800, time cost: 39.60 sec, \n",
      "          Loss: [Train: p = 1.00064, q = 1.11370], \n",
      "          Loss: [Test: p = 1.02188, q = 1.35532],\n",
      "          Effect: [ate-q], [train: 0.06840], [test: 0.06961]\n",
      "********************************************************************************\n",
      "epoch: 77 / 800, time cost: 39.99 sec, \n",
      "          Loss: [Train: p = 1.00065, q = 1.11393], \n",
      "          Loss: [Test: p = 1.02190, q = 1.35443],\n",
      "          Effect: [ate-q], [train: 0.07553], [test: 0.07673]\n",
      "********************************************************************************\n",
      "epoch: 78 / 800, time cost: 43.74 sec, \n",
      "          Loss: [Train: p = 1.00060, q = 1.11291], \n",
      "          Loss: [Test: p = 1.02188, q = 1.35651],\n",
      "          Effect: [ate-q], [train: 0.06478], [test: 0.06597]\n",
      "********************************************************************************\n",
      "epoch: 79 / 800, time cost: 39.36 sec, \n",
      "          Loss: [Train: p = 1.00056, q = 1.11348], \n",
      "          Loss: [Test: p = 1.02188, q = 1.35928],\n",
      "          Effect: [ate-q], [train: 0.04406], [test: 0.04529]\n",
      "********************************************************************************\n",
      "epoch: 80 / 800, time cost: 39.95 sec, \n",
      "          Loss: [Train: p = 1.00058, q = 1.11383], \n",
      "          Loss: [Test: p = 1.02185, q = 1.35464],\n",
      "          Effect: [ate-q], [train: 0.07649], [test: 0.07763]\n",
      "********************************************************************************\n",
      "epoch: 81 / 800, time cost: 41.82 sec, \n",
      "          Loss: [Train: p = 1.00063, q = 1.11318], \n",
      "          Loss: [Test: p = 1.02184, q = 1.35783],\n",
      "          Effect: [ate-q], [train: 0.05602], [test: 0.05719]\n",
      "********************************************************************************\n",
      "epoch: 82 / 800, time cost: 44.43 sec, \n",
      "          Loss: [Train: p = 1.00049, q = 1.11346], \n",
      "          Loss: [Test: p = 1.02182, q = 1.35697],\n",
      "          Effect: [ate-q], [train: 0.05724], [test: 0.05842]\n",
      "********************************************************************************\n",
      "epoch: 83 / 800, time cost: 43.35 sec, \n",
      "          Loss: [Train: p = 1.00046, q = 1.11277], \n",
      "          Loss: [Test: p = 1.02184, q = 1.35627],\n",
      "          Effect: [ate-q], [train: 0.06659], [test: 0.06774]\n",
      "********************************************************************************\n",
      "epoch: 84 / 800, time cost: 43.53 sec, \n",
      "          Loss: [Train: p = 1.00049, q = 1.11212], \n",
      "          Loss: [Test: p = 1.02182, q = 1.35567],\n",
      "          Effect: [ate-q], [train: 0.06778], [test: 0.06900]\n",
      "********************************************************************************\n",
      "epoch: 85 / 800, time cost: 40.79 sec, \n",
      "          Loss: [Train: p = 1.00045, q = 1.11280], \n",
      "          Loss: [Test: p = 1.02184, q = 1.35571],\n",
      "          Effect: [ate-q], [train: 0.06681], [test: 0.06797]\n",
      "********************************************************************************\n",
      "epoch: 86 / 800, time cost: 40.84 sec, \n",
      "          Loss: [Train: p = 1.00040, q = 1.11262], \n",
      "          Loss: [Test: p = 1.02180, q = 1.35387],\n",
      "          Effect: [ate-q], [train: 0.07820], [test: 0.07934]\n",
      "********************************************************************************\n",
      "epoch: 87 / 800, time cost: 42.40 sec, \n",
      "          Loss: [Train: p = 1.00036, q = 1.11230], \n",
      "          Loss: [Test: p = 1.02183, q = 1.35644],\n",
      "          Effect: [ate-q], [train: 0.06671], [test: 0.06794]\n",
      "********************************************************************************\n",
      "epoch: 88 / 800, time cost: 45.72 sec, \n",
      "          Loss: [Train: p = 1.00033, q = 1.11265], \n",
      "          Loss: [Test: p = 1.02181, q = 1.35531],\n",
      "          Effect: [ate-q], [train: 0.06867], [test: 0.06988]\n",
      "********************************************************************************\n",
      "epoch: 89 / 800, time cost: 40.23 sec, \n",
      "          Loss: [Train: p = 1.00030, q = 1.11225], \n",
      "          Loss: [Test: p = 1.02179, q = 1.35607],\n",
      "          Effect: [ate-q], [train: 0.06959], [test: 0.07080]\n",
      "********************************************************************************\n",
      "epoch: 90 / 800, time cost: 39.48 sec, \n",
      "          Loss: [Train: p = 1.00039, q = 1.11200], \n",
      "          Loss: [Test: p = 1.02179, q = 1.35540],\n",
      "          Effect: [ate-q], [train: 0.07392], [test: 0.07512]\n",
      "********************************************************************************\n",
      "epoch: 91 / 800, time cost: 40.27 sec, \n",
      "          Loss: [Train: p = 1.00024, q = 1.11173], \n",
      "          Loss: [Test: p = 1.02179, q = 1.35771],\n",
      "          Effect: [ate-q], [train: 0.05662], [test: 0.05782]\n",
      "********************************************************************************\n",
      "epoch: 92 / 800, time cost: 40.18 sec, \n",
      "          Loss: [Train: p = 1.00022, q = 1.11189], \n",
      "          Loss: [Test: p = 1.02174, q = 1.35607],\n",
      "          Effect: [ate-q], [train: 0.06961], [test: 0.07081]\n",
      "********************************************************************************\n",
      "epoch: 93 / 800, time cost: 44.34 sec, \n",
      "          Loss: [Train: p = 1.00015, q = 1.11227], \n",
      "          Loss: [Test: p = 1.02177, q = 1.35816],\n",
      "          Effect: [ate-q], [train: 0.05828], [test: 0.05940]\n",
      "********************************************************************************\n",
      "epoch: 94 / 800, time cost: 42.15 sec, \n",
      "          Loss: [Train: p = 1.00029, q = 1.11128], \n",
      "          Loss: [Test: p = 1.02173, q = 1.35616],\n",
      "          Effect: [ate-q], [train: 0.07060], [test: 0.07181]\n",
      "********************************************************************************\n",
      "epoch: 95 / 800, time cost: 41.04 sec, \n",
      "          Loss: [Train: p = 1.00020, q = 1.11150], \n",
      "          Loss: [Test: p = 1.02178, q = 1.35742],\n",
      "          Effect: [ate-q], [train: 0.06418], [test: 0.06533]\n",
      "********************************************************************************\n",
      "epoch: 96 / 800, time cost: 40.30 sec, \n",
      "          Loss: [Train: p = 1.00014, q = 1.11106], \n",
      "          Loss: [Test: p = 1.02172, q = 1.35738],\n",
      "          Effect: [ate-q], [train: 0.06439], [test: 0.06558]\n",
      "********************************************************************************\n",
      "epoch: 97 / 800, time cost: 42.35 sec, \n",
      "          Loss: [Train: p = 1.00011, q = 1.11136], \n",
      "          Loss: [Test: p = 1.02173, q = 1.35937],\n",
      "          Effect: [ate-q], [train: 0.05487], [test: 0.05606]\n",
      "********************************************************************************\n",
      "epoch: 98 / 800, time cost: 44.78 sec, \n",
      "          Loss: [Train: p = 1.00009, q = 1.11121], \n",
      "          Loss: [Test: p = 1.02174, q = 1.36022],\n",
      "          Effect: [ate-q], [train: 0.04950], [test: 0.05064]\n",
      "********************************************************************************\n",
      "epoch: 99 / 800, time cost: 42.20 sec, \n",
      "          Loss: [Train: p = 0.99997, q = 1.11061], \n",
      "          Loss: [Test: p = 1.02170, q = 1.35692],\n",
      "          Effect: [ate-q], [train: 0.06645], [test: 0.06764]\n",
      "********************************************************************************\n",
      "epoch: 100 / 800, time cost: 42.25 sec, \n",
      "          Loss: [Train: p = 1.00009, q = 1.11063], \n",
      "          Loss: [Test: p = 1.02172, q = 1.35713],\n",
      "          Effect: [ate-q], [train: 0.06610], [test: 0.06725]\n",
      "********************************************************************************\n",
      "epoch: 101 / 800, time cost: 41.16 sec, \n",
      "          Loss: [Train: p = 1.00007, q = 1.11073], \n",
      "          Loss: [Test: p = 1.02171, q = 1.35669],\n",
      "          Effect: [ate-q], [train: 0.07009], [test: 0.07122]\n",
      "********************************************************************************\n",
      "epoch: 102 / 800, time cost: 40.27 sec, \n",
      "          Loss: [Train: p = 0.99999, q = 1.11072], \n",
      "          Loss: [Test: p = 1.02170, q = 1.35808],\n",
      "          Effect: [ate-q], [train: 0.06361], [test: 0.06479]\n",
      "********************************************************************************\n",
      "epoch: 103 / 800, time cost: 42.79 sec, \n",
      "          Loss: [Train: p = 0.99997, q = 1.11001], \n",
      "          Loss: [Test: p = 1.02171, q = 1.35622],\n",
      "          Effect: [ate-q], [train: 0.07605], [test: 0.07721]\n",
      "********************************************************************************\n",
      "epoch: 104 / 800, time cost: 41.54 sec, \n",
      "          Loss: [Train: p = 0.99993, q = 1.11052], \n",
      "          Loss: [Test: p = 1.02163, q = 1.35773],\n",
      "          Effect: [ate-q], [train: 0.06779], [test: 0.06899]\n",
      "********************************************************************************\n",
      "epoch: 105 / 800, time cost: 42.58 sec, \n",
      "          Loss: [Train: p = 0.99978, q = 1.11010], \n",
      "          Loss: [Test: p = 1.02168, q = 1.36027],\n",
      "          Effect: [ate-q], [train: 0.05200], [test: 0.05322]\n",
      "********************************************************************************\n",
      "epoch: 106 / 800, time cost: 40.34 sec, \n",
      "          Loss: [Train: p = 0.99990, q = 1.11048], \n",
      "          Loss: [Test: p = 1.02169, q = 1.35721],\n",
      "          Effect: [ate-q], [train: 0.06978], [test: 0.07097]\n",
      "********************************************************************************\n",
      "epoch: 107 / 800, time cost: 44.08 sec, \n",
      "          Loss: [Train: p = 0.99987, q = 1.11033], \n",
      "          Loss: [Test: p = 1.02167, q = 1.35808],\n",
      "          Effect: [ate-q], [train: 0.06710], [test: 0.06827]\n",
      "********************************************************************************\n",
      "epoch: 108 / 800, time cost: 43.26 sec, \n",
      "          Loss: [Train: p = 0.99987, q = 1.11004], \n",
      "          Loss: [Test: p = 1.02163, q = 1.35864],\n",
      "          Effect: [ate-q], [train: 0.06492], [test: 0.06610]\n",
      "********************************************************************************\n",
      "epoch: 109 / 800, time cost: 40.01 sec, \n",
      "          Loss: [Train: p = 0.99982, q = 1.10952], \n",
      "          Loss: [Test: p = 1.02161, q = 1.35928],\n",
      "          Effect: [ate-q], [train: 0.06016], [test: 0.06128]\n",
      "********************************************************************************\n",
      "epoch: 110 / 800, time cost: 40.01 sec, \n",
      "          Loss: [Train: p = 0.99983, q = 1.10983], \n",
      "          Loss: [Test: p = 1.02164, q = 1.35861],\n",
      "          Effect: [ate-q], [train: 0.06399], [test: 0.06522]\n",
      "********************************************************************************\n",
      "epoch: 111 / 800, time cost: 42.21 sec, \n",
      "          Loss: [Train: p = 0.99992, q = 1.10963], \n",
      "          Loss: [Test: p = 1.02163, q = 1.35752],\n",
      "          Effect: [ate-q], [train: 0.07028], [test: 0.07140]\n",
      "********************************************************************************\n",
      "epoch: 112 / 800, time cost: 43.33 sec, \n",
      "          Loss: [Train: p = 0.99974, q = 1.10978], \n",
      "          Loss: [Test: p = 1.02161, q = 1.35771],\n",
      "          Effect: [ate-q], [train: 0.07281], [test: 0.07397]\n",
      "********************************************************************************\n",
      "epoch: 113 / 800, time cost: 41.12 sec, \n",
      "          Loss: [Train: p = 0.99975, q = 1.10955], \n",
      "          Loss: [Test: p = 1.02162, q = 1.36148],\n",
      "          Effect: [ate-q], [train: 0.04938], [test: 0.05053]\n",
      "********************************************************************************\n",
      "epoch: 114 / 800, time cost: 45.39 sec, \n",
      "          Loss: [Train: p = 0.99970, q = 1.10900], \n",
      "          Loss: [Test: p = 1.02162, q = 1.35700],\n",
      "          Effect: [ate-q], [train: 0.08533], [test: 0.08650]\n",
      "********************************************************************************\n",
      "epoch: 115 / 800, time cost: 43.30 sec, \n",
      "          Loss: [Train: p = 0.99970, q = 1.10942], \n",
      "          Loss: [Test: p = 1.02159, q = 1.35842],\n",
      "          Effect: [ate-q], [train: 0.07000], [test: 0.07111]\n",
      "********************************************************************************\n",
      "epoch: 116 / 800, time cost: 41.82 sec, \n",
      "          Loss: [Train: p = 0.99968, q = 1.10895], \n",
      "          Loss: [Test: p = 1.02160, q = 1.35928],\n",
      "          Effect: [ate-q], [train: 0.06193], [test: 0.06310]\n",
      "********************************************************************************\n",
      "epoch: 117 / 800, time cost: 48.82 sec, \n",
      "          Loss: [Train: p = 0.99962, q = 1.10941], \n",
      "          Loss: [Test: p = 1.02154, q = 1.36162],\n",
      "          Effect: [ate-q], [train: 0.05197], [test: 0.05314]\n",
      "********************************************************************************\n",
      "epoch: 118 / 800, time cost: 40.72 sec, \n",
      "          Loss: [Train: p = 0.99966, q = 1.10898], \n",
      "          Loss: [Test: p = 1.02157, q = 1.35912],\n",
      "          Effect: [ate-q], [train: 0.06458], [test: 0.06576]\n",
      "********************************************************************************\n",
      "epoch: 119 / 800, time cost: 41.81 sec, \n",
      "          Loss: [Train: p = 0.99958, q = 1.10840], \n",
      "          Loss: [Test: p = 1.02157, q = 1.36004],\n",
      "          Effect: [ate-q], [train: 0.06372], [test: 0.06485]\n",
      "********************************************************************************\n",
      "epoch: 120 / 800, time cost: 40.78 sec, \n",
      "          Loss: [Train: p = 0.99965, q = 1.10862], \n",
      "          Loss: [Test: p = 1.02156, q = 1.36029],\n",
      "          Effect: [ate-q], [train: 0.05976], [test: 0.06091]\n",
      "********************************************************************************\n",
      "epoch: 121 / 800, time cost: 40.59 sec, \n",
      "          Loss: [Train: p = 0.99952, q = 1.10802], \n",
      "          Loss: [Test: p = 1.02153, q = 1.35733],\n",
      "          Effect: [ate-q], [train: 0.07854], [test: 0.07969]\n",
      "********************************************************************************\n",
      "epoch: 122 / 800, time cost: 44.00 sec, \n",
      "          Loss: [Train: p = 0.99940, q = 1.10834], \n",
      "          Loss: [Test: p = 1.02156, q = 1.35928],\n",
      "          Effect: [ate-q], [train: 0.06617], [test: 0.06732]\n",
      "********************************************************************************\n",
      "epoch: 123 / 800, time cost: 39.66 sec, \n",
      "          Loss: [Train: p = 0.99948, q = 1.10826], \n",
      "          Loss: [Test: p = 1.02155, q = 1.35969],\n",
      "          Effect: [ate-q], [train: 0.06780], [test: 0.06891]\n",
      "********************************************************************************\n",
      "epoch: 124 / 800, time cost: 44.98 sec, \n",
      "          Loss: [Train: p = 0.99943, q = 1.10787], \n",
      "          Loss: [Test: p = 1.02150, q = 1.35886],\n",
      "          Effect: [ate-q], [train: 0.07567], [test: 0.07681]\n",
      "********************************************************************************\n",
      "epoch: 125 / 800, time cost: 44.36 sec, \n",
      "          Loss: [Train: p = 0.99945, q = 1.10742], \n",
      "          Loss: [Test: p = 1.02151, q = 1.35944],\n",
      "          Effect: [ate-q], [train: 0.06428], [test: 0.06544]\n",
      "********************************************************************************\n",
      "epoch: 126 / 800, time cost: 41.71 sec, \n",
      "          Loss: [Train: p = 0.99944, q = 1.10789], \n",
      "          Loss: [Test: p = 1.02148, q = 1.36130],\n",
      "          Effect: [ate-q], [train: 0.05644], [test: 0.05759]\n",
      "********************************************************************************\n",
      "epoch: 127 / 800, time cost: 43.10 sec, \n",
      "          Loss: [Train: p = 0.99935, q = 1.10783], \n",
      "          Loss: [Test: p = 1.02151, q = 1.35988],\n",
      "          Effect: [ate-q], [train: 0.06601], [test: 0.06725]\n",
      "********************************************************************************\n",
      "epoch: 128 / 800, time cost: 42.28 sec, \n",
      "          Loss: [Train: p = 0.99938, q = 1.10734], \n",
      "          Loss: [Test: p = 1.02150, q = 1.35853],\n",
      "          Effect: [ate-q], [train: 0.07853], [test: 0.07966]\n",
      "********************************************************************************\n",
      "epoch: 129 / 800, time cost: 41.58 sec, \n",
      "          Loss: [Train: p = 0.99938, q = 1.10755], \n",
      "          Loss: [Test: p = 1.02148, q = 1.35885],\n",
      "          Effect: [ate-q], [train: 0.07226], [test: 0.07340]\n",
      "********************************************************************************\n",
      "epoch: 130 / 800, time cost: 40.34 sec, \n",
      "          Loss: [Train: p = 0.99938, q = 1.10756], \n",
      "          Loss: [Test: p = 1.02149, q = 1.35981],\n",
      "          Effect: [ate-q], [train: 0.06593], [test: 0.06706]\n",
      "********************************************************************************\n",
      "epoch: 131 / 800, time cost: 40.74 sec, \n",
      "          Loss: [Train: p = 0.99915, q = 1.10745], \n",
      "          Loss: [Test: p = 1.02147, q = 1.36097],\n",
      "          Effect: [ate-q], [train: 0.06369], [test: 0.06492]\n",
      "********************************************************************************\n",
      "epoch: 132 / 800, time cost: 43.44 sec, \n",
      "          Loss: [Train: p = 0.99931, q = 1.10737], \n",
      "          Loss: [Test: p = 1.02146, q = 1.36055],\n",
      "          Effect: [ate-q], [train: 0.06431], [test: 0.06544]\n",
      "********************************************************************************\n",
      "epoch: 133 / 800, time cost: 40.14 sec, \n",
      "          Loss: [Train: p = 0.99913, q = 1.10736], \n",
      "          Loss: [Test: p = 1.02142, q = 1.35998],\n",
      "          Effect: [ate-q], [train: 0.06855], [test: 0.06966]\n",
      "********************************************************************************\n",
      "epoch: 134 / 800, time cost: 42.00 sec, \n",
      "          Loss: [Train: p = 0.99917, q = 1.10733], \n",
      "          Loss: [Test: p = 1.02147, q = 1.36195],\n",
      "          Effect: [ate-q], [train: 0.05619], [test: 0.05733]\n",
      "********************************************************************************\n",
      "epoch: 135 / 800, time cost: 42.30 sec, \n",
      "          Loss: [Train: p = 0.99914, q = 1.10709], \n",
      "          Loss: [Test: p = 1.02144, q = 1.36116],\n",
      "          Effect: [ate-q], [train: 0.06752], [test: 0.06864]\n",
      "********************************************************************************\n",
      "epoch: 136 / 800, time cost: 41.54 sec, \n",
      "          Loss: [Train: p = 0.99905, q = 1.10614], \n",
      "          Loss: [Test: p = 1.02144, q = 1.36114],\n",
      "          Effect: [ate-q], [train: 0.05878], [test: 0.05987]\n",
      "********************************************************************************\n",
      "epoch: 137 / 800, time cost: 43.35 sec, \n",
      "          Loss: [Train: p = 0.99914, q = 1.10656], \n",
      "          Loss: [Test: p = 1.02147, q = 1.36181],\n",
      "          Effect: [ate-q], [train: 0.05859], [test: 0.05977]\n",
      "********************************************************************************\n",
      "epoch: 138 / 800, time cost: 43.37 sec, \n",
      "          Loss: [Train: p = 0.99907, q = 1.10659], \n",
      "          Loss: [Test: p = 1.02144, q = 1.36207],\n",
      "          Effect: [ate-q], [train: 0.05912], [test: 0.06028]\n",
      "********************************************************************************\n",
      "epoch: 139 / 800, time cost: 44.34 sec, \n",
      "          Loss: [Train: p = 0.99905, q = 1.10631], \n",
      "          Loss: [Test: p = 1.02143, q = 1.35895],\n",
      "          Effect: [ate-q], [train: 0.08437], [test: 0.08547]\n",
      "********************************************************************************\n",
      "epoch: 140 / 800, time cost: 41.76 sec, \n",
      "          Loss: [Train: p = 0.99910, q = 1.10616], \n",
      "          Loss: [Test: p = 1.02140, q = 1.36112],\n",
      "          Effect: [ate-q], [train: 0.05993], [test: 0.06103]\n",
      "********************************************************************************\n",
      "epoch: 141 / 800, time cost: 43.37 sec, \n",
      "          Loss: [Train: p = 0.99906, q = 1.10640], \n",
      "          Loss: [Test: p = 1.02134, q = 1.36131],\n",
      "          Effect: [ate-q], [train: 0.06198], [test: 0.06318]\n",
      "********************************************************************************\n",
      "epoch: 142 / 800, time cost: 41.59 sec, \n",
      "          Loss: [Train: p = 0.99887, q = 1.10611], \n",
      "          Loss: [Test: p = 1.02138, q = 1.36259],\n",
      "          Effect: [ate-q], [train: 0.05839], [test: 0.05956]\n",
      "********************************************************************************\n",
      "epoch: 143 / 800, time cost: 40.59 sec, \n",
      "          Loss: [Train: p = 0.99894, q = 1.10601], \n",
      "          Loss: [Test: p = 1.02141, q = 1.36176],\n",
      "          Effect: [ate-q], [train: 0.06242], [test: 0.06355]\n",
      "********************************************************************************\n",
      "epoch: 144 / 800, time cost: 45.57 sec, \n",
      "          Loss: [Train: p = 0.99905, q = 1.10585], \n",
      "          Loss: [Test: p = 1.02135, q = 1.36091],\n",
      "          Effect: [ate-q], [train: 0.07002], [test: 0.07117]\n",
      "********************************************************************************\n",
      "epoch: 145 / 800, time cost: 41.09 sec, \n",
      "          Loss: [Train: p = 0.99891, q = 1.10556], \n",
      "          Loss: [Test: p = 1.02140, q = 1.36006],\n",
      "          Effect: [ate-q], [train: 0.07554], [test: 0.07665]\n",
      "********************************************************************************\n",
      "epoch: 146 / 800, time cost: 45.45 sec, \n",
      "          Loss: [Train: p = 0.99890, q = 1.10542], \n",
      "          Loss: [Test: p = 1.02131, q = 1.36074],\n",
      "          Effect: [ate-q], [train: 0.07352], [test: 0.07465]\n",
      "********************************************************************************\n",
      "epoch: 147 / 800, time cost: 40.94 sec, \n",
      "          Loss: [Train: p = 0.99889, q = 1.10532], \n",
      "          Loss: [Test: p = 1.02135, q = 1.36390],\n",
      "          Effect: [ate-q], [train: 0.05350], [test: 0.05460]\n",
      "********************************************************************************\n",
      "epoch: 148 / 800, time cost: 40.43 sec, \n",
      "          Loss: [Train: p = 0.99876, q = 1.10537], \n",
      "          Loss: [Test: p = 1.02134, q = 1.36178],\n",
      "          Effect: [ate-q], [train: 0.06615], [test: 0.06731]\n",
      "********************************************************************************\n",
      "epoch: 149 / 800, time cost: 40.35 sec, \n",
      "          Loss: [Train: p = 0.99887, q = 1.10530], \n",
      "          Loss: [Test: p = 1.02135, q = 1.36294],\n",
      "          Effect: [ate-q], [train: 0.05760], [test: 0.05872]\n",
      "********************************************************************************\n",
      "epoch: 150 / 800, time cost: 40.50 sec, \n",
      "          Loss: [Train: p = 0.99872, q = 1.10509], \n",
      "          Loss: [Test: p = 1.02134, q = 1.35957],\n",
      "          Effect: [ate-q], [train: 0.08319], [test: 0.08431]\n",
      "********************************************************************************\n",
      "epoch: 151 / 800, time cost: 48.58 sec, \n",
      "          Loss: [Train: p = 0.99879, q = 1.10520], \n",
      "          Loss: [Test: p = 1.02133, q = 1.36061],\n",
      "          Effect: [ate-q], [train: 0.07633], [test: 0.07750]\n",
      "********************************************************************************\n",
      "epoch: 152 / 800, time cost: 41.90 sec, \n",
      "          Loss: [Train: p = 0.99878, q = 1.10528], \n",
      "          Loss: [Test: p = 1.02132, q = 1.36012],\n",
      "          Effect: [ate-q], [train: 0.08163], [test: 0.08273]\n",
      "********************************************************************************\n",
      "epoch: 153 / 800, time cost: 40.79 sec, \n",
      "          Loss: [Train: p = 0.99875, q = 1.10497], \n",
      "          Loss: [Test: p = 1.02134, q = 1.36334],\n",
      "          Effect: [ate-q], [train: 0.05821], [test: 0.05934]\n",
      "********************************************************************************\n",
      "epoch: 154 / 800, time cost: 40.52 sec, \n",
      "          Loss: [Train: p = 0.99864, q = 1.10455], \n",
      "          Loss: [Test: p = 1.02130, q = 1.36290],\n",
      "          Effect: [ate-q], [train: 0.06078], [test: 0.06193]\n",
      "********************************************************************************\n",
      "epoch: 155 / 800, time cost: 40.24 sec, \n",
      "          Loss: [Train: p = 0.99864, q = 1.10473], \n",
      "          Loss: [Test: p = 1.02130, q = 1.36099],\n",
      "          Effect: [ate-q], [train: 0.07327], [test: 0.07431]\n",
      "********************************************************************************\n",
      "epoch: 156 / 800, time cost: 43.50 sec, \n",
      "          Loss: [Train: p = 0.99856, q = 1.10440], \n",
      "          Loss: [Test: p = 1.02132, q = 1.36203],\n",
      "          Effect: [ate-q], [train: 0.06954], [test: 0.07065]\n",
      "********************************************************************************\n",
      "epoch: 157 / 800, time cost: 41.16 sec, \n",
      "          Loss: [Train: p = 0.99860, q = 1.10425], \n",
      "          Loss: [Test: p = 1.02131, q = 1.36235],\n",
      "          Effect: [ate-q], [train: 0.06053], [test: 0.06169]\n",
      "********************************************************************************\n",
      "epoch: 158 / 800, time cost: 39.43 sec, \n",
      "          Loss: [Train: p = 0.99855, q = 1.10476], \n",
      "          Loss: [Test: p = 1.02128, q = 1.36448],\n",
      "          Effect: [ate-q], [train: 0.05113], [test: 0.05228]\n",
      "********************************************************************************\n",
      "epoch: 159 / 800, time cost: 39.58 sec, \n",
      "          Loss: [Train: p = 0.99856, q = 1.10448], \n",
      "          Loss: [Test: p = 1.02126, q = 1.36587],\n",
      "          Effect: [ate-q], [train: 0.04484], [test: 0.04597]\n",
      "********************************************************************************\n",
      "epoch: 160 / 800, time cost: 40.72 sec, \n",
      "          Loss: [Train: p = 0.99851, q = 1.10399], \n",
      "          Loss: [Test: p = 1.02126, q = 1.36400],\n",
      "          Effect: [ate-q], [train: 0.05825], [test: 0.05939]\n",
      "********************************************************************************\n",
      "epoch: 161 / 800, time cost: 42.73 sec, \n",
      "          Loss: [Train: p = 0.99854, q = 1.10431], \n",
      "          Loss: [Test: p = 1.02128, q = 1.36652],\n",
      "          Effect: [ate-q], [train: 0.04476], [test: 0.04588]\n",
      "********************************************************************************\n",
      "epoch: 162 / 800, time cost: 40.26 sec, \n",
      "          Loss: [Train: p = 0.99839, q = 1.10385], \n",
      "          Loss: [Test: p = 1.02122, q = 1.36211],\n",
      "          Effect: [ate-q], [train: 0.07107], [test: 0.07218]\n",
      "********************************************************************************\n",
      "epoch: 163 / 800, time cost: 39.89 sec, \n",
      "          Loss: [Train: p = 0.99846, q = 1.10384], \n",
      "          Loss: [Test: p = 1.02124, q = 1.36289],\n",
      "          Effect: [ate-q], [train: 0.06212], [test: 0.06324]\n",
      "********************************************************************************\n",
      "epoch: 164 / 800, time cost: 44.44 sec, \n",
      "          Loss: [Train: p = 0.99848, q = 1.10370], \n",
      "          Loss: [Test: p = 1.02124, q = 1.36570],\n",
      "          Effect: [ate-q], [train: 0.05336], [test: 0.05451]\n",
      "********************************************************************************\n",
      "epoch: 165 / 800, time cost: 41.78 sec, \n",
      "          Loss: [Train: p = 0.99842, q = 1.10351], \n",
      "          Loss: [Test: p = 1.02121, q = 1.36136],\n",
      "          Effect: [ate-q], [train: 0.07506], [test: 0.07613]\n",
      "********************************************************************************\n",
      "epoch: 166 / 800, time cost: 43.78 sec, \n",
      "          Loss: [Train: p = 0.99852, q = 1.10371], \n",
      "          Loss: [Test: p = 1.02124, q = 1.36310],\n",
      "          Effect: [ate-q], [train: 0.06634], [test: 0.06750]\n",
      "********************************************************************************\n",
      "epoch: 167 / 800, time cost: 42.14 sec, \n",
      "          Loss: [Train: p = 0.99840, q = 1.10292], \n",
      "          Loss: [Test: p = 1.02121, q = 1.36190],\n",
      "          Effect: [ate-q], [train: 0.07678], [test: 0.07786]\n",
      "********************************************************************************\n",
      "epoch: 168 / 800, time cost: 41.00 sec, \n",
      "          Loss: [Train: p = 0.99837, q = 1.10345], \n",
      "          Loss: [Test: p = 1.02122, q = 1.36607],\n",
      "          Effect: [ate-q], [train: 0.04984], [test: 0.05097]\n",
      "********************************************************************************\n",
      "epoch: 169 / 800, time cost: 40.30 sec, \n",
      "          Loss: [Train: p = 0.99837, q = 1.10305], \n",
      "          Loss: [Test: p = 1.02120, q = 1.36258],\n",
      "          Effect: [ate-q], [train: 0.07266], [test: 0.07373]\n",
      "********************************************************************************\n",
      "epoch: 170 / 800, time cost: 41.42 sec, \n",
      "          Loss: [Train: p = 0.99831, q = 1.10286], \n",
      "          Loss: [Test: p = 1.02121, q = 1.36501],\n",
      "          Effect: [ate-q], [train: 0.05658], [test: 0.05770]\n",
      "********************************************************************************\n",
      "epoch: 171 / 800, time cost: 43.56 sec, \n",
      "          Loss: [Train: p = 0.99825, q = 1.10286], \n",
      "          Loss: [Test: p = 1.02120, q = 1.36746],\n",
      "          Effect: [ate-q], [train: 0.04415], [test: 0.04530]\n",
      "********************************************************************************\n",
      "epoch: 172 / 800, time cost: 40.18 sec, \n",
      "          Loss: [Train: p = 0.99826, q = 1.10304], \n",
      "          Loss: [Test: p = 1.02118, q = 1.36389],\n",
      "          Effect: [ate-q], [train: 0.06340], [test: 0.06454]\n",
      "********************************************************************************\n",
      "epoch: 173 / 800, time cost: 40.39 sec, \n",
      "          Loss: [Train: p = 0.99828, q = 1.10289], \n",
      "          Loss: [Test: p = 1.02116, q = 1.36172],\n",
      "          Effect: [ate-q], [train: 0.08519], [test: 0.08627]\n",
      "********************************************************************************\n",
      "epoch: 174 / 800, time cost: 40.84 sec, \n",
      "          Loss: [Train: p = 0.99819, q = 1.10245], \n",
      "          Loss: [Test: p = 1.02117, q = 1.36288],\n",
      "          Effect: [ate-q], [train: 0.06694], [test: 0.06802]\n",
      "********************************************************************************\n",
      "epoch: 175 / 800, time cost: 40.52 sec, \n",
      "          Loss: [Train: p = 0.99820, q = 1.10249], \n",
      "          Loss: [Test: p = 1.02117, q = 1.36299],\n",
      "          Effect: [ate-q], [train: 0.07479], [test: 0.07586]\n",
      "********************************************************************************\n",
      "epoch: 176 / 800, time cost: 44.48 sec, \n",
      "          Loss: [Train: p = 0.99807, q = 1.10225], \n",
      "          Loss: [Test: p = 1.02111, q = 1.36660],\n",
      "          Effect: [ate-q], [train: 0.05346], [test: 0.05454]\n",
      "********************************************************************************\n",
      "epoch: 177 / 800, time cost: 38.87 sec, \n",
      "          Loss: [Train: p = 0.99810, q = 1.10244], \n",
      "          Loss: [Test: p = 1.02114, q = 1.36413],\n",
      "          Effect: [ate-q], [train: 0.06883], [test: 0.06993]\n",
      "********************************************************************************\n",
      "epoch: 178 / 800, time cost: 38.14 sec, \n",
      "          Loss: [Train: p = 0.99806, q = 1.10171], \n",
      "          Loss: [Test: p = 1.02113, q = 1.36503],\n",
      "          Effect: [ate-q], [train: 0.05690], [test: 0.05798]\n",
      "********************************************************************************\n",
      "epoch: 179 / 800, time cost: 37.82 sec, \n",
      "          Loss: [Train: p = 0.99804, q = 1.10161], \n",
      "          Loss: [Test: p = 1.02110, q = 1.36530],\n",
      "          Effect: [ate-q], [train: 0.06085], [test: 0.06197]\n",
      "********************************************************************************\n",
      "epoch: 180 / 800, time cost: 39.94 sec, \n",
      "          Loss: [Train: p = 0.99803, q = 1.10210], \n",
      "          Loss: [Test: p = 1.02109, q = 1.36348],\n",
      "          Effect: [ate-q], [train: 0.07126], [test: 0.07239]\n",
      "********************************************************************************\n",
      "epoch: 181 / 800, time cost: 37.92 sec, \n",
      "          Loss: [Train: p = 0.99801, q = 1.10210], \n",
      "          Loss: [Test: p = 1.02111, q = 1.36565],\n",
      "          Effect: [ate-q], [train: 0.06062], [test: 0.06175]\n",
      "********************************************************************************\n",
      "epoch: 182 / 800, time cost: 44.02 sec, \n",
      "          Loss: [Train: p = 0.99798, q = 1.10158], \n",
      "          Loss: [Test: p = 1.02110, q = 1.36483],\n",
      "          Effect: [ate-q], [train: 0.06646], [test: 0.06763]\n",
      "********************************************************************************\n",
      "epoch: 183 / 800, time cost: 40.98 sec, \n",
      "          Loss: [Train: p = 0.99799, q = 1.10211], \n",
      "          Loss: [Test: p = 1.02110, q = 1.36492],\n",
      "          Effect: [ate-q], [train: 0.06297], [test: 0.06413]\n",
      "********************************************************************************\n",
      "epoch: 184 / 800, time cost: 40.34 sec, \n",
      "          Loss: [Train: p = 0.99794, q = 1.10147], \n",
      "          Loss: [Test: p = 1.02109, q = 1.36769],\n",
      "          Effect: [ate-q], [train: 0.04964], [test: 0.05072]\n",
      "********************************************************************************\n",
      "epoch: 185 / 800, time cost: 43.12 sec, \n",
      "          Loss: [Train: p = 0.99799, q = 1.10135], \n",
      "          Loss: [Test: p = 1.02109, q = 1.36666],\n",
      "          Effect: [ate-q], [train: 0.05363], [test: 0.05474]\n",
      "********************************************************************************\n",
      "epoch: 186 / 800, time cost: 41.19 sec, \n",
      "          Loss: [Train: p = 0.99791, q = 1.10145], \n",
      "          Loss: [Test: p = 1.02104, q = 1.36540],\n",
      "          Effect: [ate-q], [train: 0.06045], [test: 0.06159]\n",
      "********************************************************************************\n",
      "epoch: 187 / 800, time cost: 40.35 sec, \n",
      "          Loss: [Train: p = 0.99787, q = 1.10126], \n",
      "          Loss: [Test: p = 1.02109, q = 1.36877],\n",
      "          Effect: [ate-q], [train: 0.04669], [test: 0.04782]\n",
      "********************************************************************************\n",
      "epoch: 188 / 800, time cost: 44.77 sec, \n",
      "          Loss: [Train: p = 0.99781, q = 1.10149], \n",
      "          Loss: [Test: p = 1.02102, q = 1.36387],\n",
      "          Effect: [ate-q], [train: 0.07441], [test: 0.07548]\n",
      "********************************************************************************\n",
      "epoch: 189 / 800, time cost: 43.45 sec, \n",
      "          Loss: [Train: p = 0.99772, q = 1.10153], \n",
      "          Loss: [Test: p = 1.02106, q = 1.36466],\n",
      "          Effect: [ate-q], [train: 0.06598], [test: 0.06708]\n",
      "********************************************************************************\n",
      "epoch: 190 / 800, time cost: 48.62 sec, \n",
      "          Loss: [Train: p = 0.99775, q = 1.10073], \n",
      "          Loss: [Test: p = 1.02103, q = 1.36404],\n",
      "          Effect: [ate-q], [train: 0.07320], [test: 0.07429]\n",
      "********************************************************************************\n",
      "epoch: 191 / 800, time cost: 42.64 sec, \n",
      "          Loss: [Train: p = 0.99777, q = 1.10119], \n",
      "          Loss: [Test: p = 1.02103, q = 1.36900],\n",
      "          Effect: [ate-q], [train: 0.04584], [test: 0.04699]\n",
      "********************************************************************************\n",
      "epoch: 192 / 800, time cost: 44.98 sec, \n",
      "          Loss: [Train: p = 0.99775, q = 1.10115], \n",
      "          Loss: [Test: p = 1.02097, q = 1.36500],\n",
      "          Effect: [ate-q], [train: 0.06793], [test: 0.06900]\n",
      "********************************************************************************\n",
      "epoch: 193 / 800, time cost: 42.44 sec, \n",
      "          Loss: [Train: p = 0.99772, q = 1.10070], \n",
      "          Loss: [Test: p = 1.02106, q = 1.36413],\n",
      "          Effect: [ate-q], [train: 0.07348], [test: 0.07456]\n",
      "********************************************************************************\n",
      "epoch: 194 / 800, time cost: 43.70 sec, \n",
      "          Loss: [Train: p = 0.99762, q = 1.10027], \n",
      "          Loss: [Test: p = 1.02101, q = 1.36528],\n",
      "          Effect: [ate-q], [train: 0.07044], [test: 0.07156]\n",
      "********************************************************************************\n",
      "epoch: 195 / 800, time cost: 45.74 sec, \n",
      "          Loss: [Train: p = 0.99762, q = 1.10045], \n",
      "          Loss: [Test: p = 1.02099, q = 1.36528],\n",
      "          Effect: [ate-q], [train: 0.07326], [test: 0.07437]\n",
      "********************************************************************************\n",
      "epoch: 196 / 800, time cost: 40.36 sec, \n",
      "          Loss: [Train: p = 0.99765, q = 1.10038], \n",
      "          Loss: [Test: p = 1.02100, q = 1.36720],\n",
      "          Effect: [ate-q], [train: 0.05606], [test: 0.05718]\n",
      "********************************************************************************\n",
      "epoch: 197 / 800, time cost: 39.69 sec, \n",
      "          Loss: [Train: p = 0.99764, q = 1.10031], \n",
      "          Loss: [Test: p = 1.02100, q = 1.36805],\n",
      "          Effect: [ate-q], [train: 0.05177], [test: 0.05290]\n",
      "********************************************************************************\n",
      "epoch: 198 / 800, time cost: 43.07 sec, \n",
      "          Loss: [Train: p = 0.99763, q = 1.10010], \n",
      "          Loss: [Test: p = 1.02102, q = 1.36579],\n",
      "          Effect: [ate-q], [train: 0.06741], [test: 0.06846]\n",
      "********************************************************************************\n",
      "epoch: 199 / 800, time cost: 40.13 sec, \n",
      "          Loss: [Train: p = 0.99756, q = 1.10010], \n",
      "          Loss: [Test: p = 1.02099, q = 1.37024],\n",
      "          Effect: [ate-q], [train: 0.04559], [test: 0.04675]\n",
      "********************************************************************************\n",
      "epoch: 200 / 800, time cost: 42.82 sec, \n",
      "          Loss: [Train: p = 0.99755, q = 1.09961], \n",
      "          Loss: [Test: p = 1.02100, q = 1.36774],\n",
      "          Effect: [ate-q], [train: 0.05861], [test: 0.05973]\n",
      "********************************************************************************\n",
      "epoch: 201 / 800, time cost: 40.26 sec, \n",
      "          Loss: [Train: p = 0.99749, q = 1.10001], \n",
      "          Loss: [Test: p = 1.02095, q = 1.36511],\n",
      "          Effect: [ate-q], [train: 0.07221], [test: 0.07333]\n",
      "********************************************************************************\n",
      "epoch: 202 / 800, time cost: 40.68 sec, \n",
      "          Loss: [Train: p = 0.99760, q = 1.09973], \n",
      "          Loss: [Test: p = 1.02097, q = 1.36797],\n",
      "          Effect: [ate-q], [train: 0.05574], [test: 0.05686]\n",
      "********************************************************************************\n",
      "epoch: 203 / 800, time cost: 41.92 sec, \n",
      "          Loss: [Train: p = 0.99743, q = 1.09988], \n",
      "          Loss: [Test: p = 1.02094, q = 1.36793],\n",
      "          Effect: [ate-q], [train: 0.05632], [test: 0.05741]\n",
      "********************************************************************************\n",
      "epoch: 204 / 800, time cost: 40.43 sec, \n",
      "          Loss: [Train: p = 0.99749, q = 1.09993], \n",
      "          Loss: [Test: p = 1.02095, q = 1.36695],\n",
      "          Effect: [ate-q], [train: 0.06232], [test: 0.06338]\n",
      "********************************************************************************\n",
      "epoch: 205 / 800, time cost: 43.05 sec, \n",
      "          Loss: [Train: p = 0.99758, q = 1.09935], \n",
      "          Loss: [Test: p = 1.02094, q = 1.36693],\n",
      "          Effect: [ate-q], [train: 0.06410], [test: 0.06519]\n",
      "********************************************************************************\n",
      "epoch: 206 / 800, time cost: 44.39 sec, \n",
      "          Loss: [Train: p = 0.99737, q = 1.09960], \n",
      "          Loss: [Test: p = 1.02094, q = 1.36738],\n",
      "          Effect: [ate-q], [train: 0.06163], [test: 0.06273]\n",
      "********************************************************************************\n",
      "epoch: 207 / 800, time cost: 51.30 sec, \n",
      "          Loss: [Train: p = 0.99730, q = 1.09906], \n",
      "          Loss: [Test: p = 1.02092, q = 1.36578],\n",
      "          Effect: [ate-q], [train: 0.07982], [test: 0.08090]\n",
      "********************************************************************************\n",
      "epoch: 208 / 800, time cost: 50.37 sec, \n",
      "          Loss: [Train: p = 0.99735, q = 1.09899], \n",
      "          Loss: [Test: p = 1.02094, q = 1.36898],\n",
      "          Effect: [ate-q], [train: 0.05508], [test: 0.05618]\n",
      "********************************************************************************\n",
      "epoch: 209 / 800, time cost: 45.93 sec, \n",
      "          Loss: [Train: p = 0.99723, q = 1.09921], \n",
      "          Loss: [Test: p = 1.02090, q = 1.36637],\n",
      "          Effect: [ate-q], [train: 0.07491], [test: 0.07597]\n",
      "********************************************************************************\n",
      "epoch: 210 / 800, time cost: 43.79 sec, \n",
      "          Loss: [Train: p = 0.99723, q = 1.09911], \n",
      "          Loss: [Test: p = 1.02092, q = 1.36678],\n",
      "          Effect: [ate-q], [train: 0.06835], [test: 0.06947]\n",
      "********************************************************************************\n",
      "epoch: 211 / 800, time cost: 40.90 sec, \n",
      "          Loss: [Train: p = 0.99731, q = 1.09894], \n",
      "          Loss: [Test: p = 1.02086, q = 1.36685],\n",
      "          Effect: [ate-q], [train: 0.06800], [test: 0.06906]\n",
      "********************************************************************************\n",
      "epoch: 212 / 800, time cost: 40.54 sec, \n",
      "          Loss: [Train: p = 0.99727, q = 1.09848], \n",
      "          Loss: [Test: p = 1.02089, q = 1.36546],\n",
      "          Effect: [ate-q], [train: 0.08589], [test: 0.08691]\n",
      "********************************************************************************\n",
      "epoch: 213 / 800, time cost: 42.92 sec, \n",
      "          Loss: [Train: p = 0.99717, q = 1.09870], \n",
      "          Loss: [Test: p = 1.02087, q = 1.36771],\n",
      "          Effect: [ate-q], [train: 0.06771], [test: 0.06876]\n",
      "********************************************************************************\n",
      "epoch: 214 / 800, time cost: 46.30 sec, \n",
      "          Loss: [Train: p = 0.99718, q = 1.09904], \n",
      "          Loss: [Test: p = 1.02091, q = 1.36822],\n",
      "          Effect: [ate-q], [train: 0.05931], [test: 0.06039]\n",
      "********************************************************************************\n",
      "epoch: 215 / 800, time cost: 41.95 sec, \n",
      "          Loss: [Train: p = 0.99707, q = 1.09847], \n",
      "          Loss: [Test: p = 1.02089, q = 1.36727],\n",
      "          Effect: [ate-q], [train: 0.06920], [test: 0.07021]\n",
      "********************************************************************************\n",
      "epoch: 216 / 800, time cost: 40.63 sec, \n",
      "          Loss: [Train: p = 0.99716, q = 1.09869], \n",
      "          Loss: [Test: p = 1.02089, q = 1.36538],\n",
      "          Effect: [ate-q], [train: 0.08295], [test: 0.08398]\n",
      "********************************************************************************\n",
      "epoch: 217 / 800, time cost: 41.72 sec, \n",
      "          Loss: [Train: p = 0.99714, q = 1.09820], \n",
      "          Loss: [Test: p = 1.02083, q = 1.36595],\n",
      "          Effect: [ate-q], [train: 0.08056], [test: 0.08168]\n",
      "********************************************************************************\n",
      "epoch: 218 / 800, time cost: 39.91 sec, \n",
      "          Loss: [Train: p = 0.99715, q = 1.09860], \n",
      "          Loss: [Test: p = 1.02088, q = 1.36787],\n",
      "          Effect: [ate-q], [train: 0.06760], [test: 0.06868]\n",
      "********************************************************************************\n",
      "epoch: 219 / 800, time cost: 43.09 sec, \n",
      "          Loss: [Train: p = 0.99704, q = 1.09866], \n",
      "          Loss: [Test: p = 1.02085, q = 1.36953],\n",
      "          Effect: [ate-q], [train: 0.05878], [test: 0.05984]\n",
      "********************************************************************************\n",
      "epoch: 220 / 800, time cost: 41.21 sec, \n",
      "          Loss: [Train: p = 0.99701, q = 1.09785], \n",
      "          Loss: [Test: p = 1.02084, q = 1.36890],\n",
      "          Effect: [ate-q], [train: 0.05997], [test: 0.06099]\n",
      "********************************************************************************\n",
      "epoch: 221 / 800, time cost: 39.94 sec, \n",
      "          Loss: [Train: p = 0.99693, q = 1.09797], \n",
      "          Loss: [Test: p = 1.02088, q = 1.37213],\n",
      "          Effect: [ate-q], [train: 0.04377], [test: 0.04486]\n",
      "********************************************************************************\n",
      "epoch: 222 / 800, time cost: 42.15 sec, \n",
      "          Loss: [Train: p = 0.99701, q = 1.09821], \n",
      "          Loss: [Test: p = 1.02085, q = 1.36821],\n",
      "          Effect: [ate-q], [train: 0.06205], [test: 0.06308]\n",
      "********************************************************************************\n",
      "epoch: 223 / 800, time cost: 45.01 sec, \n",
      "          Loss: [Train: p = 0.99693, q = 1.09791], \n",
      "          Loss: [Test: p = 1.02081, q = 1.36837],\n",
      "          Effect: [ate-q], [train: 0.06102], [test: 0.06207]\n",
      "********************************************************************************\n",
      "epoch: 224 / 800, time cost: 42.43 sec, \n",
      "          Loss: [Train: p = 0.99690, q = 1.09770], \n",
      "          Loss: [Test: p = 1.02080, q = 1.36671],\n",
      "          Effect: [ate-q], [train: 0.07471], [test: 0.07577]\n",
      "********************************************************************************\n",
      "epoch: 225 / 800, time cost: 40.92 sec, \n",
      "          Loss: [Train: p = 0.99688, q = 1.09732], \n",
      "          Loss: [Test: p = 1.02080, q = 1.37023],\n",
      "          Effect: [ate-q], [train: 0.05680], [test: 0.05788]\n",
      "********************************************************************************\n",
      "epoch: 226 / 800, time cost: 38.93 sec, \n",
      "          Loss: [Train: p = 0.99693, q = 1.09787], \n",
      "          Loss: [Test: p = 1.02079, q = 1.36983],\n",
      "          Effect: [ate-q], [train: 0.05712], [test: 0.05825]\n",
      "********************************************************************************\n",
      "epoch: 227 / 800, time cost: 40.00 sec, \n",
      "          Loss: [Train: p = 0.99683, q = 1.09724], \n",
      "          Loss: [Test: p = 1.02076, q = 1.36934],\n",
      "          Effect: [ate-q], [train: 0.06190], [test: 0.06299]\n",
      "********************************************************************************\n",
      "epoch: 228 / 800, time cost: 40.18 sec, \n",
      "          Loss: [Train: p = 0.99677, q = 1.09725], \n",
      "          Loss: [Test: p = 1.02076, q = 1.37219],\n",
      "          Effect: [ate-q], [train: 0.05085], [test: 0.05196]\n",
      "********************************************************************************\n",
      "epoch: 229 / 800, time cost: 44.84 sec, \n",
      "          Loss: [Train: p = 0.99687, q = 1.09765], \n",
      "          Loss: [Test: p = 1.02079, q = 1.36912],\n",
      "          Effect: [ate-q], [train: 0.06336], [test: 0.06442]\n",
      "********************************************************************************\n",
      "epoch: 230 / 800, time cost: 42.26 sec, \n",
      "          Loss: [Train: p = 0.99667, q = 1.09760], \n",
      "          Loss: [Test: p = 1.02077, q = 1.37036],\n",
      "          Effect: [ate-q], [train: 0.05583], [test: 0.05689]\n",
      "********************************************************************************\n",
      "epoch: 231 / 800, time cost: 41.63 sec, \n",
      "          Loss: [Train: p = 0.99675, q = 1.09660], \n",
      "          Loss: [Test: p = 1.02077, q = 1.37186],\n",
      "          Effect: [ate-q], [train: 0.05127], [test: 0.05243]\n",
      "********************************************************************************\n",
      "epoch: 232 / 800, time cost: 43.95 sec, \n",
      "          Loss: [Train: p = 0.99670, q = 1.09638], \n",
      "          Loss: [Test: p = 1.02076, q = 1.36930],\n",
      "          Effect: [ate-q], [train: 0.06757], [test: 0.06865]\n",
      "********************************************************************************\n",
      "epoch: 233 / 800, time cost: 40.87 sec, \n",
      "          Loss: [Train: p = 0.99678, q = 1.09688], \n",
      "          Loss: [Test: p = 1.02072, q = 1.36932],\n",
      "          Effect: [ate-q], [train: 0.06385], [test: 0.06491]\n",
      "********************************************************************************\n",
      "epoch: 234 / 800, time cost: 42.89 sec, \n",
      "          Loss: [Train: p = 0.99662, q = 1.09666], \n",
      "          Loss: [Test: p = 1.02075, q = 1.36980],\n",
      "          Effect: [ate-q], [train: 0.06361], [test: 0.06467]\n",
      "********************************************************************************\n",
      "epoch: 235 / 800, time cost: 39.19 sec, \n",
      "          Loss: [Train: p = 0.99672, q = 1.09631], \n",
      "          Loss: [Test: p = 1.02075, q = 1.37163],\n",
      "          Effect: [ate-q], [train: 0.05060], [test: 0.05165]\n",
      "********************************************************************************\n",
      "epoch: 236 / 800, time cost: 40.89 sec, \n",
      "          Loss: [Train: p = 0.99651, q = 1.09673], \n",
      "          Loss: [Test: p = 1.02074, q = 1.37077],\n",
      "          Effect: [ate-q], [train: 0.05708], [test: 0.05815]\n",
      "********************************************************************************\n",
      "epoch: 237 / 800, time cost: 41.49 sec, \n",
      "          Loss: [Train: p = 0.99672, q = 1.09602], \n",
      "          Loss: [Test: p = 1.02072, q = 1.36899],\n",
      "          Effect: [ate-q], [train: 0.06562], [test: 0.06664]\n",
      "********************************************************************************\n",
      "epoch: 238 / 800, time cost: 41.32 sec, \n",
      "          Loss: [Train: p = 0.99657, q = 1.09608], \n",
      "          Loss: [Test: p = 1.02071, q = 1.36936],\n",
      "          Effect: [ate-q], [train: 0.06855], [test: 0.06956]\n",
      "********************************************************************************\n",
      "epoch: 239 / 800, time cost: 43.22 sec, \n",
      "          Loss: [Train: p = 0.99661, q = 1.09621], \n",
      "          Loss: [Test: p = 1.02070, q = 1.37064],\n",
      "          Effect: [ate-q], [train: 0.06647], [test: 0.06756]\n",
      "********************************************************************************\n",
      "epoch: 240 / 800, time cost: 39.83 sec, \n",
      "          Loss: [Train: p = 0.99662, q = 1.09586], \n",
      "          Loss: [Test: p = 1.02066, q = 1.37050],\n",
      "          Effect: [ate-q], [train: 0.06367], [test: 0.06470]\n",
      "********************************************************************************\n",
      "epoch: 241 / 800, time cost: 40.14 sec, \n",
      "          Loss: [Train: p = 0.99647, q = 1.09622], \n",
      "          Loss: [Test: p = 1.02068, q = 1.36945],\n",
      "          Effect: [ate-q], [train: 0.07482], [test: 0.07582]\n",
      "********************************************************************************\n",
      "epoch: 242 / 800, time cost: 40.99 sec, \n",
      "          Loss: [Train: p = 0.99653, q = 1.09632], \n",
      "          Loss: [Test: p = 1.02071, q = 1.37199],\n",
      "          Effect: [ate-q], [train: 0.05819], [test: 0.05927]\n",
      "********************************************************************************\n",
      "epoch: 243 / 800, time cost: 40.84 sec, \n",
      "          Loss: [Train: p = 0.99647, q = 1.09581], \n",
      "          Loss: [Test: p = 1.02068, q = 1.37015],\n",
      "          Effect: [ate-q], [train: 0.06614], [test: 0.06716]\n",
      "********************************************************************************\n",
      "epoch: 244 / 800, time cost: 45.78 sec, \n",
      "          Loss: [Train: p = 0.99639, q = 1.09593], \n",
      "          Loss: [Test: p = 1.02065, q = 1.36846],\n",
      "          Effect: [ate-q], [train: 0.08201], [test: 0.08307]\n",
      "********************************************************************************\n",
      "epoch: 245 / 800, time cost: 41.82 sec, \n",
      "          Loss: [Train: p = 0.99636, q = 1.09573], \n",
      "          Loss: [Test: p = 1.02064, q = 1.37063],\n",
      "          Effect: [ate-q], [train: 0.06353], [test: 0.06459]\n",
      "********************************************************************************\n",
      "epoch: 246 / 800, time cost: 41.26 sec, \n",
      "          Loss: [Train: p = 0.99640, q = 1.09526], \n",
      "          Loss: [Test: p = 1.02066, q = 1.36822],\n",
      "          Effect: [ate-q], [train: 0.08014], [test: 0.08115]\n",
      "********************************************************************************\n",
      "epoch: 247 / 800, time cost: 40.81 sec, \n",
      "          Loss: [Train: p = 0.99636, q = 1.09568], \n",
      "          Loss: [Test: p = 1.02067, q = 1.37024],\n",
      "          Effect: [ate-q], [train: 0.06783], [test: 0.06887]\n",
      "********************************************************************************\n",
      "epoch: 248 / 800, time cost: 43.71 sec, \n",
      "          Loss: [Train: p = 0.99631, q = 1.09560], \n",
      "          Loss: [Test: p = 1.02065, q = 1.37049],\n",
      "          Effect: [ate-q], [train: 0.06636], [test: 0.06733]\n",
      "********************************************************************************\n",
      "epoch: 249 / 800, time cost: 44.51 sec, \n",
      "          Loss: [Train: p = 0.99635, q = 1.09527], \n",
      "          Loss: [Test: p = 1.02068, q = 1.37027],\n",
      "          Effect: [ate-q], [train: 0.07134], [test: 0.07234]\n",
      "********************************************************************************\n",
      "epoch: 250 / 800, time cost: 40.31 sec, \n",
      "          Loss: [Train: p = 0.99629, q = 1.09527], \n",
      "          Loss: [Test: p = 1.02064, q = 1.37191],\n",
      "          Effect: [ate-q], [train: 0.05763], [test: 0.05870]\n",
      "********************************************************************************\n",
      "epoch: 251 / 800, time cost: 41.56 sec, \n",
      "          Loss: [Train: p = 0.99624, q = 1.09498], \n",
      "          Loss: [Test: p = 1.02064, q = 1.37152],\n",
      "          Effect: [ate-q], [train: 0.06234], [test: 0.06340]\n",
      "********************************************************************************\n",
      "epoch: 252 / 800, time cost: 41.40 sec, \n",
      "          Loss: [Train: p = 0.99605, q = 1.09502], \n",
      "          Loss: [Test: p = 1.02065, q = 1.36922],\n",
      "          Effect: [ate-q], [train: 0.07745], [test: 0.07842]\n",
      "********************************************************************************\n",
      "epoch: 253 / 800, time cost: 42.88 sec, \n",
      "          Loss: [Train: p = 0.99616, q = 1.09497], \n",
      "          Loss: [Test: p = 1.02061, q = 1.37160],\n",
      "          Effect: [ate-q], [train: 0.06245], [test: 0.06353]\n",
      "********************************************************************************\n",
      "epoch: 254 / 800, time cost: 42.32 sec, \n",
      "          Loss: [Train: p = 0.99618, q = 1.09491], \n",
      "          Loss: [Test: p = 1.02062, q = 1.37391],\n",
      "          Effect: [ate-q], [train: 0.05287], [test: 0.05393]\n",
      "********************************************************************************\n",
      "epoch: 255 / 800, time cost: 40.39 sec, \n",
      "          Loss: [Train: p = 0.99624, q = 1.09472], \n",
      "          Loss: [Test: p = 1.02063, q = 1.37330],\n",
      "          Effect: [ate-q], [train: 0.05479], [test: 0.05587]\n",
      "********************************************************************************\n",
      "epoch: 256 / 800, time cost: 40.40 sec, \n",
      "          Loss: [Train: p = 0.99612, q = 1.09482], \n",
      "          Loss: [Test: p = 1.02064, q = 1.37484],\n",
      "          Effect: [ate-q], [train: 0.04618], [test: 0.04723]\n",
      "********************************************************************************\n",
      "epoch: 257 / 800, time cost: 40.22 sec, \n",
      "          Loss: [Train: p = 0.99614, q = 1.09450], \n",
      "          Loss: [Test: p = 1.02061, q = 1.36983],\n",
      "          Effect: [ate-q], [train: 0.09536], [test: 0.09632]\n",
      "********************************************************************************\n",
      "epoch: 258 / 800, time cost: 43.37 sec, \n",
      "          Loss: [Train: p = 0.99614, q = 1.09440], \n",
      "          Loss: [Test: p = 1.02055, q = 1.37136],\n",
      "          Effect: [ate-q], [train: 0.06780], [test: 0.06881]\n",
      "********************************************************************************\n",
      "epoch: 259 / 800, time cost: 43.38 sec, \n",
      "          Loss: [Train: p = 0.99604, q = 1.09454], \n",
      "          Loss: [Test: p = 1.02058, q = 1.37252],\n",
      "          Effect: [ate-q], [train: 0.05868], [test: 0.05970]\n",
      "********************************************************************************\n",
      "epoch: 260 / 800, time cost: 42.51 sec, \n",
      "          Loss: [Train: p = 0.99603, q = 1.09434], \n",
      "          Loss: [Test: p = 1.02053, q = 1.37043],\n",
      "          Effect: [ate-q], [train: 0.07555], [test: 0.07657]\n",
      "********************************************************************************\n",
      "epoch: 261 / 800, time cost: 41.87 sec, \n",
      "          Loss: [Train: p = 0.99600, q = 1.09466], \n",
      "          Loss: [Test: p = 1.02058, q = 1.37309],\n",
      "          Effect: [ate-q], [train: 0.06096], [test: 0.06201]\n",
      "********************************************************************************\n",
      "epoch: 262 / 800, time cost: 40.30 sec, \n",
      "          Loss: [Train: p = 0.99597, q = 1.09411], \n",
      "          Loss: [Test: p = 1.02052, q = 1.37292],\n",
      "          Effect: [ate-q], [train: 0.06112], [test: 0.06214]\n",
      "********************************************************************************\n",
      "epoch: 263 / 800, time cost: 45.98 sec, \n",
      "          Loss: [Train: p = 0.99597, q = 1.09420], \n",
      "          Loss: [Test: p = 1.02059, q = 1.37215],\n",
      "          Effect: [ate-q], [train: 0.06624], [test: 0.06728]\n",
      "********************************************************************************\n",
      "epoch: 264 / 800, time cost: 42.40 sec, \n",
      "          Loss: [Train: p = 0.99592, q = 1.09354], \n",
      "          Loss: [Test: p = 1.02057, q = 1.37333],\n",
      "          Effect: [ate-q], [train: 0.05917], [test: 0.06025]\n",
      "********************************************************************************\n",
      "epoch: 265 / 800, time cost: 39.27 sec, \n",
      "          Loss: [Train: p = 0.99588, q = 1.09364], \n",
      "          Loss: [Test: p = 1.02055, q = 1.37179],\n",
      "          Effect: [ate-q], [train: 0.07009], [test: 0.07109]\n",
      "********************************************************************************\n",
      "epoch: 266 / 800, time cost: 41.43 sec, \n",
      "          Loss: [Train: p = 0.99600, q = 1.09369], \n",
      "          Loss: [Test: p = 1.02052, q = 1.37106],\n",
      "          Effect: [ate-q], [train: 0.07654], [test: 0.07759]\n",
      "********************************************************************************\n",
      "epoch: 267 / 800, time cost: 43.89 sec, \n",
      "          Loss: [Train: p = 0.99576, q = 1.09364], \n",
      "          Loss: [Test: p = 1.02054, q = 1.37029],\n",
      "          Effect: [ate-q], [train: 0.07977], [test: 0.08073]\n",
      "********************************************************************************\n",
      "epoch: 268 / 800, time cost: 43.99 sec, \n",
      "          Loss: [Train: p = 0.99577, q = 1.09347], \n",
      "          Loss: [Test: p = 1.02051, q = 1.37412],\n",
      "          Effect: [ate-q], [train: 0.05489], [test: 0.05604]\n",
      "********************************************************************************\n",
      "epoch: 269 / 800, time cost: 44.61 sec, \n",
      "          Loss: [Train: p = 0.99576, q = 1.09315], \n",
      "          Loss: [Test: p = 1.02054, q = 1.37679],\n",
      "          Effect: [ate-q], [train: 0.04549], [test: 0.04662]\n",
      "********************************************************************************\n",
      "epoch: 270 / 800, time cost: 36.61 sec, \n",
      "          Loss: [Train: p = 0.99574, q = 1.09308], \n",
      "          Loss: [Test: p = 1.02050, q = 1.37299],\n",
      "          Effect: [ate-q], [train: 0.06197], [test: 0.06300]\n",
      "********************************************************************************\n",
      "epoch: 271 / 800, time cost: 38.07 sec, \n",
      "          Loss: [Train: p = 0.99570, q = 1.09312], \n",
      "          Loss: [Test: p = 1.02052, q = 1.37479],\n",
      "          Effect: [ate-q], [train: 0.05304], [test: 0.05412]\n",
      "********************************************************************************\n",
      "epoch: 272 / 800, time cost: 43.00 sec, \n",
      "          Loss: [Train: p = 0.99583, q = 1.09336], \n",
      "          Loss: [Test: p = 1.02052, q = 1.37490],\n",
      "          Effect: [ate-q], [train: 0.05830], [test: 0.05943]\n",
      "********************************************************************************\n",
      "epoch: 273 / 800, time cost: 43.45 sec, \n",
      "          Loss: [Train: p = 0.99576, q = 1.09324], \n",
      "          Loss: [Test: p = 1.02049, q = 1.37382],\n",
      "          Effect: [ate-q], [train: 0.06321], [test: 0.06425]\n",
      "********************************************************************************\n",
      "epoch: 274 / 800, time cost: 41.68 sec, \n",
      "          Loss: [Train: p = 0.99581, q = 1.09332], \n",
      "          Loss: [Test: p = 1.02049, q = 1.37197],\n",
      "          Effect: [ate-q], [train: 0.07367], [test: 0.07472]\n",
      "********************************************************************************\n",
      "epoch: 275 / 800, time cost: 39.76 sec, \n",
      "          Loss: [Train: p = 0.99568, q = 1.09265], \n",
      "          Loss: [Test: p = 1.02052, q = 1.37535],\n",
      "          Effect: [ate-q], [train: 0.05572], [test: 0.05678]\n",
      "********************************************************************************\n",
      "epoch: 276 / 800, time cost: 41.92 sec, \n",
      "          Loss: [Train: p = 0.99567, q = 1.09265], \n",
      "          Loss: [Test: p = 1.02048, q = 1.37376],\n",
      "          Effect: [ate-q], [train: 0.06332], [test: 0.06437]\n",
      "********************************************************************************\n",
      "epoch: 277 / 800, time cost: 40.42 sec, \n",
      "          Loss: [Train: p = 0.99561, q = 1.09294], \n",
      "          Loss: [Test: p = 1.02046, q = 1.37383],\n",
      "          Effect: [ate-q], [train: 0.06493], [test: 0.06600]\n",
      "********************************************************************************\n",
      "epoch: 278 / 800, time cost: 42.57 sec, \n",
      "          Loss: [Train: p = 0.99552, q = 1.09271], \n",
      "          Loss: [Test: p = 1.02044, q = 1.37257],\n",
      "          Effect: [ate-q], [train: 0.07164], [test: 0.07265]\n",
      "********************************************************************************\n",
      "epoch: 279 / 800, time cost: 43.21 sec, \n",
      "          Loss: [Train: p = 0.99562, q = 1.09225], \n",
      "          Loss: [Test: p = 1.02043, q = 1.37434],\n",
      "          Effect: [ate-q], [train: 0.06323], [test: 0.06430]\n",
      "********************************************************************************\n",
      "epoch: 280 / 800, time cost: 41.03 sec, \n",
      "          Loss: [Train: p = 0.99548, q = 1.09241], \n",
      "          Loss: [Test: p = 1.02043, q = 1.37454],\n",
      "          Effect: [ate-q], [train: 0.05936], [test: 0.06042]\n",
      "********************************************************************************\n",
      "epoch: 281 / 800, time cost: 40.72 sec, \n",
      "          Loss: [Train: p = 0.99548, q = 1.09246], \n",
      "          Loss: [Test: p = 1.02047, q = 1.37493],\n",
      "          Effect: [ate-q], [train: 0.05857], [test: 0.05961]\n",
      "********************************************************************************\n",
      "epoch: 282 / 800, time cost: 42.88 sec, \n",
      "          Loss: [Train: p = 0.99554, q = 1.09229], \n",
      "          Loss: [Test: p = 1.02042, q = 1.37298],\n",
      "          Effect: [ate-q], [train: 0.07297], [test: 0.07399]\n",
      "********************************************************************************\n",
      "epoch: 283 / 800, time cost: 43.64 sec, \n",
      "          Loss: [Train: p = 0.99541, q = 1.09241], \n",
      "          Loss: [Test: p = 1.02044, q = 1.37377],\n",
      "          Effect: [ate-q], [train: 0.07152], [test: 0.07257]\n",
      "********************************************************************************\n",
      "epoch: 284 / 800, time cost: 40.82 sec, \n",
      "          Loss: [Train: p = 0.99545, q = 1.09225], \n",
      "          Loss: [Test: p = 1.02046, q = 1.37441],\n",
      "          Effect: [ate-q], [train: 0.06128], [test: 0.06238]\n",
      "********************************************************************************\n",
      "epoch: 285 / 800, time cost: 41.30 sec, \n",
      "          Loss: [Train: p = 0.99538, q = 1.09222], \n",
      "          Loss: [Test: p = 1.02041, q = 1.37279],\n",
      "          Effect: [ate-q], [train: 0.07717], [test: 0.07818]\n",
      "********************************************************************************\n",
      "epoch: 286 / 800, time cost: 40.09 sec, \n",
      "          Loss: [Train: p = 0.99546, q = 1.09199], \n",
      "          Loss: [Test: p = 1.02047, q = 1.37507],\n",
      "          Effect: [ate-q], [train: 0.06349], [test: 0.06455]\n",
      "********************************************************************************\n",
      "epoch: 287 / 800, time cost: 45.20 sec, \n",
      "          Loss: [Train: p = 0.99538, q = 1.09225], \n",
      "          Loss: [Test: p = 1.02043, q = 1.37339],\n",
      "          Effect: [ate-q], [train: 0.07358], [test: 0.07455]\n",
      "********************************************************************************\n",
      "epoch: 288 / 800, time cost: 45.53 sec, \n",
      "          Loss: [Train: p = 0.99530, q = 1.09209], \n",
      "          Loss: [Test: p = 1.02042, q = 1.37463],\n",
      "          Effect: [ate-q], [train: 0.06257], [test: 0.06361]\n",
      "********************************************************************************\n",
      "epoch: 289 / 800, time cost: 39.88 sec, \n",
      "          Loss: [Train: p = 0.99531, q = 1.09129], \n",
      "          Loss: [Test: p = 1.02041, q = 1.37474],\n",
      "          Effect: [ate-q], [train: 0.06048], [test: 0.06154]\n",
      "********************************************************************************\n",
      "epoch: 290 / 800, time cost: 39.96 sec, \n",
      "          Loss: [Train: p = 0.99539, q = 1.09175], \n",
      "          Loss: [Test: p = 1.02039, q = 1.37507],\n",
      "          Effect: [ate-q], [train: 0.06064], [test: 0.06171]\n",
      "********************************************************************************\n",
      "epoch: 291 / 800, time cost: 44.32 sec, \n",
      "          Loss: [Train: p = 0.99532, q = 1.09167], \n",
      "          Loss: [Test: p = 1.02041, q = 1.37562],\n",
      "          Effect: [ate-q], [train: 0.06349], [test: 0.06450]\n",
      "********************************************************************************\n",
      "epoch: 292 / 800, time cost: 48.65 sec, \n",
      "          Loss: [Train: p = 0.99514, q = 1.09145], \n",
      "          Loss: [Test: p = 1.02037, q = 1.37668],\n",
      "          Effect: [ate-q], [train: 0.05527], [test: 0.05632]\n",
      "********************************************************************************\n",
      "epoch: 293 / 800, time cost: 41.64 sec, \n",
      "          Loss: [Train: p = 0.99526, q = 1.09113], \n",
      "          Loss: [Test: p = 1.02038, q = 1.37396],\n",
      "          Effect: [ate-q], [train: 0.07711], [test: 0.07813]\n",
      "********************************************************************************\n",
      "epoch: 294 / 800, time cost: 46.91 sec, \n",
      "          Loss: [Train: p = 0.99535, q = 1.09110], \n",
      "          Loss: [Test: p = 1.02037, q = 1.37348],\n",
      "          Effect: [ate-q], [train: 0.08329], [test: 0.08423]\n",
      "********************************************************************************\n",
      "epoch: 295 / 800, time cost: 45.71 sec, \n",
      "          Loss: [Train: p = 0.99512, q = 1.09126], \n",
      "          Loss: [Test: p = 1.02035, q = 1.37617],\n",
      "          Effect: [ate-q], [train: 0.06337], [test: 0.06437]\n",
      "********************************************************************************\n",
      "epoch: 296 / 800, time cost: 43.71 sec, \n",
      "          Loss: [Train: p = 0.99514, q = 1.09085], \n",
      "          Loss: [Test: p = 1.02036, q = 1.37707],\n",
      "          Effect: [ate-q], [train: 0.06025], [test: 0.06133]\n",
      "********************************************************************************\n",
      "epoch: 297 / 800, time cost: 43.66 sec, \n",
      "          Loss: [Train: p = 0.99510, q = 1.09129], \n",
      "          Loss: [Test: p = 1.02033, q = 1.37629],\n",
      "          Effect: [ate-q], [train: 0.06002], [test: 0.06105]\n",
      "********************************************************************************\n",
      "epoch: 298 / 800, time cost: 42.56 sec, \n",
      "          Loss: [Train: p = 0.99513, q = 1.09124], \n",
      "          Loss: [Test: p = 1.02034, q = 1.37588],\n",
      "          Effect: [ate-q], [train: 0.06295], [test: 0.06395]\n",
      "********************************************************************************\n",
      "epoch: 299 / 800, time cost: 39.96 sec, \n",
      "          Loss: [Train: p = 0.99506, q = 1.09086], \n",
      "          Loss: [Test: p = 1.02040, q = 1.37629],\n",
      "          Effect: [ate-q], [train: 0.06283], [test: 0.06385]\n",
      "********************************************************************************\n",
      "epoch: 300 / 800, time cost: 42.31 sec, \n",
      "          Loss: [Train: p = 0.99510, q = 1.09049], \n",
      "          Loss: [Test: p = 1.02034, q = 1.37519],\n",
      "          Effect: [ate-q], [train: 0.07138], [test: 0.07239]\n",
      "********************************************************************************\n",
      "epoch: 301 / 800, time cost: 46.72 sec, \n",
      "          Loss: [Train: p = 0.99493, q = 1.09065], \n",
      "          Loss: [Test: p = 1.02033, q = 1.37542],\n",
      "          Effect: [ate-q], [train: 0.07247], [test: 0.07346]\n",
      "********************************************************************************\n",
      "epoch: 302 / 800, time cost: 44.62 sec, \n",
      "          Loss: [Train: p = 0.99502, q = 1.09049], \n",
      "          Loss: [Test: p = 1.02033, q = 1.38185],\n",
      "          Effect: [ate-q], [train: 0.03787], [test: 0.03898]\n",
      "********************************************************************************\n",
      "epoch: 303 / 800, time cost: 42.43 sec, \n",
      "          Loss: [Train: p = 0.99499, q = 1.09003], \n",
      "          Loss: [Test: p = 1.02031, q = 1.37690],\n",
      "          Effect: [ate-q], [train: 0.06285], [test: 0.06386]\n",
      "********************************************************************************\n",
      "epoch: 304 / 800, time cost: 40.26 sec, \n",
      "          Loss: [Train: p = 0.99492, q = 1.09052], \n",
      "          Loss: [Test: p = 1.02032, q = 1.37693],\n",
      "          Effect: [ate-q], [train: 0.06270], [test: 0.06374]\n",
      "********************************************************************************\n",
      "epoch: 305 / 800, time cost: 47.01 sec, \n",
      "          Loss: [Train: p = 0.99495, q = 1.09036], \n",
      "          Loss: [Test: p = 1.02028, q = 1.37574],\n",
      "          Effect: [ate-q], [train: 0.07112], [test: 0.07212]\n",
      "********************************************************************************\n",
      "epoch: 306 / 800, time cost: 49.47 sec, \n",
      "          Loss: [Train: p = 0.99493, q = 1.09054], \n",
      "          Loss: [Test: p = 1.02031, q = 1.37491],\n",
      "          Effect: [ate-q], [train: 0.07747], [test: 0.07842]\n",
      "********************************************************************************\n",
      "epoch: 307 / 800, time cost: 43.11 sec, \n",
      "          Loss: [Train: p = 0.99473, q = 1.09031], \n",
      "          Loss: [Test: p = 1.02028, q = 1.37673],\n",
      "          Effect: [ate-q], [train: 0.06109], [test: 0.06213]\n",
      "********************************************************************************\n",
      "epoch: 308 / 800, time cost: 41.75 sec, \n",
      "          Loss: [Train: p = 0.99481, q = 1.09053], \n",
      "          Loss: [Test: p = 1.02030, q = 1.37819],\n",
      "          Effect: [ate-q], [train: 0.05677], [test: 0.05784]\n",
      "********************************************************************************\n",
      "epoch: 309 / 800, time cost: 41.26 sec, \n",
      "          Loss: [Train: p = 0.99469, q = 1.09007], \n",
      "          Loss: [Test: p = 1.02027, q = 1.37481],\n",
      "          Effect: [ate-q], [train: 0.07871], [test: 0.07963]\n",
      "********************************************************************************\n",
      "epoch: 310 / 800, time cost: 41.13 sec, \n",
      "          Loss: [Train: p = 0.99473, q = 1.09005], \n",
      "          Loss: [Test: p = 1.02028, q = 1.38057],\n",
      "          Effect: [ate-q], [train: 0.04508], [test: 0.04618]\n",
      "********************************************************************************\n",
      "epoch: 311 / 800, time cost: 40.20 sec, \n",
      "          Loss: [Train: p = 0.99476, q = 1.08976], \n",
      "          Loss: [Test: p = 1.02026, q = 1.37704],\n",
      "          Effect: [ate-q], [train: 0.06662], [test: 0.06761]\n",
      "********************************************************************************\n",
      "epoch: 312 / 800, time cost: 46.54 sec, \n",
      "          Loss: [Train: p = 0.99482, q = 1.08984], \n",
      "          Loss: [Test: p = 1.02025, q = 1.37749],\n",
      "          Effect: [ate-q], [train: 0.06156], [test: 0.06262]\n",
      "********************************************************************************\n",
      "epoch: 313 / 800, time cost: 47.97 sec, \n",
      "          Loss: [Train: p = 0.99470, q = 1.08973], \n",
      "          Loss: [Test: p = 1.02027, q = 1.38022],\n",
      "          Effect: [ate-q], [train: 0.04749], [test: 0.04854]\n",
      "********************************************************************************\n",
      "epoch: 314 / 800, time cost: 43.70 sec, \n",
      "          Loss: [Train: p = 0.99465, q = 1.08931], \n",
      "          Loss: [Test: p = 1.02026, q = 1.37861],\n",
      "          Effect: [ate-q], [train: 0.05993], [test: 0.06089]\n",
      "********************************************************************************\n",
      "epoch: 315 / 800, time cost: 40.86 sec, \n",
      "          Loss: [Train: p = 0.99466, q = 1.08938], \n",
      "          Loss: [Test: p = 1.02023, q = 1.37614],\n",
      "          Effect: [ate-q], [train: 0.06813], [test: 0.06915]\n",
      "********************************************************************************\n",
      "epoch: 316 / 800, time cost: 41.53 sec, \n",
      "          Loss: [Train: p = 0.99475, q = 1.08929], \n",
      "          Loss: [Test: p = 1.02025, q = 1.37816],\n",
      "          Effect: [ate-q], [train: 0.05973], [test: 0.06078]\n",
      "********************************************************************************\n",
      "epoch: 317 / 800, time cost: 42.82 sec, \n",
      "          Loss: [Train: p = 0.99464, q = 1.08951], \n",
      "          Loss: [Test: p = 1.02023, q = 1.37940],\n",
      "          Effect: [ate-q], [train: 0.05430], [test: 0.05536]\n",
      "********************************************************************************\n",
      "epoch: 318 / 800, time cost: 41.74 sec, \n",
      "          Loss: [Train: p = 0.99464, q = 1.08948], \n",
      "          Loss: [Test: p = 1.02019, q = 1.37677],\n",
      "          Effect: [ate-q], [train: 0.07482], [test: 0.07575]\n",
      "********************************************************************************\n",
      "epoch: 319 / 800, time cost: 40.32 sec, \n",
      "          Loss: [Train: p = 0.99446, q = 1.08966], \n",
      "          Loss: [Test: p = 1.02020, q = 1.37663],\n",
      "          Effect: [ate-q], [train: 0.07607], [test: 0.07703]\n",
      "********************************************************************************\n",
      "epoch: 320 / 800, time cost: 44.37 sec, \n",
      "          Loss: [Train: p = 0.99455, q = 1.08864], \n",
      "          Loss: [Test: p = 1.02022, q = 1.37721],\n",
      "          Effect: [ate-q], [train: 0.06961], [test: 0.07058]\n",
      "********************************************************************************\n",
      "epoch: 321 / 800, time cost: 41.39 sec, \n",
      "          Loss: [Train: p = 0.99451, q = 1.08895], \n",
      "          Loss: [Test: p = 1.02021, q = 1.37816],\n",
      "          Effect: [ate-q], [train: 0.06457], [test: 0.06555]\n",
      "********************************************************************************\n",
      "epoch: 322 / 800, time cost: 44.20 sec, \n",
      "          Loss: [Train: p = 0.99455, q = 1.08895], \n",
      "          Loss: [Test: p = 1.02020, q = 1.38101],\n",
      "          Effect: [ate-q], [train: 0.04931], [test: 0.05045]\n",
      "********************************************************************************\n",
      "epoch: 323 / 800, time cost: 40.55 sec, \n",
      "          Loss: [Train: p = 0.99455, q = 1.08897], \n",
      "          Loss: [Test: p = 1.02017, q = 1.38172],\n",
      "          Effect: [ate-q], [train: 0.04752], [test: 0.04855]\n",
      "********************************************************************************\n",
      "epoch: 324 / 800, time cost: 41.54 sec, \n",
      "          Loss: [Train: p = 0.99444, q = 1.08905], \n",
      "          Loss: [Test: p = 1.02020, q = 1.37783],\n",
      "          Effect: [ate-q], [train: 0.06695], [test: 0.06794]\n",
      "********************************************************************************\n",
      "epoch: 325 / 800, time cost: 40.92 sec, \n",
      "          Loss: [Train: p = 0.99439, q = 1.08827], \n",
      "          Loss: [Test: p = 1.02017, q = 1.37769],\n",
      "          Effect: [ate-q], [train: 0.07107], [test: 0.07201]\n",
      "********************************************************************************\n",
      "epoch: 326 / 800, time cost: 43.63 sec, \n",
      "          Loss: [Train: p = 0.99438, q = 1.08843], \n",
      "          Loss: [Test: p = 1.02022, q = 1.37653],\n",
      "          Effect: [ate-q], [train: 0.08305], [test: 0.08398]\n",
      "********************************************************************************\n",
      "epoch: 327 / 800, time cost: 35.39 sec, \n",
      "          Loss: [Train: p = 0.99431, q = 1.08838], \n",
      "          Loss: [Test: p = 1.02018, q = 1.38003],\n",
      "          Effect: [ate-q], [train: 0.05437], [test: 0.05534]\n",
      "********************************************************************************\n",
      "epoch: 328 / 800, time cost: 42.23 sec, \n",
      "          Loss: [Train: p = 0.99429, q = 1.08832], \n",
      "          Loss: [Test: p = 1.02016, q = 1.38107],\n",
      "          Effect: [ate-q], [train: 0.05539], [test: 0.05648]\n",
      "********************************************************************************\n",
      "epoch: 329 / 800, time cost: 44.96 sec, \n",
      "          Loss: [Train: p = 0.99437, q = 1.08843], \n",
      "          Loss: [Test: p = 1.02017, q = 1.37867],\n",
      "          Effect: [ate-q], [train: 0.06646], [test: 0.06744]\n",
      "********************************************************************************\n",
      "epoch: 330 / 800, time cost: 44.50 sec, \n",
      "          Loss: [Train: p = 0.99429, q = 1.08806], \n",
      "          Loss: [Test: p = 1.02015, q = 1.37896],\n",
      "          Effect: [ate-q], [train: 0.06710], [test: 0.06817]\n",
      "********************************************************************************\n",
      "epoch: 331 / 800, time cost: 47.83 sec, \n",
      "          Loss: [Train: p = 0.99420, q = 1.08840], \n",
      "          Loss: [Test: p = 1.02013, q = 1.38222],\n",
      "          Effect: [ate-q], [train: 0.04853], [test: 0.04956]\n",
      "********************************************************************************\n",
      "epoch: 332 / 800, time cost: 44.57 sec, \n",
      "          Loss: [Train: p = 0.99419, q = 1.08782], \n",
      "          Loss: [Test: p = 1.02014, q = 1.37757],\n",
      "          Effect: [ate-q], [train: 0.07266], [test: 0.07361]\n",
      "********************************************************************************\n",
      "epoch: 333 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.99423, q = 1.08823], \n",
      "          Loss: [Test: p = 1.02013, q = 1.38076],\n",
      "          Effect: [ate-q], [train: 0.05546], [test: 0.05644]\n",
      "********************************************************************************\n",
      "epoch: 334 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.99421, q = 1.08786], \n",
      "          Loss: [Test: p = 1.02018, q = 1.38218],\n",
      "          Effect: [ate-q], [train: 0.04965], [test: 0.05069]\n",
      "********************************************************************************\n",
      "epoch: 335 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.99406, q = 1.08796], \n",
      "          Loss: [Test: p = 1.02011, q = 1.37808],\n",
      "          Effect: [ate-q], [train: 0.06813], [test: 0.06913]\n",
      "********************************************************************************\n",
      "epoch: 336 / 800, time cost: 40.72 sec, \n",
      "          Loss: [Train: p = 0.99415, q = 1.08793], \n",
      "          Loss: [Test: p = 1.02011, q = 1.38028],\n",
      "          Effect: [ate-q], [train: 0.05877], [test: 0.05980]\n",
      "********************************************************************************\n",
      "epoch: 337 / 800, time cost: 37.14 sec, \n",
      "          Loss: [Train: p = 0.99411, q = 1.08756], \n",
      "          Loss: [Test: p = 1.02014, q = 1.38088],\n",
      "          Effect: [ate-q], [train: 0.05592], [test: 0.05688]\n",
      "********************************************************************************\n",
      "epoch: 338 / 800, time cost: 38.21 sec, \n",
      "          Loss: [Train: p = 0.99417, q = 1.08791], \n",
      "          Loss: [Test: p = 1.02011, q = 1.37976],\n",
      "          Effect: [ate-q], [train: 0.06066], [test: 0.06160]\n",
      "********************************************************************************\n",
      "epoch: 339 / 800, time cost: 38.20 sec, \n",
      "          Loss: [Train: p = 0.99415, q = 1.08788], \n",
      "          Loss: [Test: p = 1.02013, q = 1.38005],\n",
      "          Effect: [ate-q], [train: 0.06443], [test: 0.06538]\n",
      "********************************************************************************\n",
      "epoch: 340 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.99411, q = 1.08758], \n",
      "          Loss: [Test: p = 1.02006, q = 1.37847],\n",
      "          Effect: [ate-q], [train: 0.07237], [test: 0.07334]\n",
      "********************************************************************************\n",
      "epoch: 341 / 800, time cost: 40.23 sec, \n",
      "          Loss: [Train: p = 0.99406, q = 1.08720], \n",
      "          Loss: [Test: p = 1.02011, q = 1.38006],\n",
      "          Effect: [ate-q], [train: 0.06154], [test: 0.06253]\n",
      "********************************************************************************\n",
      "epoch: 342 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.99411, q = 1.08723], \n",
      "          Loss: [Test: p = 1.02011, q = 1.38088],\n",
      "          Effect: [ate-q], [train: 0.06679], [test: 0.06780]\n",
      "********************************************************************************\n",
      "epoch: 343 / 800, time cost: 38.54 sec, \n",
      "          Loss: [Train: p = 0.99396, q = 1.08755], \n",
      "          Loss: [Test: p = 1.02011, q = 1.37998],\n",
      "          Effect: [ate-q], [train: 0.06423], [test: 0.06525]\n",
      "********************************************************************************\n",
      "epoch: 344 / 800, time cost: 37.86 sec, \n",
      "          Loss: [Train: p = 0.99396, q = 1.08727], \n",
      "          Loss: [Test: p = 1.02011, q = 1.37852],\n",
      "          Effect: [ate-q], [train: 0.07369], [test: 0.07471]\n",
      "********************************************************************************\n",
      "epoch: 345 / 800, time cost: 38.54 sec, \n",
      "          Loss: [Train: p = 0.99388, q = 1.08723], \n",
      "          Loss: [Test: p = 1.02010, q = 1.38011],\n",
      "          Effect: [ate-q], [train: 0.06795], [test: 0.06892]\n",
      "********************************************************************************\n",
      "epoch: 346 / 800, time cost: 40.64 sec, \n",
      "          Loss: [Train: p = 0.99394, q = 1.08704], \n",
      "          Loss: [Test: p = 1.02007, q = 1.37937],\n",
      "          Effect: [ate-q], [train: 0.06551], [test: 0.06647]\n",
      "********************************************************************************\n",
      "epoch: 347 / 800, time cost: 38.20 sec, \n",
      "          Loss: [Train: p = 0.99382, q = 1.08682], \n",
      "          Loss: [Test: p = 1.02006, q = 1.38194],\n",
      "          Effect: [ate-q], [train: 0.05804], [test: 0.05904]\n",
      "********************************************************************************\n",
      "epoch: 348 / 800, time cost: 37.76 sec, \n",
      "          Loss: [Train: p = 0.99381, q = 1.08645], \n",
      "          Loss: [Test: p = 1.02007, q = 1.38311],\n",
      "          Effect: [ate-q], [train: 0.05310], [test: 0.05419]\n",
      "********************************************************************************\n",
      "epoch: 349 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.99381, q = 1.08703], \n",
      "          Loss: [Test: p = 1.02004, q = 1.38229],\n",
      "          Effect: [ate-q], [train: 0.05711], [test: 0.05806]\n",
      "********************************************************************************\n",
      "epoch: 350 / 800, time cost: 38.55 sec, \n",
      "          Loss: [Train: p = 0.99381, q = 1.08648], \n",
      "          Loss: [Test: p = 1.02008, q = 1.38121],\n",
      "          Effect: [ate-q], [train: 0.06181], [test: 0.06280]\n",
      "********************************************************************************\n",
      "epoch: 351 / 800, time cost: 40.63 sec, \n",
      "          Loss: [Train: p = 0.99393, q = 1.08699], \n",
      "          Loss: [Test: p = 1.02005, q = 1.38110],\n",
      "          Effect: [ate-q], [train: 0.06438], [test: 0.06539]\n",
      "********************************************************************************\n",
      "epoch: 352 / 800, time cost: 37.35 sec, \n",
      "          Loss: [Train: p = 0.99374, q = 1.08623], \n",
      "          Loss: [Test: p = 1.02004, q = 1.38181],\n",
      "          Effect: [ate-q], [train: 0.05868], [test: 0.05963]\n",
      "********************************************************************************\n",
      "epoch: 353 / 800, time cost: 38.28 sec, \n",
      "          Loss: [Train: p = 0.99370, q = 1.08633], \n",
      "          Loss: [Test: p = 1.02004, q = 1.38194],\n",
      "          Effect: [ate-q], [train: 0.06126], [test: 0.06226]\n",
      "********************************************************************************\n",
      "epoch: 354 / 800, time cost: 38.17 sec, \n",
      "          Loss: [Train: p = 0.99373, q = 1.08648], \n",
      "          Loss: [Test: p = 1.02004, q = 1.37976],\n",
      "          Effect: [ate-q], [train: 0.07808], [test: 0.07903]\n",
      "********************************************************************************\n",
      "epoch: 355 / 800, time cost: 37.78 sec, \n",
      "          Loss: [Train: p = 0.99368, q = 1.08620], \n",
      "          Loss: [Test: p = 1.02006, q = 1.38598],\n",
      "          Effect: [ate-q], [train: 0.04289], [test: 0.04398]\n",
      "********************************************************************************\n",
      "epoch: 356 / 800, time cost: 40.09 sec, \n",
      "          Loss: [Train: p = 0.99369, q = 1.08632], \n",
      "          Loss: [Test: p = 1.02003, q = 1.38217],\n",
      "          Effect: [ate-q], [train: 0.06183], [test: 0.06278]\n",
      "********************************************************************************\n",
      "epoch: 357 / 800, time cost: 38.17 sec, \n",
      "          Loss: [Train: p = 0.99377, q = 1.08578], \n",
      "          Loss: [Test: p = 1.02001, q = 1.38038],\n",
      "          Effect: [ate-q], [train: 0.06973], [test: 0.07068]\n",
      "********************************************************************************\n",
      "epoch: 358 / 800, time cost: 38.17 sec, \n",
      "          Loss: [Train: p = 0.99363, q = 1.08635], \n",
      "          Loss: [Test: p = 1.02001, q = 1.38155],\n",
      "          Effect: [ate-q], [train: 0.06262], [test: 0.06360]\n",
      "********************************************************************************\n",
      "epoch: 359 / 800, time cost: 37.98 sec, \n",
      "          Loss: [Train: p = 0.99370, q = 1.08627], \n",
      "          Loss: [Test: p = 1.02002, q = 1.38084],\n",
      "          Effect: [ate-q], [train: 0.06905], [test: 0.06997]\n",
      "********************************************************************************\n",
      "epoch: 360 / 800, time cost: 40.37 sec, \n",
      "          Loss: [Train: p = 0.99359, q = 1.08598], \n",
      "          Loss: [Test: p = 1.02001, q = 1.38534],\n",
      "          Effect: [ate-q], [train: 0.04751], [test: 0.04855]\n",
      "********************************************************************************\n",
      "epoch: 361 / 800, time cost: 38.04 sec, \n",
      "          Loss: [Train: p = 0.99355, q = 1.08569], \n",
      "          Loss: [Test: p = 1.01998, q = 1.38225],\n",
      "          Effect: [ate-q], [train: 0.06165], [test: 0.06259]\n",
      "********************************************************************************\n",
      "epoch: 362 / 800, time cost: 38.27 sec, \n",
      "          Loss: [Train: p = 0.99357, q = 1.08580], \n",
      "          Loss: [Test: p = 1.01996, q = 1.38720],\n",
      "          Effect: [ate-q], [train: 0.03839], [test: 0.03947]\n",
      "********************************************************************************\n",
      "epoch: 363 / 800, time cost: 37.99 sec, \n",
      "          Loss: [Train: p = 0.99347, q = 1.08603], \n",
      "          Loss: [Test: p = 1.02001, q = 1.38099],\n",
      "          Effect: [ate-q], [train: 0.07396], [test: 0.07486]\n",
      "********************************************************************************\n",
      "epoch: 364 / 800, time cost: 37.76 sec, \n",
      "          Loss: [Train: p = 0.99360, q = 1.08558], \n",
      "          Loss: [Test: p = 1.02002, q = 1.38314],\n",
      "          Effect: [ate-q], [train: 0.05791], [test: 0.05894]\n",
      "********************************************************************************\n",
      "epoch: 365 / 800, time cost: 41.13 sec, \n",
      "          Loss: [Train: p = 0.99352, q = 1.08549], \n",
      "          Loss: [Test: p = 1.02000, q = 1.38041],\n",
      "          Effect: [ate-q], [train: 0.07538], [test: 0.07632]\n",
      "********************************************************************************\n",
      "epoch: 366 / 800, time cost: 45.05 sec, \n",
      "          Loss: [Train: p = 0.99339, q = 1.08563], \n",
      "          Loss: [Test: p = 1.01993, q = 1.38492],\n",
      "          Effect: [ate-q], [train: 0.05199], [test: 0.05305]\n",
      "********************************************************************************\n",
      "epoch: 367 / 800, time cost: 38.28 sec, \n",
      "          Loss: [Train: p = 0.99337, q = 1.08479], \n",
      "          Loss: [Test: p = 1.01997, q = 1.38131],\n",
      "          Effect: [ate-q], [train: 0.07241], [test: 0.07336]\n",
      "********************************************************************************\n",
      "epoch: 368 / 800, time cost: 38.26 sec, \n",
      "          Loss: [Train: p = 0.99348, q = 1.08574], \n",
      "          Loss: [Test: p = 1.01996, q = 1.38149],\n",
      "          Effect: [ate-q], [train: 0.07519], [test: 0.07612]\n",
      "********************************************************************************\n",
      "epoch: 369 / 800, time cost: 38.75 sec, \n",
      "          Loss: [Train: p = 0.99331, q = 1.08496], \n",
      "          Loss: [Test: p = 1.01997, q = 1.38193],\n",
      "          Effect: [ate-q], [train: 0.06385], [test: 0.06491]\n",
      "********************************************************************************\n",
      "epoch: 370 / 800, time cost: 40.80 sec, \n",
      "          Loss: [Train: p = 0.99339, q = 1.08453], \n",
      "          Loss: [Test: p = 1.01992, q = 1.38337],\n",
      "          Effect: [ate-q], [train: 0.06022], [test: 0.06120]\n",
      "********************************************************************************\n",
      "epoch: 371 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.99330, q = 1.08509], \n",
      "          Loss: [Test: p = 1.01996, q = 1.38140],\n",
      "          Effect: [ate-q], [train: 0.07490], [test: 0.07582]\n",
      "********************************************************************************\n",
      "epoch: 372 / 800, time cost: 37.54 sec, \n",
      "          Loss: [Train: p = 0.99333, q = 1.08505], \n",
      "          Loss: [Test: p = 1.01996, q = 1.38542],\n",
      "          Effect: [ate-q], [train: 0.05254], [test: 0.05352]\n",
      "********************************************************************************\n",
      "epoch: 373 / 800, time cost: 38.41 sec, \n",
      "          Loss: [Train: p = 0.99324, q = 1.08522], \n",
      "          Loss: [Test: p = 1.01997, q = 1.38194],\n",
      "          Effect: [ate-q], [train: 0.07275], [test: 0.07370]\n",
      "********************************************************************************\n",
      "epoch: 374 / 800, time cost: 38.45 sec, \n",
      "          Loss: [Train: p = 0.99325, q = 1.08494], \n",
      "          Loss: [Test: p = 1.01995, q = 1.38537],\n",
      "          Effect: [ate-q], [train: 0.05389], [test: 0.05487]\n",
      "********************************************************************************\n",
      "epoch: 375 / 800, time cost: 40.75 sec, \n",
      "          Loss: [Train: p = 0.99325, q = 1.08447], \n",
      "          Loss: [Test: p = 1.01995, q = 1.38190],\n",
      "          Effect: [ate-q], [train: 0.07220], [test: 0.07316]\n",
      "********************************************************************************\n",
      "epoch: 376 / 800, time cost: 37.32 sec, \n",
      "          Loss: [Train: p = 0.99318, q = 1.08496], \n",
      "          Loss: [Test: p = 1.01995, q = 1.38418],\n",
      "          Effect: [ate-q], [train: 0.05845], [test: 0.05939]\n",
      "********************************************************************************\n",
      "epoch: 377 / 800, time cost: 38.34 sec, \n",
      "          Loss: [Train: p = 0.99321, q = 1.08459], \n",
      "          Loss: [Test: p = 1.01993, q = 1.38276],\n",
      "          Effect: [ate-q], [train: 0.07290], [test: 0.07382]\n",
      "********************************************************************************\n",
      "epoch: 378 / 800, time cost: 38.23 sec, \n",
      "          Loss: [Train: p = 0.99317, q = 1.08485], \n",
      "          Loss: [Test: p = 1.01986, q = 1.38476],\n",
      "          Effect: [ate-q], [train: 0.05842], [test: 0.05946]\n",
      "********************************************************************************\n",
      "epoch: 379 / 800, time cost: 42.41 sec, \n",
      "          Loss: [Train: p = 0.99308, q = 1.08402], \n",
      "          Loss: [Test: p = 1.01994, q = 1.38378],\n",
      "          Effect: [ate-q], [train: 0.06510], [test: 0.06604]\n",
      "********************************************************************************\n",
      "epoch: 380 / 800, time cost: 47.76 sec, \n",
      "          Loss: [Train: p = 0.99317, q = 1.08453], \n",
      "          Loss: [Test: p = 1.01989, q = 1.38378],\n",
      "          Effect: [ate-q], [train: 0.06312], [test: 0.06409]\n",
      "********************************************************************************\n",
      "epoch: 381 / 800, time cost: 43.44 sec, \n",
      "          Loss: [Train: p = 0.99312, q = 1.08427], \n",
      "          Loss: [Test: p = 1.01993, q = 1.38387],\n",
      "          Effect: [ate-q], [train: 0.06589], [test: 0.06680]\n",
      "********************************************************************************\n",
      "epoch: 382 / 800, time cost: 38.25 sec, \n",
      "          Loss: [Train: p = 0.99303, q = 1.08400], \n",
      "          Loss: [Test: p = 1.01991, q = 1.38487],\n",
      "          Effect: [ate-q], [train: 0.05900], [test: 0.05996]\n",
      "********************************************************************************\n",
      "epoch: 383 / 800, time cost: 38.41 sec, \n",
      "          Loss: [Train: p = 0.99299, q = 1.08400], \n",
      "          Loss: [Test: p = 1.01991, q = 1.38471],\n",
      "          Effect: [ate-q], [train: 0.06111], [test: 0.06206]\n",
      "********************************************************************************\n",
      "epoch: 384 / 800, time cost: 38.37 sec, \n",
      "          Loss: [Train: p = 0.99303, q = 1.08422], \n",
      "          Loss: [Test: p = 1.01984, q = 1.38683],\n",
      "          Effect: [ate-q], [train: 0.04849], [test: 0.04952]\n",
      "********************************************************************************\n",
      "epoch: 385 / 800, time cost: 40.34 sec, \n",
      "          Loss: [Train: p = 0.99300, q = 1.08385], \n",
      "          Loss: [Test: p = 1.01991, q = 1.38719],\n",
      "          Effect: [ate-q], [train: 0.04801], [test: 0.04897]\n",
      "********************************************************************************\n",
      "epoch: 386 / 800, time cost: 38.25 sec, \n",
      "          Loss: [Train: p = 0.99293, q = 1.08419], \n",
      "          Loss: [Test: p = 1.01983, q = 1.38236],\n",
      "          Effect: [ate-q], [train: 0.08438], [test: 0.08523]\n",
      "********************************************************************************\n",
      "epoch: 387 / 800, time cost: 38.33 sec, \n",
      "          Loss: [Train: p = 0.99288, q = 1.08371], \n",
      "          Loss: [Test: p = 1.01989, q = 1.38859],\n",
      "          Effect: [ate-q], [train: 0.04372], [test: 0.04473]\n",
      "********************************************************************************\n",
      "epoch: 388 / 800, time cost: 38.03 sec, \n",
      "          Loss: [Train: p = 0.99292, q = 1.08388], \n",
      "          Loss: [Test: p = 1.01983, q = 1.38536],\n",
      "          Effect: [ate-q], [train: 0.06048], [test: 0.06151]\n",
      "********************************************************************************\n",
      "epoch: 389 / 800, time cost: 37.81 sec, \n",
      "          Loss: [Train: p = 0.99287, q = 1.08418], \n",
      "          Loss: [Test: p = 1.01988, q = 1.38435],\n",
      "          Effect: [ate-q], [train: 0.06728], [test: 0.06819]\n",
      "********************************************************************************\n",
      "epoch: 390 / 800, time cost: 40.26 sec, \n",
      "          Loss: [Train: p = 0.99285, q = 1.08377], \n",
      "          Loss: [Test: p = 1.01983, q = 1.38274],\n",
      "          Effect: [ate-q], [train: 0.08085], [test: 0.08176]\n",
      "********************************************************************************\n",
      "epoch: 391 / 800, time cost: 37.75 sec, \n",
      "          Loss: [Train: p = 0.99281, q = 1.08389], \n",
      "          Loss: [Test: p = 1.01983, q = 1.38415],\n",
      "          Effect: [ate-q], [train: 0.06715], [test: 0.06809]\n",
      "********************************************************************************\n",
      "epoch: 392 / 800, time cost: 38.12 sec, \n",
      "          Loss: [Train: p = 0.99280, q = 1.08353], \n",
      "          Loss: [Test: p = 1.01988, q = 1.38478],\n",
      "          Effect: [ate-q], [train: 0.06513], [test: 0.06608]\n",
      "********************************************************************************\n",
      "epoch: 393 / 800, time cost: 38.27 sec, \n",
      "          Loss: [Train: p = 0.99284, q = 1.08373], \n",
      "          Loss: [Test: p = 1.01984, q = 1.38423],\n",
      "          Effect: [ate-q], [train: 0.06903], [test: 0.07002]\n",
      "********************************************************************************\n",
      "epoch: 394 / 800, time cost: 38.23 sec, \n",
      "          Loss: [Train: p = 0.99274, q = 1.08336], \n",
      "          Loss: [Test: p = 1.01983, q = 1.38754],\n",
      "          Effect: [ate-q], [train: 0.04734], [test: 0.04827]\n",
      "********************************************************************************\n",
      "epoch: 395 / 800, time cost: 40.22 sec, \n",
      "          Loss: [Train: p = 0.99277, q = 1.08348], \n",
      "          Loss: [Test: p = 1.01980, q = 1.38627],\n",
      "          Effect: [ate-q], [train: 0.06075], [test: 0.06173]\n",
      "********************************************************************************\n",
      "epoch: 396 / 800, time cost: 37.94 sec, \n",
      "          Loss: [Train: p = 0.99269, q = 1.08337], \n",
      "          Loss: [Test: p = 1.01982, q = 1.38283],\n",
      "          Effect: [ate-q], [train: 0.07932], [test: 0.08012]\n",
      "********************************************************************************\n",
      "epoch: 397 / 800, time cost: 37.57 sec, \n",
      "          Loss: [Train: p = 0.99265, q = 1.08337], \n",
      "          Loss: [Test: p = 1.01981, q = 1.38328],\n",
      "          Effect: [ate-q], [train: 0.07903], [test: 0.07999]\n",
      "********************************************************************************\n",
      "epoch: 398 / 800, time cost: 38.34 sec, \n",
      "          Loss: [Train: p = 0.99263, q = 1.08268], \n",
      "          Loss: [Test: p = 1.01981, q = 1.38972],\n",
      "          Effect: [ate-q], [train: 0.04355], [test: 0.04451]\n",
      "********************************************************************************\n",
      "epoch: 399 / 800, time cost: 40.74 sec, \n",
      "          Loss: [Train: p = 0.99259, q = 1.08253], \n",
      "          Loss: [Test: p = 1.01985, q = 1.38567],\n",
      "          Effect: [ate-q], [train: 0.06271], [test: 0.06372]\n",
      "********************************************************************************\n",
      "epoch: 400 / 800, time cost: 37.86 sec, \n",
      "          Loss: [Train: p = 0.99263, q = 1.08301], \n",
      "          Loss: [Test: p = 1.01982, q = 1.38347],\n",
      "          Effect: [ate-q], [train: 0.07708], [test: 0.07797]\n",
      "********************************************************************************\n",
      "epoch: 401 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.99262, q = 1.08296], \n",
      "          Loss: [Test: p = 1.01981, q = 1.39130],\n",
      "          Effect: [ate-q], [train: 0.03752], [test: 0.03855]\n",
      "********************************************************************************\n",
      "epoch: 402 / 800, time cost: 38.90 sec, \n",
      "          Loss: [Train: p = 0.99261, q = 1.08301], \n",
      "          Loss: [Test: p = 1.01980, q = 1.38896],\n",
      "          Effect: [ate-q], [train: 0.04780], [test: 0.04888]\n",
      "********************************************************************************\n",
      "epoch: 403 / 800, time cost: 39.22 sec, \n",
      "          Loss: [Train: p = 0.99251, q = 1.08306], \n",
      "          Loss: [Test: p = 1.01981, q = 1.38465],\n",
      "          Effect: [ate-q], [train: 0.06860], [test: 0.06952]\n",
      "********************************************************************************\n",
      "epoch: 404 / 800, time cost: 41.02 sec, \n",
      "          Loss: [Train: p = 0.99246, q = 1.08232], \n",
      "          Loss: [Test: p = 1.01977, q = 1.38568],\n",
      "          Effect: [ate-q], [train: 0.06628], [test: 0.06717]\n",
      "********************************************************************************\n",
      "epoch: 405 / 800, time cost: 36.30 sec, \n",
      "          Loss: [Train: p = 0.99250, q = 1.08266], \n",
      "          Loss: [Test: p = 1.01979, q = 1.38685],\n",
      "          Effect: [ate-q], [train: 0.05844], [test: 0.05940]\n",
      "********************************************************************************\n",
      "epoch: 406 / 800, time cost: 37.43 sec, \n",
      "          Loss: [Train: p = 0.99240, q = 1.08256], \n",
      "          Loss: [Test: p = 1.01980, q = 1.38621],\n",
      "          Effect: [ate-q], [train: 0.06265], [test: 0.06360]\n",
      "********************************************************************************\n",
      "epoch: 407 / 800, time cost: 38.25 sec, \n",
      "          Loss: [Train: p = 0.99243, q = 1.08292], \n",
      "          Loss: [Test: p = 1.01982, q = 1.38729],\n",
      "          Effect: [ate-q], [train: 0.05479], [test: 0.05581]\n",
      "********************************************************************************\n",
      "epoch: 408 / 800, time cost: 38.22 sec, \n",
      "          Loss: [Train: p = 0.99241, q = 1.08200], \n",
      "          Loss: [Test: p = 1.01978, q = 1.38658],\n",
      "          Effect: [ate-q], [train: 0.06216], [test: 0.06312]\n",
      "********************************************************************************\n",
      "epoch: 409 / 800, time cost: 40.04 sec, \n",
      "          Loss: [Train: p = 0.99234, q = 1.08229], \n",
      "          Loss: [Test: p = 1.01972, q = 1.38650],\n",
      "          Effect: [ate-q], [train: 0.06160], [test: 0.06258]\n",
      "********************************************************************************\n",
      "epoch: 410 / 800, time cost: 37.92 sec, \n",
      "          Loss: [Train: p = 0.99232, q = 1.08219], \n",
      "          Loss: [Test: p = 1.01978, q = 1.38861],\n",
      "          Effect: [ate-q], [train: 0.05193], [test: 0.05291]\n",
      "********************************************************************************\n",
      "epoch: 411 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.99227, q = 1.08219], \n",
      "          Loss: [Test: p = 1.01974, q = 1.38557],\n",
      "          Effect: [ate-q], [train: 0.07374], [test: 0.07469]\n",
      "********************************************************************************\n",
      "epoch: 412 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.99227, q = 1.08172], \n",
      "          Loss: [Test: p = 1.01976, q = 1.38661],\n",
      "          Effect: [ate-q], [train: 0.06551], [test: 0.06646]\n",
      "********************************************************************************\n",
      "epoch: 413 / 800, time cost: 38.27 sec, \n",
      "          Loss: [Train: p = 0.99232, q = 1.08199], \n",
      "          Loss: [Test: p = 1.01975, q = 1.39030],\n",
      "          Effect: [ate-q], [train: 0.04685], [test: 0.04784]\n",
      "********************************************************************************\n",
      "epoch: 414 / 800, time cost: 40.24 sec, \n",
      "          Loss: [Train: p = 0.99229, q = 1.08200], \n",
      "          Loss: [Test: p = 1.01973, q = 1.38709],\n",
      "          Effect: [ate-q], [train: 0.05832], [test: 0.05921]\n",
      "********************************************************************************\n",
      "epoch: 415 / 800, time cost: 37.85 sec, \n",
      "          Loss: [Train: p = 0.99219, q = 1.08207], \n",
      "          Loss: [Test: p = 1.01971, q = 1.38683],\n",
      "          Effect: [ate-q], [train: 0.06323], [test: 0.06412]\n",
      "********************************************************************************\n",
      "epoch: 416 / 800, time cost: 37.69 sec, \n",
      "          Loss: [Train: p = 0.99221, q = 1.08173], \n",
      "          Loss: [Test: p = 1.01974, q = 1.38566],\n",
      "          Effect: [ate-q], [train: 0.07325], [test: 0.07410]\n",
      "********************************************************************************\n",
      "epoch: 417 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.99223, q = 1.08163], \n",
      "          Loss: [Test: p = 1.01971, q = 1.38547],\n",
      "          Effect: [ate-q], [train: 0.07810], [test: 0.07902]\n",
      "********************************************************************************\n",
      "epoch: 418 / 800, time cost: 37.84 sec, \n",
      "          Loss: [Train: p = 0.99214, q = 1.08090], \n",
      "          Loss: [Test: p = 1.01973, q = 1.39030],\n",
      "          Effect: [ate-q], [train: 0.04947], [test: 0.05035]\n",
      "********************************************************************************\n",
      "epoch: 419 / 800, time cost: 40.40 sec, \n",
      "          Loss: [Train: p = 0.99213, q = 1.08141], \n",
      "          Loss: [Test: p = 1.01973, q = 1.38668],\n",
      "          Effect: [ate-q], [train: 0.07089], [test: 0.07188]\n",
      "********************************************************************************\n",
      "epoch: 420 / 800, time cost: 37.00 sec, \n",
      "          Loss: [Train: p = 0.99213, q = 1.08194], \n",
      "          Loss: [Test: p = 1.01974, q = 1.38700],\n",
      "          Effect: [ate-q], [train: 0.06628], [test: 0.06719]\n",
      "********************************************************************************\n",
      "epoch: 421 / 800, time cost: 37.98 sec, \n",
      "          Loss: [Train: p = 0.99203, q = 1.08169], \n",
      "          Loss: [Test: p = 1.01969, q = 1.38739],\n",
      "          Effect: [ate-q], [train: 0.05934], [test: 0.06027]\n",
      "********************************************************************************\n",
      "epoch: 422 / 800, time cost: 37.94 sec, \n",
      "          Loss: [Train: p = 0.99209, q = 1.08152], \n",
      "          Loss: [Test: p = 1.01969, q = 1.38910],\n",
      "          Effect: [ate-q], [train: 0.05321], [test: 0.05420]\n",
      "********************************************************************************\n",
      "epoch: 423 / 800, time cost: 38.22 sec, \n",
      "          Loss: [Train: p = 0.99193, q = 1.08092], \n",
      "          Loss: [Test: p = 1.01965, q = 1.38659],\n",
      "          Effect: [ate-q], [train: 0.06664], [test: 0.06757]\n",
      "********************************************************************************\n",
      "epoch: 424 / 800, time cost: 40.26 sec, \n",
      "          Loss: [Train: p = 0.99210, q = 1.08120], \n",
      "          Loss: [Test: p = 1.01970, q = 1.38553],\n",
      "          Effect: [ate-q], [train: 0.07662], [test: 0.07754]\n",
      "********************************************************************************\n",
      "epoch: 425 / 800, time cost: 38.12 sec, \n",
      "          Loss: [Train: p = 0.99192, q = 1.08074], \n",
      "          Loss: [Test: p = 1.01969, q = 1.39014],\n",
      "          Effect: [ate-q], [train: 0.05110], [test: 0.05202]\n",
      "********************************************************************************\n",
      "epoch: 426 / 800, time cost: 38.09 sec, \n",
      "          Loss: [Train: p = 0.99204, q = 1.08128], \n",
      "          Loss: [Test: p = 1.01967, q = 1.38727],\n",
      "          Effect: [ate-q], [train: 0.07051], [test: 0.07145]\n",
      "********************************************************************************\n",
      "epoch: 427 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.99197, q = 1.08123], \n",
      "          Loss: [Test: p = 1.01966, q = 1.38758],\n",
      "          Effect: [ate-q], [train: 0.06509], [test: 0.06608]\n",
      "********************************************************************************\n",
      "epoch: 428 / 800, time cost: 39.10 sec, \n",
      "          Loss: [Train: p = 0.99190, q = 1.08080], \n",
      "          Loss: [Test: p = 1.01972, q = 1.38837],\n",
      "          Effect: [ate-q], [train: 0.05973], [test: 0.06069]\n",
      "********************************************************************************\n",
      "epoch: 429 / 800, time cost: 47.20 sec, \n",
      "          Loss: [Train: p = 0.99188, q = 1.08111], \n",
      "          Loss: [Test: p = 1.01969, q = 1.38895],\n",
      "          Effect: [ate-q], [train: 0.05962], [test: 0.06053]\n",
      "********************************************************************************\n",
      "epoch: 430 / 800, time cost: 45.07 sec, \n",
      "          Loss: [Train: p = 0.99191, q = 1.08065], \n",
      "          Loss: [Test: p = 1.01966, q = 1.38749],\n",
      "          Effect: [ate-q], [train: 0.07154], [test: 0.07239]\n",
      "********************************************************************************\n",
      "epoch: 431 / 800, time cost: 44.95 sec, \n",
      "          Loss: [Train: p = 0.99181, q = 1.08091], \n",
      "          Loss: [Test: p = 1.01966, q = 1.38824],\n",
      "          Effect: [ate-q], [train: 0.06513], [test: 0.06600]\n",
      "********************************************************************************\n",
      "epoch: 432 / 800, time cost: 40.38 sec, \n",
      "          Loss: [Train: p = 0.99181, q = 1.08060], \n",
      "          Loss: [Test: p = 1.01966, q = 1.39028],\n",
      "          Effect: [ate-q], [train: 0.05579], [test: 0.05676]\n",
      "********************************************************************************\n",
      "epoch: 433 / 800, time cost: 40.59 sec, \n",
      "          Loss: [Train: p = 0.99185, q = 1.08077], \n",
      "          Loss: [Test: p = 1.01961, q = 1.38964],\n",
      "          Effect: [ate-q], [train: 0.05639], [test: 0.05734]\n",
      "********************************************************************************\n",
      "epoch: 434 / 800, time cost: 38.19 sec, \n",
      "          Loss: [Train: p = 0.99179, q = 1.08085], \n",
      "          Loss: [Test: p = 1.01966, q = 1.38950],\n",
      "          Effect: [ate-q], [train: 0.05831], [test: 0.05927]\n",
      "********************************************************************************\n",
      "epoch: 435 / 800, time cost: 38.30 sec, \n",
      "          Loss: [Train: p = 0.99184, q = 1.08095], \n",
      "          Loss: [Test: p = 1.01967, q = 1.38868],\n",
      "          Effect: [ate-q], [train: 0.06529], [test: 0.06613]\n",
      "********************************************************************************\n",
      "epoch: 436 / 800, time cost: 38.28 sec, \n",
      "          Loss: [Train: p = 0.99166, q = 1.08013], \n",
      "          Loss: [Test: p = 1.01964, q = 1.39024],\n",
      "          Effect: [ate-q], [train: 0.05431], [test: 0.05521]\n",
      "********************************************************************************\n",
      "epoch: 437 / 800, time cost: 37.88 sec, \n",
      "          Loss: [Train: p = 0.99171, q = 1.08009], \n",
      "          Loss: [Test: p = 1.01961, q = 1.39038],\n",
      "          Effect: [ate-q], [train: 0.05382], [test: 0.05479]\n",
      "********************************************************************************\n",
      "epoch: 438 / 800, time cost: 40.50 sec, \n",
      "          Loss: [Train: p = 0.99169, q = 1.08056], \n",
      "          Loss: [Test: p = 1.01964, q = 1.38753],\n",
      "          Effect: [ate-q], [train: 0.07975], [test: 0.08059]\n",
      "********************************************************************************\n",
      "epoch: 439 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.99163, q = 1.08014], \n",
      "          Loss: [Test: p = 1.01962, q = 1.38930],\n",
      "          Effect: [ate-q], [train: 0.06582], [test: 0.06673]\n",
      "********************************************************************************\n",
      "epoch: 440 / 800, time cost: 37.55 sec, \n",
      "          Loss: [Train: p = 0.99165, q = 1.08003], \n",
      "          Loss: [Test: p = 1.01964, q = 1.39130],\n",
      "          Effect: [ate-q], [train: 0.05322], [test: 0.05417]\n",
      "********************************************************************************\n",
      "epoch: 441 / 800, time cost: 37.79 sec, \n",
      "          Loss: [Train: p = 0.99164, q = 1.07990], \n",
      "          Loss: [Test: p = 1.01963, q = 1.39231],\n",
      "          Effect: [ate-q], [train: 0.04930], [test: 0.05017]\n",
      "********************************************************************************\n",
      "epoch: 442 / 800, time cost: 38.06 sec, \n",
      "          Loss: [Train: p = 0.99154, q = 1.08001], \n",
      "          Loss: [Test: p = 1.01962, q = 1.39005],\n",
      "          Effect: [ate-q], [train: 0.05805], [test: 0.05900]\n",
      "********************************************************************************\n",
      "epoch: 443 / 800, time cost: 40.35 sec, \n",
      "          Loss: [Train: p = 0.99167, q = 1.08000], \n",
      "          Loss: [Test: p = 1.01962, q = 1.39095],\n",
      "          Effect: [ate-q], [train: 0.05384], [test: 0.05475]\n",
      "********************************************************************************\n",
      "epoch: 444 / 800, time cost: 36.67 sec, \n",
      "          Loss: [Train: p = 0.99156, q = 1.07971], \n",
      "          Loss: [Test: p = 1.01964, q = 1.39154],\n",
      "          Effect: [ate-q], [train: 0.05487], [test: 0.05578]\n",
      "********************************************************************************\n",
      "epoch: 445 / 800, time cost: 36.77 sec, \n",
      "          Loss: [Train: p = 0.99155, q = 1.07995], \n",
      "          Loss: [Test: p = 1.01956, q = 1.39024],\n",
      "          Effect: [ate-q], [train: 0.06352], [test: 0.06448]\n",
      "********************************************************************************\n",
      "epoch: 446 / 800, time cost: 38.46 sec, \n",
      "          Loss: [Train: p = 0.99150, q = 1.07948], \n",
      "          Loss: [Test: p = 1.01963, q = 1.39243],\n",
      "          Effect: [ate-q], [train: 0.04751], [test: 0.04844]\n",
      "********************************************************************************\n",
      "epoch: 447 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.99147, q = 1.07983], \n",
      "          Loss: [Test: p = 1.01957, q = 1.39235],\n",
      "          Effect: [ate-q], [train: 0.05037], [test: 0.05127]\n",
      "********************************************************************************\n",
      "epoch: 448 / 800, time cost: 40.09 sec, \n",
      "          Loss: [Train: p = 0.99147, q = 1.07924], \n",
      "          Loss: [Test: p = 1.01960, q = 1.39094],\n",
      "          Effect: [ate-q], [train: 0.05576], [test: 0.05672]\n",
      "********************************************************************************\n",
      "epoch: 449 / 800, time cost: 37.70 sec, \n",
      "          Loss: [Train: p = 0.99144, q = 1.07958], \n",
      "          Loss: [Test: p = 1.01959, q = 1.38926],\n",
      "          Effect: [ate-q], [train: 0.07165], [test: 0.07245]\n",
      "********************************************************************************\n",
      "epoch: 450 / 800, time cost: 38.03 sec, \n",
      "          Loss: [Train: p = 0.99143, q = 1.07958], \n",
      "          Loss: [Test: p = 1.01959, q = 1.38974],\n",
      "          Effect: [ate-q], [train: 0.06601], [test: 0.06691]\n",
      "********************************************************************************\n",
      "epoch: 451 / 800, time cost: 37.70 sec, \n",
      "          Loss: [Train: p = 0.99127, q = 1.07964], \n",
      "          Loss: [Test: p = 1.01958, q = 1.38917],\n",
      "          Effect: [ate-q], [train: 0.07301], [test: 0.07389]\n",
      "********************************************************************************\n",
      "epoch: 452 / 800, time cost: 37.81 sec, \n",
      "          Loss: [Train: p = 0.99127, q = 1.07939], \n",
      "          Loss: [Test: p = 1.01955, q = 1.38883],\n",
      "          Effect: [ate-q], [train: 0.07357], [test: 0.07443]\n",
      "********************************************************************************\n",
      "epoch: 453 / 800, time cost: 40.32 sec, \n",
      "          Loss: [Train: p = 0.99124, q = 1.07913], \n",
      "          Loss: [Test: p = 1.01961, q = 1.39093],\n",
      "          Effect: [ate-q], [train: 0.06369], [test: 0.06467]\n",
      "********************************************************************************\n",
      "epoch: 454 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.99134, q = 1.07892], \n",
      "          Loss: [Test: p = 1.01960, q = 1.38953],\n",
      "          Effect: [ate-q], [train: 0.06798], [test: 0.06885]\n",
      "********************************************************************************\n",
      "epoch: 455 / 800, time cost: 38.04 sec, \n",
      "          Loss: [Train: p = 0.99122, q = 1.07894], \n",
      "          Loss: [Test: p = 1.01955, q = 1.39086],\n",
      "          Effect: [ate-q], [train: 0.06732], [test: 0.06818]\n",
      "********************************************************************************\n",
      "epoch: 456 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.99130, q = 1.07937], \n",
      "          Loss: [Test: p = 1.01957, q = 1.39141],\n",
      "          Effect: [ate-q], [train: 0.05879], [test: 0.05967]\n",
      "********************************************************************************\n",
      "epoch: 457 / 800, time cost: 38.39 sec, \n",
      "          Loss: [Train: p = 0.99128, q = 1.07856], \n",
      "          Loss: [Test: p = 1.01955, q = 1.38992],\n",
      "          Effect: [ate-q], [train: 0.06407], [test: 0.06491]\n",
      "********************************************************************************\n",
      "epoch: 458 / 800, time cost: 40.61 sec, \n",
      "          Loss: [Train: p = 0.99117, q = 1.07913], \n",
      "          Loss: [Test: p = 1.01957, q = 1.39401],\n",
      "          Effect: [ate-q], [train: 0.04491], [test: 0.04587]\n",
      "********************************************************************************\n",
      "epoch: 459 / 800, time cost: 38.17 sec, \n",
      "          Loss: [Train: p = 0.99115, q = 1.07889], \n",
      "          Loss: [Test: p = 1.01950, q = 1.39103],\n",
      "          Effect: [ate-q], [train: 0.06562], [test: 0.06652]\n",
      "********************************************************************************\n",
      "epoch: 460 / 800, time cost: 38.42 sec, \n",
      "          Loss: [Train: p = 0.99116, q = 1.07863], \n",
      "          Loss: [Test: p = 1.01952, q = 1.38868],\n",
      "          Effect: [ate-q], [train: 0.07414], [test: 0.07493]\n",
      "********************************************************************************\n",
      "epoch: 461 / 800, time cost: 38.61 sec, \n",
      "          Loss: [Train: p = 0.99109, q = 1.07862], \n",
      "          Loss: [Test: p = 1.01953, q = 1.39024],\n",
      "          Effect: [ate-q], [train: 0.06803], [test: 0.06889]\n",
      "********************************************************************************\n",
      "epoch: 462 / 800, time cost: 38.41 sec, \n",
      "          Loss: [Train: p = 0.99104, q = 1.07835], \n",
      "          Loss: [Test: p = 1.01952, q = 1.39018],\n",
      "          Effect: [ate-q], [train: 0.07187], [test: 0.07270]\n",
      "********************************************************************************\n",
      "epoch: 463 / 800, time cost: 40.61 sec, \n",
      "          Loss: [Train: p = 0.99099, q = 1.07862], \n",
      "          Loss: [Test: p = 1.01953, q = 1.39144],\n",
      "          Effect: [ate-q], [train: 0.06228], [test: 0.06319]\n",
      "********************************************************************************\n",
      "epoch: 464 / 800, time cost: 37.76 sec, \n",
      "          Loss: [Train: p = 0.99110, q = 1.07846], \n",
      "          Loss: [Test: p = 1.01952, q = 1.39002],\n",
      "          Effect: [ate-q], [train: 0.07521], [test: 0.07605]\n",
      "********************************************************************************\n",
      "epoch: 465 / 800, time cost: 38.26 sec, \n",
      "          Loss: [Train: p = 0.99099, q = 1.07820], \n",
      "          Loss: [Test: p = 1.01953, q = 1.39450],\n",
      "          Effect: [ate-q], [train: 0.04690], [test: 0.04789]\n",
      "********************************************************************************\n",
      "epoch: 466 / 800, time cost: 37.05 sec, \n",
      "          Loss: [Train: p = 0.99103, q = 1.07826], \n",
      "          Loss: [Test: p = 1.01952, q = 1.39303],\n",
      "          Effect: [ate-q], [train: 0.05277], [test: 0.05367]\n",
      "********************************************************************************\n",
      "epoch: 467 / 800, time cost: 40.57 sec, \n",
      "          Loss: [Train: p = 0.99097, q = 1.07813], \n",
      "          Loss: [Test: p = 1.01951, q = 1.39124],\n",
      "          Effect: [ate-q], [train: 0.06552], [test: 0.06636]\n",
      "********************************************************************************\n",
      "epoch: 468 / 800, time cost: 37.21 sec, \n",
      "          Loss: [Train: p = 0.99105, q = 1.07858], \n",
      "          Loss: [Test: p = 1.01951, q = 1.39124],\n",
      "          Effect: [ate-q], [train: 0.07171], [test: 0.07260]\n",
      "********************************************************************************\n",
      "epoch: 469 / 800, time cost: 37.16 sec, \n",
      "          Loss: [Train: p = 0.99100, q = 1.07820], \n",
      "          Loss: [Test: p = 1.01951, q = 1.39176],\n",
      "          Effect: [ate-q], [train: 0.06345], [test: 0.06437]\n",
      "********************************************************************************\n",
      "epoch: 470 / 800, time cost: 37.02 sec, \n",
      "          Loss: [Train: p = 0.99095, q = 1.07792], \n",
      "          Loss: [Test: p = 1.01947, q = 1.39136],\n",
      "          Effect: [ate-q], [train: 0.06434], [test: 0.06529]\n",
      "********************************************************************************\n",
      "epoch: 471 / 800, time cost: 36.77 sec, \n",
      "          Loss: [Train: p = 0.99095, q = 1.07856], \n",
      "          Loss: [Test: p = 1.01949, q = 1.39361],\n",
      "          Effect: [ate-q], [train: 0.05371], [test: 0.05464]\n",
      "********************************************************************************\n",
      "epoch: 472 / 800, time cost: 39.29 sec, \n",
      "          Loss: [Train: p = 0.99091, q = 1.07813], \n",
      "          Loss: [Test: p = 1.01946, q = 1.39543],\n",
      "          Effect: [ate-q], [train: 0.04816], [test: 0.04909]\n",
      "********************************************************************************\n",
      "epoch: 473 / 800, time cost: 36.80 sec, \n",
      "          Loss: [Train: p = 0.99089, q = 1.07775], \n",
      "          Loss: [Test: p = 1.01947, q = 1.39289],\n",
      "          Effect: [ate-q], [train: 0.06169], [test: 0.06269]\n",
      "********************************************************************************\n",
      "epoch: 474 / 800, time cost: 36.77 sec, \n",
      "          Loss: [Train: p = 0.99071, q = 1.07770], \n",
      "          Loss: [Test: p = 1.01949, q = 1.39218],\n",
      "          Effect: [ate-q], [train: 0.06406], [test: 0.06499]\n",
      "********************************************************************************\n",
      "epoch: 475 / 800, time cost: 36.97 sec, \n",
      "          Loss: [Train: p = 0.99082, q = 1.07770], \n",
      "          Loss: [Test: p = 1.01947, q = 1.39254],\n",
      "          Effect: [ate-q], [train: 0.06282], [test: 0.06368]\n",
      "********************************************************************************\n",
      "epoch: 476 / 800, time cost: 37.04 sec, \n",
      "          Loss: [Train: p = 0.99079, q = 1.07788], \n",
      "          Loss: [Test: p = 1.01948, q = 1.39285],\n",
      "          Effect: [ate-q], [train: 0.06659], [test: 0.06752]\n",
      "********************************************************************************\n",
      "epoch: 477 / 800, time cost: 39.47 sec, \n",
      "          Loss: [Train: p = 0.99077, q = 1.07727], \n",
      "          Loss: [Test: p = 1.01947, q = 1.39320],\n",
      "          Effect: [ate-q], [train: 0.05969], [test: 0.06067]\n",
      "********************************************************************************\n",
      "epoch: 478 / 800, time cost: 36.82 sec, \n",
      "          Loss: [Train: p = 0.99076, q = 1.07734], \n",
      "          Loss: [Test: p = 1.01950, q = 1.39716],\n",
      "          Effect: [ate-q], [train: 0.03785], [test: 0.03875]\n",
      "********************************************************************************\n",
      "epoch: 479 / 800, time cost: 36.78 sec, \n",
      "          Loss: [Train: p = 0.99070, q = 1.07759], \n",
      "          Loss: [Test: p = 1.01948, q = 1.39337],\n",
      "          Effect: [ate-q], [train: 0.05853], [test: 0.05946]\n",
      "********************************************************************************\n",
      "epoch: 480 / 800, time cost: 38.29 sec, \n",
      "          Loss: [Train: p = 0.99069, q = 1.07754], \n",
      "          Loss: [Test: p = 1.01942, q = 1.39297],\n",
      "          Effect: [ate-q], [train: 0.06502], [test: 0.06597]\n",
      "********************************************************************************\n",
      "epoch: 481 / 800, time cost: 38.47 sec, \n",
      "          Loss: [Train: p = 0.99064, q = 1.07732], \n",
      "          Loss: [Test: p = 1.01949, q = 1.39299],\n",
      "          Effect: [ate-q], [train: 0.06358], [test: 0.06446]\n",
      "********************************************************************************\n",
      "epoch: 482 / 800, time cost: 40.81 sec, \n",
      "          Loss: [Train: p = 0.99059, q = 1.07747], \n",
      "          Loss: [Test: p = 1.01947, q = 1.39442],\n",
      "          Effect: [ate-q], [train: 0.05703], [test: 0.05792]\n",
      "********************************************************************************\n",
      "epoch: 483 / 800, time cost: 37.40 sec, \n",
      "          Loss: [Train: p = 0.99065, q = 1.07709], \n",
      "          Loss: [Test: p = 1.01944, q = 1.39024],\n",
      "          Effect: [ate-q], [train: 0.08965], [test: 0.09040]\n",
      "********************************************************************************\n",
      "epoch: 484 / 800, time cost: 38.33 sec, \n",
      "          Loss: [Train: p = 0.99063, q = 1.07767], \n",
      "          Loss: [Test: p = 1.01943, q = 1.39369],\n",
      "          Effect: [ate-q], [train: 0.05948], [test: 0.06037]\n",
      "********************************************************************************\n",
      "epoch: 485 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.99049, q = 1.07755], \n",
      "          Loss: [Test: p = 1.01942, q = 1.39333],\n",
      "          Effect: [ate-q], [train: 0.06466], [test: 0.06549]\n",
      "********************************************************************************\n",
      "epoch: 486 / 800, time cost: 41.49 sec, \n",
      "          Loss: [Train: p = 0.99064, q = 1.07700], \n",
      "          Loss: [Test: p = 1.01945, q = 1.39235],\n",
      "          Effect: [ate-q], [train: 0.07023], [test: 0.07113]\n",
      "********************************************************************************\n",
      "epoch: 487 / 800, time cost: 40.43 sec, \n",
      "          Loss: [Train: p = 0.99058, q = 1.07713], \n",
      "          Loss: [Test: p = 1.01942, q = 1.39308],\n",
      "          Effect: [ate-q], [train: 0.06286], [test: 0.06372]\n",
      "********************************************************************************\n",
      "epoch: 488 / 800, time cost: 38.43 sec, \n",
      "          Loss: [Train: p = 0.99043, q = 1.07662], \n",
      "          Loss: [Test: p = 1.01946, q = 1.39315],\n",
      "          Effect: [ate-q], [train: 0.05970], [test: 0.06050]\n",
      "********************************************************************************\n",
      "epoch: 489 / 800, time cost: 38.24 sec, \n",
      "          Loss: [Train: p = 0.99048, q = 1.07620], \n",
      "          Loss: [Test: p = 1.01944, q = 1.39465],\n",
      "          Effect: [ate-q], [train: 0.05567], [test: 0.05652]\n",
      "********************************************************************************\n",
      "epoch: 490 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.99046, q = 1.07706], \n",
      "          Loss: [Test: p = 1.01943, q = 1.39284],\n",
      "          Effect: [ate-q], [train: 0.06883], [test: 0.06970]\n",
      "********************************************************************************\n",
      "epoch: 491 / 800, time cost: 38.63 sec, \n",
      "          Loss: [Train: p = 0.99040, q = 1.07647], \n",
      "          Loss: [Test: p = 1.01945, q = 1.39345],\n",
      "          Effect: [ate-q], [train: 0.06297], [test: 0.06384]\n",
      "********************************************************************************\n",
      "epoch: 492 / 800, time cost: 40.85 sec, \n",
      "          Loss: [Train: p = 0.99046, q = 1.07668], \n",
      "          Loss: [Test: p = 1.01945, q = 1.39387],\n",
      "          Effect: [ate-q], [train: 0.06809], [test: 0.06889]\n",
      "********************************************************************************\n",
      "epoch: 493 / 800, time cost: 38.44 sec, \n",
      "          Loss: [Train: p = 0.99032, q = 1.07616], \n",
      "          Loss: [Test: p = 1.01943, q = 1.39326],\n",
      "          Effect: [ate-q], [train: 0.06349], [test: 0.06433]\n",
      "********************************************************************************\n",
      "epoch: 494 / 800, time cost: 37.41 sec, \n",
      "          Loss: [Train: p = 0.99032, q = 1.07702], \n",
      "          Loss: [Test: p = 1.01939, q = 1.39797],\n",
      "          Effect: [ate-q], [train: 0.04359], [test: 0.04438]\n",
      "********************************************************************************\n",
      "epoch: 495 / 800, time cost: 37.74 sec, \n",
      "          Loss: [Train: p = 0.99032, q = 1.07635], \n",
      "          Loss: [Test: p = 1.01941, q = 1.39521],\n",
      "          Effect: [ate-q], [train: 0.05071], [test: 0.05157]\n",
      "********************************************************************************\n",
      "epoch: 496 / 800, time cost: 38.39 sec, \n",
      "          Loss: [Train: p = 0.99033, q = 1.07607], \n",
      "          Loss: [Test: p = 1.01943, q = 1.39294],\n",
      "          Effect: [ate-q], [train: 0.06964], [test: 0.07045]\n",
      "********************************************************************************\n",
      "epoch: 497 / 800, time cost: 40.62 sec, \n",
      "          Loss: [Train: p = 0.99024, q = 1.07627], \n",
      "          Loss: [Test: p = 1.01939, q = 1.39512],\n",
      "          Effect: [ate-q], [train: 0.05423], [test: 0.05514]\n",
      "********************************************************************************\n",
      "epoch: 498 / 800, time cost: 37.42 sec, \n",
      "          Loss: [Train: p = 0.99024, q = 1.07636], \n",
      "          Loss: [Test: p = 1.01940, q = 1.39247],\n",
      "          Effect: [ate-q], [train: 0.07668], [test: 0.07748]\n",
      "********************************************************************************\n",
      "epoch: 499 / 800, time cost: 38.49 sec, \n",
      "          Loss: [Train: p = 0.99029, q = 1.07573], \n",
      "          Loss: [Test: p = 1.01941, q = 1.39198],\n",
      "          Effect: [ate-q], [train: 0.07657], [test: 0.07736]\n",
      "********************************************************************************\n",
      "epoch: 500 / 800, time cost: 38.32 sec, \n",
      "          Loss: [Train: p = 0.99017, q = 1.07630], \n",
      "          Loss: [Test: p = 1.01940, q = 1.39605],\n",
      "          Effect: [ate-q], [train: 0.05446], [test: 0.05538]\n",
      "********************************************************************************\n",
      "epoch: 501 / 800, time cost: 38.35 sec, \n",
      "          Loss: [Train: p = 0.99018, q = 1.07625], \n",
      "          Loss: [Test: p = 1.01940, q = 1.39255],\n",
      "          Effect: [ate-q], [train: 0.07842], [test: 0.07918]\n",
      "********************************************************************************\n",
      "epoch: 502 / 800, time cost: 40.23 sec, \n",
      "          Loss: [Train: p = 0.99023, q = 1.07602], \n",
      "          Loss: [Test: p = 1.01941, q = 1.39263],\n",
      "          Effect: [ate-q], [train: 0.07649], [test: 0.07732]\n",
      "********************************************************************************\n",
      "epoch: 503 / 800, time cost: 38.50 sec, \n",
      "          Loss: [Train: p = 0.99015, q = 1.07618], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39463],\n",
      "          Effect: [ate-q], [train: 0.06181], [test: 0.06266]\n",
      "********************************************************************************\n",
      "epoch: 504 / 800, time cost: 38.54 sec, \n",
      "          Loss: [Train: p = 0.99011, q = 1.07534], \n",
      "          Loss: [Test: p = 1.01932, q = 1.39871],\n",
      "          Effect: [ate-q], [train: 0.04199], [test: 0.04287]\n",
      "********************************************************************************\n",
      "epoch: 505 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.99006, q = 1.07593], \n",
      "          Loss: [Test: p = 1.01935, q = 1.39325],\n",
      "          Effect: [ate-q], [train: 0.07765], [test: 0.07840]\n",
      "********************************************************************************\n",
      "epoch: 506 / 800, time cost: 40.41 sec, \n",
      "          Loss: [Train: p = 0.99002, q = 1.07571], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39313],\n",
      "          Effect: [ate-q], [train: 0.08236], [test: 0.08311]\n",
      "********************************************************************************\n",
      "epoch: 507 / 800, time cost: 38.22 sec, \n",
      "          Loss: [Train: p = 0.99002, q = 1.07563], \n",
      "          Loss: [Test: p = 1.01936, q = 1.39369],\n",
      "          Effect: [ate-q], [train: 0.07586], [test: 0.07670]\n",
      "********************************************************************************\n",
      "epoch: 508 / 800, time cost: 38.03 sec, \n",
      "          Loss: [Train: p = 0.99003, q = 1.07572], \n",
      "          Loss: [Test: p = 1.01935, q = 1.39915],\n",
      "          Effect: [ate-q], [train: 0.04455], [test: 0.04550]\n",
      "********************************************************************************\n",
      "epoch: 509 / 800, time cost: 38.14 sec, \n",
      "          Loss: [Train: p = 0.98996, q = 1.07536], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39580],\n",
      "          Effect: [ate-q], [train: 0.05884], [test: 0.05968]\n",
      "********************************************************************************\n",
      "epoch: 510 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.98989, q = 1.07535], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39520],\n",
      "          Effect: [ate-q], [train: 0.06573], [test: 0.06655]\n",
      "********************************************************************************\n",
      "epoch: 511 / 800, time cost: 40.54 sec, \n",
      "          Loss: [Train: p = 0.98994, q = 1.07569], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39579],\n",
      "          Effect: [ate-q], [train: 0.05777], [test: 0.05860]\n",
      "********************************************************************************\n",
      "epoch: 512 / 800, time cost: 38.01 sec, \n",
      "          Loss: [Train: p = 0.98985, q = 1.07540], \n",
      "          Loss: [Test: p = 1.01933, q = 1.39719],\n",
      "          Effect: [ate-q], [train: 0.05496], [test: 0.05585]\n",
      "********************************************************************************\n",
      "epoch: 513 / 800, time cost: 37.88 sec, \n",
      "          Loss: [Train: p = 0.98985, q = 1.07560], \n",
      "          Loss: [Test: p = 1.01935, q = 1.39674],\n",
      "          Effect: [ate-q], [train: 0.05316], [test: 0.05406]\n",
      "********************************************************************************\n",
      "epoch: 514 / 800, time cost: 38.14 sec, \n",
      "          Loss: [Train: p = 0.98991, q = 1.07465], \n",
      "          Loss: [Test: p = 1.01932, q = 1.39522],\n",
      "          Effect: [ate-q], [train: 0.06426], [test: 0.06508]\n",
      "********************************************************************************\n",
      "epoch: 515 / 800, time cost: 38.40 sec, \n",
      "          Loss: [Train: p = 0.98989, q = 1.07544], \n",
      "          Loss: [Test: p = 1.01933, q = 1.39456],\n",
      "          Effect: [ate-q], [train: 0.06697], [test: 0.06784]\n",
      "********************************************************************************\n",
      "epoch: 516 / 800, time cost: 40.43 sec, \n",
      "          Loss: [Train: p = 0.98984, q = 1.07462], \n",
      "          Loss: [Test: p = 1.01936, q = 1.39521],\n",
      "          Effect: [ate-q], [train: 0.07000], [test: 0.07082]\n",
      "********************************************************************************\n",
      "epoch: 517 / 800, time cost: 37.69 sec, \n",
      "          Loss: [Train: p = 0.98973, q = 1.07483], \n",
      "          Loss: [Test: p = 1.01937, q = 1.39570],\n",
      "          Effect: [ate-q], [train: 0.06334], [test: 0.06412]\n",
      "********************************************************************************\n",
      "epoch: 518 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98987, q = 1.07490], \n",
      "          Loss: [Test: p = 1.01932, q = 1.39701],\n",
      "          Effect: [ate-q], [train: 0.05937], [test: 0.06021]\n",
      "********************************************************************************\n",
      "epoch: 519 / 800, time cost: 38.02 sec, \n",
      "          Loss: [Train: p = 0.98968, q = 1.07470], \n",
      "          Loss: [Test: p = 1.01931, q = 1.39694],\n",
      "          Effect: [ate-q], [train: 0.05777], [test: 0.05864]\n",
      "********************************************************************************\n",
      "epoch: 520 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.98980, q = 1.07506], \n",
      "          Loss: [Test: p = 1.01932, q = 1.39265],\n",
      "          Effect: [ate-q], [train: 0.07814], [test: 0.07890]\n",
      "********************************************************************************\n",
      "epoch: 521 / 800, time cost: 40.27 sec, \n",
      "          Loss: [Train: p = 0.98966, q = 1.07477], \n",
      "          Loss: [Test: p = 1.01934, q = 1.39706],\n",
      "          Effect: [ate-q], [train: 0.06326], [test: 0.06407]\n",
      "********************************************************************************\n",
      "epoch: 522 / 800, time cost: 37.59 sec, \n",
      "          Loss: [Train: p = 0.98978, q = 1.07534], \n",
      "          Loss: [Test: p = 1.01934, q = 1.39670],\n",
      "          Effect: [ate-q], [train: 0.05465], [test: 0.05550]\n",
      "********************************************************************************\n",
      "epoch: 523 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98967, q = 1.07447], \n",
      "          Loss: [Test: p = 1.01935, q = 1.39540],\n",
      "          Effect: [ate-q], [train: 0.07543], [test: 0.07627]\n",
      "********************************************************************************\n",
      "epoch: 524 / 800, time cost: 38.21 sec, \n",
      "          Loss: [Train: p = 0.98965, q = 1.07454], \n",
      "          Loss: [Test: p = 1.01931, q = 1.39842],\n",
      "          Effect: [ate-q], [train: 0.04987], [test: 0.05070]\n",
      "********************************************************************************\n",
      "epoch: 525 / 800, time cost: 38.19 sec, \n",
      "          Loss: [Train: p = 0.98962, q = 1.07431], \n",
      "          Loss: [Test: p = 1.01933, q = 1.39634],\n",
      "          Effect: [ate-q], [train: 0.06248], [test: 0.06335]\n",
      "********************************************************************************\n",
      "epoch: 526 / 800, time cost: 40.59 sec, \n",
      "          Loss: [Train: p = 0.98952, q = 1.07426], \n",
      "          Loss: [Test: p = 1.01935, q = 1.39546],\n",
      "          Effect: [ate-q], [train: 0.07578], [test: 0.07652]\n",
      "********************************************************************************\n",
      "epoch: 527 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.98960, q = 1.07432], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39681],\n",
      "          Effect: [ate-q], [train: 0.06393], [test: 0.06477]\n",
      "********************************************************************************\n",
      "epoch: 528 / 800, time cost: 38.03 sec, \n",
      "          Loss: [Train: p = 0.98949, q = 1.07410], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39757],\n",
      "          Effect: [ate-q], [train: 0.06260], [test: 0.06342]\n",
      "********************************************************************************\n",
      "epoch: 529 / 800, time cost: 38.22 sec, \n",
      "          Loss: [Train: p = 0.98955, q = 1.07475], \n",
      "          Loss: [Test: p = 1.01931, q = 1.39816],\n",
      "          Effect: [ate-q], [train: 0.05707], [test: 0.05786]\n",
      "********************************************************************************\n",
      "epoch: 530 / 800, time cost: 38.41 sec, \n",
      "          Loss: [Train: p = 0.98957, q = 1.07446], \n",
      "          Loss: [Test: p = 1.01922, q = 1.39611],\n",
      "          Effect: [ate-q], [train: 0.06795], [test: 0.06875]\n",
      "********************************************************************************\n",
      "epoch: 531 / 800, time cost: 41.01 sec, \n",
      "          Loss: [Train: p = 0.98955, q = 1.07424], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39648],\n",
      "          Effect: [ate-q], [train: 0.06465], [test: 0.06537]\n",
      "********************************************************************************\n",
      "epoch: 532 / 800, time cost: 38.02 sec, \n",
      "          Loss: [Train: p = 0.98947, q = 1.07456], \n",
      "          Loss: [Test: p = 1.01926, q = 1.39508],\n",
      "          Effect: [ate-q], [train: 0.07612], [test: 0.07684]\n",
      "********************************************************************************\n",
      "epoch: 533 / 800, time cost: 38.25 sec, \n",
      "          Loss: [Train: p = 0.98939, q = 1.07372], \n",
      "          Loss: [Test: p = 1.01929, q = 1.40015],\n",
      "          Effect: [ate-q], [train: 0.04934], [test: 0.05015]\n",
      "********************************************************************************\n",
      "epoch: 534 / 800, time cost: 38.51 sec, \n",
      "          Loss: [Train: p = 0.98946, q = 1.07381], \n",
      "          Loss: [Test: p = 1.01930, q = 1.40011],\n",
      "          Effect: [ate-q], [train: 0.04685], [test: 0.04771]\n",
      "********************************************************************************\n",
      "epoch: 535 / 800, time cost: 38.36 sec, \n",
      "          Loss: [Train: p = 0.98952, q = 1.07376], \n",
      "          Loss: [Test: p = 1.01926, q = 1.39555],\n",
      "          Effect: [ate-q], [train: 0.07895], [test: 0.07966]\n",
      "********************************************************************************\n",
      "epoch: 536 / 800, time cost: 40.42 sec, \n",
      "          Loss: [Train: p = 0.98937, q = 1.07403], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39588],\n",
      "          Effect: [ate-q], [train: 0.06834], [test: 0.06918]\n",
      "********************************************************************************\n",
      "epoch: 537 / 800, time cost: 38.26 sec, \n",
      "          Loss: [Train: p = 0.98933, q = 1.07371], \n",
      "          Loss: [Test: p = 1.01928, q = 1.39993],\n",
      "          Effect: [ate-q], [train: 0.05116], [test: 0.05204]\n",
      "********************************************************************************\n",
      "epoch: 538 / 800, time cost: 38.32 sec, \n",
      "          Loss: [Train: p = 0.98922, q = 1.07364], \n",
      "          Loss: [Test: p = 1.01928, q = 1.40085],\n",
      "          Effect: [ate-q], [train: 0.04839], [test: 0.04925]\n",
      "********************************************************************************\n",
      "epoch: 539 / 800, time cost: 37.57 sec, \n",
      "          Loss: [Train: p = 0.98927, q = 1.07374], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39509],\n",
      "          Effect: [ate-q], [train: 0.08687], [test: 0.08759]\n",
      "********************************************************************************\n",
      "epoch: 540 / 800, time cost: 40.19 sec, \n",
      "          Loss: [Train: p = 0.98926, q = 1.07347], \n",
      "          Loss: [Test: p = 1.01928, q = 1.39795],\n",
      "          Effect: [ate-q], [train: 0.05926], [test: 0.06005]\n",
      "********************************************************************************\n",
      "epoch: 541 / 800, time cost: 37.38 sec, \n",
      "          Loss: [Train: p = 0.98923, q = 1.07283], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39573],\n",
      "          Effect: [ate-q], [train: 0.07833], [test: 0.07906]\n",
      "********************************************************************************\n",
      "epoch: 542 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.98918, q = 1.07296], \n",
      "          Loss: [Test: p = 1.01922, q = 1.39682],\n",
      "          Effect: [ate-q], [train: 0.06785], [test: 0.06860]\n",
      "********************************************************************************\n",
      "epoch: 543 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98920, q = 1.07339], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39752],\n",
      "          Effect: [ate-q], [train: 0.07021], [test: 0.07103]\n",
      "********************************************************************************\n",
      "epoch: 544 / 800, time cost: 38.41 sec, \n",
      "          Loss: [Train: p = 0.98910, q = 1.07313], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39870],\n",
      "          Effect: [ate-q], [train: 0.05904], [test: 0.05982]\n",
      "********************************************************************************\n",
      "epoch: 545 / 800, time cost: 40.81 sec, \n",
      "          Loss: [Train: p = 0.98915, q = 1.07299], \n",
      "          Loss: [Test: p = 1.01928, q = 1.39940],\n",
      "          Effect: [ate-q], [train: 0.05881], [test: 0.05960]\n",
      "********************************************************************************\n",
      "epoch: 546 / 800, time cost: 38.30 sec, \n",
      "          Loss: [Train: p = 0.98912, q = 1.07376], \n",
      "          Loss: [Test: p = 1.01923, q = 1.39860],\n",
      "          Effect: [ate-q], [train: 0.06042], [test: 0.06122]\n",
      "********************************************************************************\n",
      "epoch: 547 / 800, time cost: 38.19 sec, \n",
      "          Loss: [Train: p = 0.98913, q = 1.07316], \n",
      "          Loss: [Test: p = 1.01927, q = 1.39642],\n",
      "          Effect: [ate-q], [train: 0.07301], [test: 0.07382]\n",
      "********************************************************************************\n",
      "epoch: 548 / 800, time cost: 38.04 sec, \n",
      "          Loss: [Train: p = 0.98908, q = 1.07287], \n",
      "          Loss: [Test: p = 1.01927, q = 1.39968],\n",
      "          Effect: [ate-q], [train: 0.06041], [test: 0.06117]\n",
      "********************************************************************************\n",
      "epoch: 549 / 800, time cost: 38.11 sec, \n",
      "          Loss: [Train: p = 0.98909, q = 1.07363], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39650],\n",
      "          Effect: [ate-q], [train: 0.07875], [test: 0.07946]\n",
      "********************************************************************************\n",
      "epoch: 550 / 800, time cost: 39.36 sec, \n",
      "          Loss: [Train: p = 0.98907, q = 1.07300], \n",
      "          Loss: [Test: p = 1.01929, q = 1.39650],\n",
      "          Effect: [ate-q], [train: 0.08010], [test: 0.08090]\n",
      "********************************************************************************\n",
      "epoch: 551 / 800, time cost: 36.82 sec, \n",
      "          Loss: [Train: p = 0.98893, q = 1.07302], \n",
      "          Loss: [Test: p = 1.01925, q = 1.40066],\n",
      "          Effect: [ate-q], [train: 0.05420], [test: 0.05505]\n",
      "********************************************************************************\n",
      "epoch: 552 / 800, time cost: 36.15 sec, \n",
      "          Loss: [Train: p = 0.98906, q = 1.07254], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39760],\n",
      "          Effect: [ate-q], [train: 0.07398], [test: 0.07473]\n",
      "********************************************************************************\n",
      "epoch: 553 / 800, time cost: 37.01 sec, \n",
      "          Loss: [Train: p = 0.98903, q = 1.07223], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39969],\n",
      "          Effect: [ate-q], [train: 0.05500], [test: 0.05589]\n",
      "********************************************************************************\n",
      "epoch: 554 / 800, time cost: 36.98 sec, \n",
      "          Loss: [Train: p = 0.98893, q = 1.07312], \n",
      "          Loss: [Test: p = 1.01927, q = 1.39894],\n",
      "          Effect: [ate-q], [train: 0.06809], [test: 0.06885]\n",
      "********************************************************************************\n",
      "epoch: 555 / 800, time cost: 39.35 sec, \n",
      "          Loss: [Train: p = 0.98900, q = 1.07273], \n",
      "          Loss: [Test: p = 1.01924, q = 1.39797],\n",
      "          Effect: [ate-q], [train: 0.06830], [test: 0.06907]\n",
      "********************************************************************************\n",
      "epoch: 556 / 800, time cost: 35.92 sec, \n",
      "          Loss: [Train: p = 0.98895, q = 1.07264], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39821],\n",
      "          Effect: [ate-q], [train: 0.07251], [test: 0.07330]\n",
      "********************************************************************************\n",
      "epoch: 557 / 800, time cost: 36.93 sec, \n",
      "          Loss: [Train: p = 0.98890, q = 1.07267], \n",
      "          Loss: [Test: p = 1.01925, q = 1.39951],\n",
      "          Effect: [ate-q], [train: 0.05911], [test: 0.05990]\n",
      "********************************************************************************\n",
      "epoch: 558 / 800, time cost: 38.06 sec, \n",
      "          Loss: [Train: p = 0.98893, q = 1.07223], \n",
      "          Loss: [Test: p = 1.01920, q = 1.39673],\n",
      "          Effect: [ate-q], [train: 0.07657], [test: 0.07729]\n",
      "********************************************************************************\n",
      "epoch: 559 / 800, time cost: 36.72 sec, \n",
      "          Loss: [Train: p = 0.98881, q = 1.07215], \n",
      "          Loss: [Test: p = 1.01924, q = 1.39845],\n",
      "          Effect: [ate-q], [train: 0.06869], [test: 0.06945]\n",
      "********************************************************************************\n",
      "epoch: 560 / 800, time cost: 40.23 sec, \n",
      "          Loss: [Train: p = 0.98879, q = 1.07219], \n",
      "          Loss: [Test: p = 1.01924, q = 1.39871],\n",
      "          Effect: [ate-q], [train: 0.07072], [test: 0.07153]\n",
      "********************************************************************************\n",
      "epoch: 561 / 800, time cost: 38.21 sec, \n",
      "          Loss: [Train: p = 0.98867, q = 1.07235], \n",
      "          Loss: [Test: p = 1.01922, q = 1.39942],\n",
      "          Effect: [ate-q], [train: 0.06434], [test: 0.06514]\n",
      "********************************************************************************\n",
      "epoch: 562 / 800, time cost: 38.14 sec, \n",
      "          Loss: [Train: p = 0.98879, q = 1.07229], \n",
      "          Loss: [Test: p = 1.01922, q = 1.39950],\n",
      "          Effect: [ate-q], [train: 0.06446], [test: 0.06521]\n",
      "********************************************************************************\n",
      "epoch: 563 / 800, time cost: 38.29 sec, \n",
      "          Loss: [Train: p = 0.98881, q = 1.07163], \n",
      "          Loss: [Test: p = 1.01920, q = 1.39876],\n",
      "          Effect: [ate-q], [train: 0.07331], [test: 0.07404]\n",
      "********************************************************************************\n",
      "epoch: 564 / 800, time cost: 38.53 sec, \n",
      "          Loss: [Train: p = 0.98868, q = 1.07233], \n",
      "          Loss: [Test: p = 1.01924, q = 1.40003],\n",
      "          Effect: [ate-q], [train: 0.06710], [test: 0.06788]\n",
      "********************************************************************************\n",
      "epoch: 565 / 800, time cost: 40.76 sec, \n",
      "          Loss: [Train: p = 0.98876, q = 1.07192], \n",
      "          Loss: [Test: p = 1.01921, q = 1.40225],\n",
      "          Effect: [ate-q], [train: 0.04914], [test: 0.05001]\n",
      "********************************************************************************\n",
      "epoch: 566 / 800, time cost: 38.35 sec, \n",
      "          Loss: [Train: p = 0.98869, q = 1.07172], \n",
      "          Loss: [Test: p = 1.01919, q = 1.39925],\n",
      "          Effect: [ate-q], [train: 0.07377], [test: 0.07445]\n",
      "********************************************************************************\n",
      "epoch: 567 / 800, time cost: 37.91 sec, \n",
      "          Loss: [Train: p = 0.98856, q = 1.07159], \n",
      "          Loss: [Test: p = 1.01923, q = 1.39884],\n",
      "          Effect: [ate-q], [train: 0.06942], [test: 0.07016]\n",
      "********************************************************************************\n",
      "epoch: 568 / 800, time cost: 38.52 sec, \n",
      "          Loss: [Train: p = 0.98866, q = 1.07169], \n",
      "          Loss: [Test: p = 1.01918, q = 1.39853],\n",
      "          Effect: [ate-q], [train: 0.07297], [test: 0.07373]\n",
      "********************************************************************************\n",
      "epoch: 569 / 800, time cost: 38.44 sec, \n",
      "          Loss: [Train: p = 0.98867, q = 1.07155], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40004],\n",
      "          Effect: [ate-q], [train: 0.06842], [test: 0.06917]\n",
      "********************************************************************************\n",
      "epoch: 570 / 800, time cost: 40.50 sec, \n",
      "          Loss: [Train: p = 0.98859, q = 1.07185], \n",
      "          Loss: [Test: p = 1.01923, q = 1.40008],\n",
      "          Effect: [ate-q], [train: 0.06225], [test: 0.06302]\n",
      "********************************************************************************\n",
      "epoch: 571 / 800, time cost: 37.85 sec, \n",
      "          Loss: [Train: p = 0.98854, q = 1.07161], \n",
      "          Loss: [Test: p = 1.01917, q = 1.39910],\n",
      "          Effect: [ate-q], [train: 0.07364], [test: 0.07436]\n",
      "********************************************************************************\n",
      "epoch: 572 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98843, q = 1.07180], \n",
      "          Loss: [Test: p = 1.01922, q = 1.40147],\n",
      "          Effect: [ate-q], [train: 0.05672], [test: 0.05750]\n",
      "********************************************************************************\n",
      "epoch: 573 / 800, time cost: 37.14 sec, \n",
      "          Loss: [Train: p = 0.98843, q = 1.07139], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40107],\n",
      "          Effect: [ate-q], [train: 0.05688], [test: 0.05778]\n",
      "********************************************************************************\n",
      "epoch: 574 / 800, time cost: 37.64 sec, \n",
      "          Loss: [Train: p = 0.98844, q = 1.07143], \n",
      "          Loss: [Test: p = 1.01919, q = 1.39973],\n",
      "          Effect: [ate-q], [train: 0.07228], [test: 0.07309]\n",
      "********************************************************************************\n",
      "epoch: 575 / 800, time cost: 40.44 sec, \n",
      "          Loss: [Train: p = 0.98844, q = 1.07140], \n",
      "          Loss: [Test: p = 1.01916, q = 1.39918],\n",
      "          Effect: [ate-q], [train: 0.06943], [test: 0.07020]\n",
      "********************************************************************************\n",
      "epoch: 576 / 800, time cost: 38.02 sec, \n",
      "          Loss: [Train: p = 0.98839, q = 1.07107], \n",
      "          Loss: [Test: p = 1.01916, q = 1.39894],\n",
      "          Effect: [ate-q], [train: 0.08277], [test: 0.08343]\n",
      "********************************************************************************\n",
      "epoch: 577 / 800, time cost: 38.23 sec, \n",
      "          Loss: [Train: p = 0.98846, q = 1.07121], \n",
      "          Loss: [Test: p = 1.01919, q = 1.39929],\n",
      "          Effect: [ate-q], [train: 0.07312], [test: 0.07384]\n",
      "********************************************************************************\n",
      "epoch: 578 / 800, time cost: 37.92 sec, \n",
      "          Loss: [Train: p = 0.98840, q = 1.07107], \n",
      "          Loss: [Test: p = 1.01919, q = 1.39999],\n",
      "          Effect: [ate-q], [train: 0.06997], [test: 0.07067]\n",
      "********************************************************************************\n",
      "epoch: 579 / 800, time cost: 40.59 sec, \n",
      "          Loss: [Train: p = 0.98830, q = 1.07145], \n",
      "          Loss: [Test: p = 1.01917, q = 1.40172],\n",
      "          Effect: [ate-q], [train: 0.05934], [test: 0.06021]\n",
      "********************************************************************************\n",
      "epoch: 580 / 800, time cost: 37.77 sec, \n",
      "          Loss: [Train: p = 0.98836, q = 1.07072], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40061],\n",
      "          Effect: [ate-q], [train: 0.06637], [test: 0.06706]\n",
      "********************************************************************************\n",
      "epoch: 581 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.98823, q = 1.07128], \n",
      "          Loss: [Test: p = 1.01916, q = 1.39918],\n",
      "          Effect: [ate-q], [train: 0.07920], [test: 0.07993]\n",
      "********************************************************************************\n",
      "epoch: 582 / 800, time cost: 37.94 sec, \n",
      "          Loss: [Train: p = 0.98824, q = 1.07098], \n",
      "          Loss: [Test: p = 1.01915, q = 1.40150],\n",
      "          Effect: [ate-q], [train: 0.06278], [test: 0.06349]\n",
      "********************************************************************************\n",
      "epoch: 583 / 800, time cost: 38.01 sec, \n",
      "          Loss: [Train: p = 0.98822, q = 1.07040], \n",
      "          Loss: [Test: p = 1.01911, q = 1.40144],\n",
      "          Effect: [ate-q], [train: 0.06498], [test: 0.06564]\n",
      "********************************************************************************\n",
      "epoch: 584 / 800, time cost: 40.47 sec, \n",
      "          Loss: [Train: p = 0.98826, q = 1.07089], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40230],\n",
      "          Effect: [ate-q], [train: 0.05703], [test: 0.05788]\n",
      "********************************************************************************\n",
      "epoch: 585 / 800, time cost: 37.82 sec, \n",
      "          Loss: [Train: p = 0.98818, q = 1.07079], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40036],\n",
      "          Effect: [ate-q], [train: 0.06479], [test: 0.06553]\n",
      "********************************************************************************\n",
      "epoch: 586 / 800, time cost: 37.06 sec, \n",
      "          Loss: [Train: p = 0.98814, q = 1.07077], \n",
      "          Loss: [Test: p = 1.01917, q = 1.40597],\n",
      "          Effect: [ate-q], [train: 0.04147], [test: 0.04232]\n",
      "********************************************************************************\n",
      "epoch: 587 / 800, time cost: 38.10 sec, \n",
      "          Loss: [Train: p = 0.98815, q = 1.07055], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40035],\n",
      "          Effect: [ate-q], [train: 0.06607], [test: 0.06681]\n",
      "********************************************************************************\n",
      "epoch: 588 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.98819, q = 1.06994], \n",
      "          Loss: [Test: p = 1.01918, q = 1.39963],\n",
      "          Effect: [ate-q], [train: 0.07379], [test: 0.07455]\n",
      "********************************************************************************\n",
      "epoch: 589 / 800, time cost: 40.46 sec, \n",
      "          Loss: [Train: p = 0.98812, q = 1.07014], \n",
      "          Loss: [Test: p = 1.01913, q = 1.40060],\n",
      "          Effect: [ate-q], [train: 0.07401], [test: 0.07479]\n",
      "********************************************************************************\n",
      "epoch: 590 / 800, time cost: 36.91 sec, \n",
      "          Loss: [Train: p = 0.98820, q = 1.07106], \n",
      "          Loss: [Test: p = 1.01915, q = 1.39992],\n",
      "          Effect: [ate-q], [train: 0.07622], [test: 0.07691]\n",
      "********************************************************************************\n",
      "epoch: 591 / 800, time cost: 37.96 sec, \n",
      "          Loss: [Train: p = 0.98807, q = 1.07090], \n",
      "          Loss: [Test: p = 1.01914, q = 1.40196],\n",
      "          Effect: [ate-q], [train: 0.05964], [test: 0.06043]\n",
      "********************************************************************************\n",
      "epoch: 592 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98808, q = 1.06998], \n",
      "          Loss: [Test: p = 1.01916, q = 1.40225],\n",
      "          Effect: [ate-q], [train: 0.05981], [test: 0.06052]\n",
      "********************************************************************************\n",
      "epoch: 593 / 800, time cost: 37.68 sec, \n",
      "          Loss: [Train: p = 0.98806, q = 1.07085], \n",
      "          Loss: [Test: p = 1.01918, q = 1.40502],\n",
      "          Effect: [ate-q], [train: 0.05107], [test: 0.05192]\n",
      "********************************************************************************\n",
      "epoch: 594 / 800, time cost: 39.96 sec, \n",
      "          Loss: [Train: p = 0.98808, q = 1.07068], \n",
      "          Loss: [Test: p = 1.01912, q = 1.40540],\n",
      "          Effect: [ate-q], [train: 0.04639], [test: 0.04726]\n",
      "********************************************************************************\n",
      "epoch: 595 / 800, time cost: 38.09 sec, \n",
      "          Loss: [Train: p = 0.98798, q = 1.07035], \n",
      "          Loss: [Test: p = 1.01915, q = 1.39989],\n",
      "          Effect: [ate-q], [train: 0.07976], [test: 0.08045]\n",
      "********************************************************************************\n",
      "epoch: 596 / 800, time cost: 37.87 sec, \n",
      "          Loss: [Train: p = 0.98795, q = 1.07022], \n",
      "          Loss: [Test: p = 1.01915, q = 1.40102],\n",
      "          Effect: [ate-q], [train: 0.07293], [test: 0.07363]\n",
      "********************************************************************************\n",
      "epoch: 597 / 800, time cost: 37.80 sec, \n",
      "          Loss: [Train: p = 0.98790, q = 1.06971], \n",
      "          Loss: [Test: p = 1.01912, q = 1.40254],\n",
      "          Effect: [ate-q], [train: 0.06453], [test: 0.06525]\n",
      "********************************************************************************\n",
      "epoch: 598 / 800, time cost: 37.83 sec, \n",
      "          Loss: [Train: p = 0.98788, q = 1.07005], \n",
      "          Loss: [Test: p = 1.01911, q = 1.40120],\n",
      "          Effect: [ate-q], [train: 0.07801], [test: 0.07873]\n",
      "********************************************************************************\n",
      "epoch: 599 / 800, time cost: 40.44 sec, \n",
      "          Loss: [Train: p = 0.98792, q = 1.07006], \n",
      "          Loss: [Test: p = 1.01913, q = 1.40124],\n",
      "          Effect: [ate-q], [train: 0.06976], [test: 0.07051]\n",
      "********************************************************************************\n",
      "epoch: 600 / 800, time cost: 38.04 sec, \n",
      "          Loss: [Train: p = 0.98789, q = 1.06975], \n",
      "          Loss: [Test: p = 1.01912, q = 1.40394],\n",
      "          Effect: [ate-q], [train: 0.05905], [test: 0.05983]\n",
      "********************************************************************************\n",
      "epoch: 601 / 800, time cost: 37.69 sec, \n",
      "          Loss: [Train: p = 0.98787, q = 1.06954], \n",
      "          Loss: [Test: p = 1.01911, q = 1.40201],\n",
      "          Effect: [ate-q], [train: 0.06369], [test: 0.06444]\n",
      "********************************************************************************\n",
      "epoch: 602 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.98787, q = 1.06974], \n",
      "          Loss: [Test: p = 1.01913, q = 1.40076],\n",
      "          Effect: [ate-q], [train: 0.07417], [test: 0.07482]\n",
      "********************************************************************************\n",
      "epoch: 603 / 800, time cost: 38.02 sec, \n",
      "          Loss: [Train: p = 0.98770, q = 1.06937], \n",
      "          Loss: [Test: p = 1.01914, q = 1.40498],\n",
      "          Effect: [ate-q], [train: 0.05341], [test: 0.05413]\n",
      "********************************************************************************\n",
      "epoch: 604 / 800, time cost: 40.69 sec, \n",
      "          Loss: [Train: p = 0.98775, q = 1.06983], \n",
      "          Loss: [Test: p = 1.01912, q = 1.40310],\n",
      "          Effect: [ate-q], [train: 0.06650], [test: 0.06715]\n",
      "********************************************************************************\n",
      "epoch: 605 / 800, time cost: 37.17 sec, \n",
      "          Loss: [Train: p = 0.98778, q = 1.06960], \n",
      "          Loss: [Test: p = 1.01912, q = 1.40369],\n",
      "          Effect: [ate-q], [train: 0.05875], [test: 0.05943]\n",
      "********************************************************************************\n",
      "epoch: 606 / 800, time cost: 37.75 sec, \n",
      "          Loss: [Train: p = 0.98772, q = 1.07028], \n",
      "          Loss: [Test: p = 1.01911, q = 1.40350],\n",
      "          Effect: [ate-q], [train: 0.05998], [test: 0.06074]\n",
      "********************************************************************************\n",
      "epoch: 607 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.98764, q = 1.06957], \n",
      "          Loss: [Test: p = 1.01913, q = 1.40088],\n",
      "          Effect: [ate-q], [train: 0.08049], [test: 0.08118]\n",
      "********************************************************************************\n",
      "epoch: 608 / 800, time cost: 38.19 sec, \n",
      "          Loss: [Train: p = 0.98777, q = 1.06954], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40111],\n",
      "          Effect: [ate-q], [train: 0.08286], [test: 0.08353]\n",
      "********************************************************************************\n",
      "epoch: 609 / 800, time cost: 40.07 sec, \n",
      "          Loss: [Train: p = 0.98767, q = 1.06908], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40723],\n",
      "          Effect: [ate-q], [train: 0.04170], [test: 0.04245]\n",
      "********************************************************************************\n",
      "epoch: 610 / 800, time cost: 38.37 sec, \n",
      "          Loss: [Train: p = 0.98759, q = 1.06897], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40129],\n",
      "          Effect: [ate-q], [train: 0.08766], [test: 0.08835]\n",
      "********************************************************************************\n",
      "epoch: 611 / 800, time cost: 38.30 sec, \n",
      "          Loss: [Train: p = 0.98760, q = 1.06955], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40454],\n",
      "          Effect: [ate-q], [train: 0.06111], [test: 0.06182]\n",
      "********************************************************************************\n",
      "epoch: 612 / 800, time cost: 37.97 sec, \n",
      "          Loss: [Train: p = 0.98760, q = 1.06896], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40246],\n",
      "          Effect: [ate-q], [train: 0.06814], [test: 0.06881]\n",
      "********************************************************************************\n",
      "epoch: 613 / 800, time cost: 40.69 sec, \n",
      "          Loss: [Train: p = 0.98761, q = 1.06934], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40168],\n",
      "          Effect: [ate-q], [train: 0.08719], [test: 0.08786]\n",
      "********************************************************************************\n",
      "epoch: 614 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98755, q = 1.06920], \n",
      "          Loss: [Test: p = 1.01906, q = 1.40251],\n",
      "          Effect: [ate-q], [train: 0.07579], [test: 0.07646]\n",
      "********************************************************************************\n",
      "epoch: 615 / 800, time cost: 38.14 sec, \n",
      "          Loss: [Train: p = 0.98759, q = 1.06852], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40269],\n",
      "          Effect: [ate-q], [train: 0.07197], [test: 0.07269]\n",
      "********************************************************************************\n",
      "epoch: 616 / 800, time cost: 37.90 sec, \n",
      "          Loss: [Train: p = 0.98760, q = 1.06868], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40172],\n",
      "          Effect: [ate-q], [train: 0.08124], [test: 0.08186]\n",
      "********************************************************************************\n",
      "epoch: 617 / 800, time cost: 39.30 sec, \n",
      "          Loss: [Train: p = 0.98757, q = 1.06888], \n",
      "          Loss: [Test: p = 1.01904, q = 1.40169],\n",
      "          Effect: [ate-q], [train: 0.08256], [test: 0.08319]\n",
      "********************************************************************************\n",
      "epoch: 618 / 800, time cost: 47.59 sec, \n",
      "          Loss: [Train: p = 0.98745, q = 1.06862], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40331],\n",
      "          Effect: [ate-q], [train: 0.06854], [test: 0.06929]\n",
      "********************************************************************************\n",
      "epoch: 619 / 800, time cost: 44.92 sec, \n",
      "          Loss: [Train: p = 0.98756, q = 1.06891], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40772],\n",
      "          Effect: [ate-q], [train: 0.04636], [test: 0.04715]\n",
      "********************************************************************************\n",
      "epoch: 620 / 800, time cost: 44.99 sec, \n",
      "          Loss: [Train: p = 0.98738, q = 1.06847], \n",
      "          Loss: [Test: p = 1.01910, q = 1.40738],\n",
      "          Effect: [ate-q], [train: 0.04785], [test: 0.04865]\n",
      "********************************************************************************\n",
      "epoch: 621 / 800, time cost: 44.94 sec, \n",
      "          Loss: [Train: p = 0.98739, q = 1.06849], \n",
      "          Loss: [Test: p = 1.01910, q = 1.40524],\n",
      "          Effect: [ate-q], [train: 0.05703], [test: 0.05782]\n",
      "********************************************************************************\n",
      "epoch: 622 / 800, time cost: 45.38 sec, \n",
      "          Loss: [Train: p = 0.98746, q = 1.06838], \n",
      "          Loss: [Test: p = 1.01906, q = 1.40293],\n",
      "          Effect: [ate-q], [train: 0.06841], [test: 0.06912]\n",
      "********************************************************************************\n",
      "epoch: 623 / 800, time cost: 42.83 sec, \n",
      "          Loss: [Train: p = 0.98728, q = 1.06829], \n",
      "          Loss: [Test: p = 1.01907, q = 1.40341],\n",
      "          Effect: [ate-q], [train: 0.06582], [test: 0.06652]\n",
      "********************************************************************************\n",
      "epoch: 624 / 800, time cost: 38.12 sec, \n",
      "          Loss: [Train: p = 0.98748, q = 1.06873], \n",
      "          Loss: [Test: p = 1.01906, q = 1.40736],\n",
      "          Effect: [ate-q], [train: 0.04703], [test: 0.04783]\n",
      "********************************************************************************\n",
      "epoch: 625 / 800, time cost: 38.19 sec, \n",
      "          Loss: [Train: p = 0.98732, q = 1.06856], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40339],\n",
      "          Effect: [ate-q], [train: 0.07216], [test: 0.07286]\n",
      "********************************************************************************\n",
      "epoch: 626 / 800, time cost: 38.11 sec, \n",
      "          Loss: [Train: p = 0.98728, q = 1.06848], \n",
      "          Loss: [Test: p = 1.01906, q = 1.40687],\n",
      "          Effect: [ate-q], [train: 0.04950], [test: 0.05032]\n",
      "********************************************************************************\n",
      "epoch: 627 / 800, time cost: 38.13 sec, \n",
      "          Loss: [Train: p = 0.98727, q = 1.06815], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40770],\n",
      "          Effect: [ate-q], [train: 0.04651], [test: 0.04734]\n",
      "********************************************************************************\n",
      "epoch: 628 / 800, time cost: 40.56 sec, \n",
      "          Loss: [Train: p = 0.98731, q = 1.06832], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40573],\n",
      "          Effect: [ate-q], [train: 0.05542], [test: 0.05621]\n",
      "********************************************************************************\n",
      "epoch: 629 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.98722, q = 1.06820], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40498],\n",
      "          Effect: [ate-q], [train: 0.06656], [test: 0.06725]\n",
      "********************************************************************************\n",
      "epoch: 630 / 800, time cost: 37.76 sec, \n",
      "          Loss: [Train: p = 0.98715, q = 1.06827], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40275],\n",
      "          Effect: [ate-q], [train: 0.07866], [test: 0.07929]\n",
      "********************************************************************************\n",
      "epoch: 631 / 800, time cost: 37.85 sec, \n",
      "          Loss: [Train: p = 0.98714, q = 1.06760], \n",
      "          Loss: [Test: p = 1.01907, q = 1.41139],\n",
      "          Effect: [ate-q], [train: 0.03729], [test: 0.03809]\n",
      "********************************************************************************\n",
      "epoch: 632 / 800, time cost: 38.60 sec, \n",
      "          Loss: [Train: p = 0.98722, q = 1.06817], \n",
      "          Loss: [Test: p = 1.01904, q = 1.40543],\n",
      "          Effect: [ate-q], [train: 0.06423], [test: 0.06497]\n",
      "********************************************************************************\n",
      "epoch: 633 / 800, time cost: 40.48 sec, \n",
      "          Loss: [Train: p = 0.98706, q = 1.06811], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40696],\n",
      "          Effect: [ate-q], [train: 0.05240], [test: 0.05317]\n",
      "********************************************************************************\n",
      "epoch: 634 / 800, time cost: 37.93 sec, \n",
      "          Loss: [Train: p = 0.98707, q = 1.06804], \n",
      "          Loss: [Test: p = 1.01904, q = 1.40598],\n",
      "          Effect: [ate-q], [train: 0.05764], [test: 0.05841]\n",
      "********************************************************************************\n",
      "epoch: 635 / 800, time cost: 37.48 sec, \n",
      "          Loss: [Train: p = 0.98711, q = 1.06784], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40224],\n",
      "          Effect: [ate-q], [train: 0.08788], [test: 0.08846]\n",
      "********************************************************************************\n",
      "epoch: 636 / 800, time cost: 38.22 sec, \n",
      "          Loss: [Train: p = 0.98702, q = 1.06814], \n",
      "          Loss: [Test: p = 1.01909, q = 1.40362],\n",
      "          Effect: [ate-q], [train: 0.07746], [test: 0.07810]\n",
      "********************************************************************************\n",
      "epoch: 637 / 800, time cost: 38.01 sec, \n",
      "          Loss: [Train: p = 0.98707, q = 1.06773], \n",
      "          Loss: [Test: p = 1.01903, q = 1.40948],\n",
      "          Effect: [ate-q], [train: 0.04185], [test: 0.04270]\n",
      "********************************************************************************\n",
      "epoch: 638 / 800, time cost: 40.50 sec, \n",
      "          Loss: [Train: p = 0.98704, q = 1.06783], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40621],\n",
      "          Effect: [ate-q], [train: 0.06383], [test: 0.06448]\n",
      "********************************************************************************\n",
      "epoch: 639 / 800, time cost: 37.82 sec, \n",
      "          Loss: [Train: p = 0.98693, q = 1.06748], \n",
      "          Loss: [Test: p = 1.01905, q = 1.41048],\n",
      "          Effect: [ate-q], [train: 0.04039], [test: 0.04114]\n",
      "********************************************************************************\n",
      "epoch: 640 / 800, time cost: 37.96 sec, \n",
      "          Loss: [Train: p = 0.98699, q = 1.06727], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40406],\n",
      "          Effect: [ate-q], [train: 0.07342], [test: 0.07404]\n",
      "********************************************************************************\n",
      "epoch: 641 / 800, time cost: 38.09 sec, \n",
      "          Loss: [Train: p = 0.98697, q = 1.06759], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40671],\n",
      "          Effect: [ate-q], [train: 0.06293], [test: 0.06357]\n",
      "********************************************************************************\n",
      "epoch: 642 / 800, time cost: 37.79 sec, \n",
      "          Loss: [Train: p = 0.98701, q = 1.06782], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40503],\n",
      "          Effect: [ate-q], [train: 0.07090], [test: 0.07156]\n",
      "********************************************************************************\n",
      "epoch: 643 / 800, time cost: 40.36 sec, \n",
      "          Loss: [Train: p = 0.98691, q = 1.06726], \n",
      "          Loss: [Test: p = 1.01908, q = 1.40649],\n",
      "          Effect: [ate-q], [train: 0.06120], [test: 0.06194]\n",
      "********************************************************************************\n",
      "epoch: 644 / 800, time cost: 38.03 sec, \n",
      "          Loss: [Train: p = 0.98695, q = 1.06715], \n",
      "          Loss: [Test: p = 1.01903, q = 1.40896],\n",
      "          Effect: [ate-q], [train: 0.05265], [test: 0.05343]\n",
      "********************************************************************************\n",
      "epoch: 645 / 800, time cost: 37.90 sec, \n",
      "          Loss: [Train: p = 0.98697, q = 1.06722], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40596],\n",
      "          Effect: [ate-q], [train: 0.06834], [test: 0.06899]\n",
      "********************************************************************************\n",
      "epoch: 646 / 800, time cost: 38.02 sec, \n",
      "          Loss: [Train: p = 0.98684, q = 1.06685], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40593],\n",
      "          Effect: [ate-q], [train: 0.06513], [test: 0.06578]\n",
      "********************************************************************************\n",
      "epoch: 647 / 800, time cost: 40.19 sec, \n",
      "          Loss: [Train: p = 0.98676, q = 1.06748], \n",
      "          Loss: [Test: p = 1.01900, q = 1.40675],\n",
      "          Effect: [ate-q], [train: 0.06187], [test: 0.06258]\n",
      "********************************************************************************\n",
      "epoch: 648 / 800, time cost: 37.90 sec, \n",
      "          Loss: [Train: p = 0.98672, q = 1.06654], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40713],\n",
      "          Effect: [ate-q], [train: 0.05445], [test: 0.05517]\n",
      "********************************************************************************\n",
      "epoch: 649 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98670, q = 1.06706], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40695],\n",
      "          Effect: [ate-q], [train: 0.06431], [test: 0.06503]\n",
      "********************************************************************************\n",
      "epoch: 650 / 800, time cost: 38.07 sec, \n",
      "          Loss: [Train: p = 0.98667, q = 1.06681], \n",
      "          Loss: [Test: p = 1.01906, q = 1.40530],\n",
      "          Effect: [ate-q], [train: 0.07087], [test: 0.07152]\n",
      "********************************************************************************\n",
      "epoch: 651 / 800, time cost: 38.51 sec, \n",
      "          Loss: [Train: p = 0.98669, q = 1.06692], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40810],\n",
      "          Effect: [ate-q], [train: 0.05866], [test: 0.05935]\n",
      "********************************************************************************\n",
      "epoch: 652 / 800, time cost: 40.81 sec, \n",
      "          Loss: [Train: p = 0.98678, q = 1.06675], \n",
      "          Loss: [Test: p = 1.01905, q = 1.40740],\n",
      "          Effect: [ate-q], [train: 0.05778], [test: 0.05853]\n",
      "********************************************************************************\n",
      "epoch: 653 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98663, q = 1.06690], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40719],\n",
      "          Effect: [ate-q], [train: 0.05726], [test: 0.05792]\n",
      "********************************************************************************\n",
      "epoch: 654 / 800, time cost: 37.55 sec, \n",
      "          Loss: [Train: p = 0.98657, q = 1.06655], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40467],\n",
      "          Effect: [ate-q], [train: 0.08111], [test: 0.08167]\n",
      "********************************************************************************\n",
      "epoch: 655 / 800, time cost: 38.50 sec, \n",
      "          Loss: [Train: p = 0.98663, q = 1.06681], \n",
      "          Loss: [Test: p = 1.01904, q = 1.40618],\n",
      "          Effect: [ate-q], [train: 0.06898], [test: 0.06965]\n",
      "********************************************************************************\n",
      "epoch: 656 / 800, time cost: 44.28 sec, \n",
      "          Loss: [Train: p = 0.98652, q = 1.06662], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40444],\n",
      "          Effect: [ate-q], [train: 0.09225], [test: 0.09276]\n",
      "********************************************************************************\n",
      "epoch: 657 / 800, time cost: 40.71 sec, \n",
      "          Loss: [Train: p = 0.98655, q = 1.06654], \n",
      "          Loss: [Test: p = 1.01900, q = 1.40837],\n",
      "          Effect: [ate-q], [train: 0.05334], [test: 0.05412]\n",
      "********************************************************************************\n",
      "epoch: 658 / 800, time cost: 37.58 sec, \n",
      "          Loss: [Train: p = 0.98646, q = 1.06644], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40687],\n",
      "          Effect: [ate-q], [train: 0.06598], [test: 0.06656]\n",
      "********************************************************************************\n",
      "epoch: 659 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.98645, q = 1.06656], \n",
      "          Loss: [Test: p = 1.01900, q = 1.41026],\n",
      "          Effect: [ate-q], [train: 0.04824], [test: 0.04902]\n",
      "********************************************************************************\n",
      "epoch: 660 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.98647, q = 1.06670], \n",
      "          Loss: [Test: p = 1.01903, q = 1.40934],\n",
      "          Effect: [ate-q], [train: 0.05173], [test: 0.05232]\n",
      "********************************************************************************\n",
      "epoch: 661 / 800, time cost: 38.20 sec, \n",
      "          Loss: [Train: p = 0.98652, q = 1.06607], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40664],\n",
      "          Effect: [ate-q], [train: 0.07054], [test: 0.07119]\n",
      "********************************************************************************\n",
      "epoch: 662 / 800, time cost: 40.32 sec, \n",
      "          Loss: [Train: p = 0.98649, q = 1.06654], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40630],\n",
      "          Effect: [ate-q], [train: 0.06858], [test: 0.06921]\n",
      "********************************************************************************\n",
      "epoch: 663 / 800, time cost: 37.95 sec, \n",
      "          Loss: [Train: p = 0.98655, q = 1.06634], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40751],\n",
      "          Effect: [ate-q], [train: 0.06609], [test: 0.06676]\n",
      "********************************************************************************\n",
      "epoch: 664 / 800, time cost: 38.05 sec, \n",
      "          Loss: [Train: p = 0.98648, q = 1.06615], \n",
      "          Loss: [Test: p = 1.01907, q = 1.40558],\n",
      "          Effect: [ate-q], [train: 0.07356], [test: 0.07422]\n",
      "********************************************************************************\n",
      "epoch: 665 / 800, time cost: 37.99 sec, \n",
      "          Loss: [Train: p = 0.98638, q = 1.06566], \n",
      "          Loss: [Test: p = 1.01903, q = 1.40597],\n",
      "          Effect: [ate-q], [train: 0.07078], [test: 0.07149]\n",
      "********************************************************************************\n",
      "epoch: 666 / 800, time cost: 38.06 sec, \n",
      "          Loss: [Train: p = 0.98641, q = 1.06570], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40745],\n",
      "          Effect: [ate-q], [train: 0.06568], [test: 0.06636]\n",
      "********************************************************************************\n",
      "epoch: 667 / 800, time cost: 40.53 sec, \n",
      "          Loss: [Train: p = 0.98642, q = 1.06617], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40897],\n",
      "          Effect: [ate-q], [train: 0.05639], [test: 0.05708]\n",
      "********************************************************************************\n",
      "epoch: 668 / 800, time cost: 38.00 sec, \n",
      "          Loss: [Train: p = 0.98630, q = 1.06573], \n",
      "          Loss: [Test: p = 1.01901, q = 1.41094],\n",
      "          Effect: [ate-q], [train: 0.05121], [test: 0.05195]\n",
      "********************************************************************************\n",
      "epoch: 669 / 800, time cost: 37.95 sec, \n",
      "          Loss: [Train: p = 0.98628, q = 1.06607], \n",
      "          Loss: [Test: p = 1.01900, q = 1.40675],\n",
      "          Effect: [ate-q], [train: 0.07035], [test: 0.07103]\n",
      "********************************************************************************\n",
      "epoch: 670 / 800, time cost: 37.93 sec, \n",
      "          Loss: [Train: p = 0.98623, q = 1.06610], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40984],\n",
      "          Effect: [ate-q], [train: 0.05827], [test: 0.05894]\n",
      "********************************************************************************\n",
      "epoch: 671 / 800, time cost: 38.43 sec, \n",
      "          Loss: [Train: p = 0.98627, q = 1.06566], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40961],\n",
      "          Effect: [ate-q], [train: 0.05562], [test: 0.05630]\n",
      "********************************************************************************\n",
      "epoch: 672 / 800, time cost: 40.55 sec, \n",
      "          Loss: [Train: p = 0.98633, q = 1.06623], \n",
      "          Loss: [Test: p = 1.01902, q = 1.40533],\n",
      "          Effect: [ate-q], [train: 0.09017], [test: 0.09071]\n",
      "********************************************************************************\n",
      "epoch: 673 / 800, time cost: 37.89 sec, \n",
      "          Loss: [Train: p = 0.98630, q = 1.06591], \n",
      "          Loss: [Test: p = 1.01901, q = 1.41226],\n",
      "          Effect: [ate-q], [train: 0.04119], [test: 0.04202]\n",
      "********************************************************************************\n",
      "epoch: 674 / 800, time cost: 37.78 sec, \n",
      "          Loss: [Train: p = 0.98619, q = 1.06546], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40943],\n",
      "          Effect: [ate-q], [train: 0.05788], [test: 0.05852]\n",
      "********************************************************************************\n",
      "epoch: 675 / 800, time cost: 38.24 sec, \n",
      "          Loss: [Train: p = 0.98611, q = 1.06553], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40651],\n",
      "          Effect: [ate-q], [train: 0.06447], [test: 0.06515]\n",
      "********************************************************************************\n",
      "epoch: 676 / 800, time cost: 38.53 sec, \n",
      "          Loss: [Train: p = 0.98610, q = 1.06550], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40909],\n",
      "          Effect: [ate-q], [train: 0.05727], [test: 0.05791]\n",
      "********************************************************************************\n",
      "epoch: 677 / 800, time cost: 40.53 sec, \n",
      "          Loss: [Train: p = 0.98606, q = 1.06550], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40975],\n",
      "          Effect: [ate-q], [train: 0.05132], [test: 0.05206]\n",
      "********************************************************************************\n",
      "epoch: 678 / 800, time cost: 37.93 sec, \n",
      "          Loss: [Train: p = 0.98610, q = 1.06583], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40866],\n",
      "          Effect: [ate-q], [train: 0.06237], [test: 0.06310]\n",
      "********************************************************************************\n",
      "epoch: 679 / 800, time cost: 38.24 sec, \n",
      "          Loss: [Train: p = 0.98615, q = 1.06533], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40613],\n",
      "          Effect: [ate-q], [train: 0.08829], [test: 0.08880]\n",
      "********************************************************************************\n",
      "epoch: 680 / 800, time cost: 38.39 sec, \n",
      "          Loss: [Train: p = 0.98607, q = 1.06506], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41060],\n",
      "          Effect: [ate-q], [train: 0.05406], [test: 0.05475]\n",
      "********************************************************************************\n",
      "epoch: 681 / 800, time cost: 38.13 sec, \n",
      "          Loss: [Train: p = 0.98605, q = 1.06549], \n",
      "          Loss: [Test: p = 1.01900, q = 1.40680],\n",
      "          Effect: [ate-q], [train: 0.07698], [test: 0.07750]\n",
      "********************************************************************************\n",
      "epoch: 682 / 800, time cost: 40.04 sec, \n",
      "          Loss: [Train: p = 0.98596, q = 1.06515], \n",
      "          Loss: [Test: p = 1.01891, q = 1.40843],\n",
      "          Effect: [ate-q], [train: 0.06324], [test: 0.06380]\n",
      "********************************************************************************\n",
      "epoch: 683 / 800, time cost: 38.16 sec, \n",
      "          Loss: [Train: p = 0.98604, q = 1.06475], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40877],\n",
      "          Effect: [ate-q], [train: 0.07111], [test: 0.07168]\n",
      "********************************************************************************\n",
      "epoch: 684 / 800, time cost: 38.23 sec, \n",
      "          Loss: [Train: p = 0.98597, q = 1.06513], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41051],\n",
      "          Effect: [ate-q], [train: 0.05392], [test: 0.05452]\n",
      "********************************************************************************\n",
      "epoch: 685 / 800, time cost: 38.13 sec, \n",
      "          Loss: [Train: p = 0.98595, q = 1.06497], \n",
      "          Loss: [Test: p = 1.01900, q = 1.40836],\n",
      "          Effect: [ate-q], [train: 0.07172], [test: 0.07243]\n",
      "********************************************************************************\n",
      "epoch: 686 / 800, time cost: 40.54 sec, \n",
      "          Loss: [Train: p = 0.98591, q = 1.06508], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40765],\n",
      "          Effect: [ate-q], [train: 0.07595], [test: 0.07653]\n",
      "********************************************************************************\n",
      "epoch: 687 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98585, q = 1.06465], \n",
      "          Loss: [Test: p = 1.01896, q = 1.40902],\n",
      "          Effect: [ate-q], [train: 0.06176], [test: 0.06248]\n",
      "********************************************************************************\n",
      "epoch: 688 / 800, time cost: 37.96 sec, \n",
      "          Loss: [Train: p = 0.98592, q = 1.06529], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40927],\n",
      "          Effect: [ate-q], [train: 0.06181], [test: 0.06240]\n",
      "********************************************************************************\n",
      "epoch: 689 / 800, time cost: 36.63 sec, \n",
      "          Loss: [Train: p = 0.98583, q = 1.06522], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41404],\n",
      "          Effect: [ate-q], [train: 0.04425], [test: 0.04501]\n",
      "********************************************************************************\n",
      "epoch: 690 / 800, time cost: 36.84 sec, \n",
      "          Loss: [Train: p = 0.98584, q = 1.06509], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41106],\n",
      "          Effect: [ate-q], [train: 0.06262], [test: 0.06332]\n",
      "********************************************************************************\n",
      "epoch: 691 / 800, time cost: 40.62 sec, \n",
      "          Loss: [Train: p = 0.98576, q = 1.06443], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40917],\n",
      "          Effect: [ate-q], [train: 0.06761], [test: 0.06823]\n",
      "********************************************************************************\n",
      "epoch: 692 / 800, time cost: 38.04 sec, \n",
      "          Loss: [Train: p = 0.98571, q = 1.06455], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40723],\n",
      "          Effect: [ate-q], [train: 0.08515], [test: 0.08567]\n",
      "********************************************************************************\n",
      "epoch: 693 / 800, time cost: 37.58 sec, \n",
      "          Loss: [Train: p = 0.98579, q = 1.06497], \n",
      "          Loss: [Test: p = 1.01898, q = 1.40820],\n",
      "          Effect: [ate-q], [train: 0.08441], [test: 0.08494]\n",
      "********************************************************************************\n",
      "epoch: 694 / 800, time cost: 38.15 sec, \n",
      "          Loss: [Train: p = 0.98580, q = 1.06503], \n",
      "          Loss: [Test: p = 1.01900, q = 1.41290],\n",
      "          Effect: [ate-q], [train: 0.04797], [test: 0.04866]\n",
      "********************************************************************************\n",
      "epoch: 695 / 800, time cost: 38.39 sec, \n",
      "          Loss: [Train: p = 0.98572, q = 1.06457], \n",
      "          Loss: [Test: p = 1.01899, q = 1.40680],\n",
      "          Effect: [ate-q], [train: 0.08426], [test: 0.08484]\n",
      "********************************************************************************\n",
      "epoch: 696 / 800, time cost: 40.63 sec, \n",
      "          Loss: [Train: p = 0.98563, q = 1.06450], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41624],\n",
      "          Effect: [ate-q], [train: 0.03846], [test: 0.03927]\n",
      "********************************************************************************\n",
      "epoch: 697 / 800, time cost: 37.11 sec, \n",
      "          Loss: [Train: p = 0.98570, q = 1.06425], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40864],\n",
      "          Effect: [ate-q], [train: 0.07027], [test: 0.07088]\n",
      "********************************************************************************\n",
      "epoch: 698 / 800, time cost: 38.09 sec, \n",
      "          Loss: [Train: p = 0.98560, q = 1.06404], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41050],\n",
      "          Effect: [ate-q], [train: 0.06091], [test: 0.06156]\n",
      "********************************************************************************\n",
      "epoch: 699 / 800, time cost: 38.34 sec, \n",
      "          Loss: [Train: p = 0.98564, q = 1.06404], \n",
      "          Loss: [Test: p = 1.01901, q = 1.40779],\n",
      "          Effect: [ate-q], [train: 0.08262], [test: 0.08317]\n",
      "********************************************************************************\n",
      "epoch: 700 / 800, time cost: 38.40 sec, \n",
      "          Loss: [Train: p = 0.98557, q = 1.06415], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40967],\n",
      "          Effect: [ate-q], [train: 0.07212], [test: 0.07277]\n",
      "********************************************************************************\n",
      "epoch: 701 / 800, time cost: 40.48 sec, \n",
      "          Loss: [Train: p = 0.98549, q = 1.06432], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41035],\n",
      "          Effect: [ate-q], [train: 0.06535], [test: 0.06599]\n",
      "********************************************************************************\n",
      "epoch: 702 / 800, time cost: 38.31 sec, \n",
      "          Loss: [Train: p = 0.98561, q = 1.06429], \n",
      "          Loss: [Test: p = 1.01894, q = 1.40871],\n",
      "          Effect: [ate-q], [train: 0.07882], [test: 0.07938]\n",
      "********************************************************************************\n",
      "epoch: 703 / 800, time cost: 37.72 sec, \n",
      "          Loss: [Train: p = 0.98558, q = 1.06425], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40860],\n",
      "          Effect: [ate-q], [train: 0.07201], [test: 0.07259]\n",
      "********************************************************************************\n",
      "epoch: 704 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98554, q = 1.06405], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41261],\n",
      "          Effect: [ate-q], [train: 0.05547], [test: 0.05617]\n",
      "********************************************************************************\n",
      "epoch: 705 / 800, time cost: 38.57 sec, \n",
      "          Loss: [Train: p = 0.98554, q = 1.06393], \n",
      "          Loss: [Test: p = 1.01897, q = 1.40866],\n",
      "          Effect: [ate-q], [train: 0.07402], [test: 0.07459]\n",
      "********************************************************************************\n",
      "epoch: 706 / 800, time cost: 40.64 sec, \n",
      "          Loss: [Train: p = 0.98559, q = 1.06411], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41136],\n",
      "          Effect: [ate-q], [train: 0.05672], [test: 0.05739]\n",
      "********************************************************************************\n",
      "epoch: 707 / 800, time cost: 37.72 sec, \n",
      "          Loss: [Train: p = 0.98549, q = 1.06428], \n",
      "          Loss: [Test: p = 1.01897, q = 1.41252],\n",
      "          Effect: [ate-q], [train: 0.05476], [test: 0.05550]\n",
      "********************************************************************************\n",
      "epoch: 708 / 800, time cost: 36.24 sec, \n",
      "          Loss: [Train: p = 0.98540, q = 1.06409], \n",
      "          Loss: [Test: p = 1.01896, q = 1.40789],\n",
      "          Effect: [ate-q], [train: 0.09041], [test: 0.09093]\n",
      "********************************************************************************\n",
      "epoch: 709 / 800, time cost: 38.28 sec, \n",
      "          Loss: [Train: p = 0.98540, q = 1.06376], \n",
      "          Loss: [Test: p = 1.01894, q = 1.40885],\n",
      "          Effect: [ate-q], [train: 0.07817], [test: 0.07875]\n",
      "********************************************************************************\n",
      "epoch: 710 / 800, time cost: 38.48 sec, \n",
      "          Loss: [Train: p = 0.98533, q = 1.06368], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41118],\n",
      "          Effect: [ate-q], [train: 0.06558], [test: 0.06621]\n",
      "********************************************************************************\n",
      "epoch: 711 / 800, time cost: 40.62 sec, \n",
      "          Loss: [Train: p = 0.98539, q = 1.06392], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41289],\n",
      "          Effect: [ate-q], [train: 0.05041], [test: 0.05106]\n",
      "********************************************************************************\n",
      "epoch: 712 / 800, time cost: 36.36 sec, \n",
      "          Loss: [Train: p = 0.98529, q = 1.06362], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41058],\n",
      "          Effect: [ate-q], [train: 0.06879], [test: 0.06944]\n",
      "********************************************************************************\n",
      "epoch: 713 / 800, time cost: 37.17 sec, \n",
      "          Loss: [Train: p = 0.98521, q = 1.06289], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41177],\n",
      "          Effect: [ate-q], [train: 0.05802], [test: 0.05864]\n",
      "********************************************************************************\n",
      "epoch: 714 / 800, time cost: 38.57 sec, \n",
      "          Loss: [Train: p = 0.98529, q = 1.06383], \n",
      "          Loss: [Test: p = 1.01897, q = 1.41500],\n",
      "          Effect: [ate-q], [train: 0.04371], [test: 0.04440]\n",
      "********************************************************************************\n",
      "epoch: 715 / 800, time cost: 38.13 sec, \n",
      "          Loss: [Train: p = 0.98524, q = 1.06330], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41180],\n",
      "          Effect: [ate-q], [train: 0.06368], [test: 0.06438]\n",
      "********************************************************************************\n",
      "epoch: 716 / 800, time cost: 40.17 sec, \n",
      "          Loss: [Train: p = 0.98523, q = 1.06325], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41149],\n",
      "          Effect: [ate-q], [train: 0.06184], [test: 0.06244]\n",
      "********************************************************************************\n",
      "epoch: 717 / 800, time cost: 38.12 sec, \n",
      "          Loss: [Train: p = 0.98512, q = 1.06342], \n",
      "          Loss: [Test: p = 1.01893, q = 1.41198],\n",
      "          Effect: [ate-q], [train: 0.06536], [test: 0.06594]\n",
      "********************************************************************************\n",
      "epoch: 718 / 800, time cost: 38.21 sec, \n",
      "          Loss: [Train: p = 0.98507, q = 1.06351], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41048],\n",
      "          Effect: [ate-q], [train: 0.06296], [test: 0.06361]\n",
      "********************************************************************************\n",
      "epoch: 719 / 800, time cost: 37.94 sec, \n",
      "          Loss: [Train: p = 0.98522, q = 1.06357], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41086],\n",
      "          Effect: [ate-q], [train: 0.06603], [test: 0.06659]\n",
      "********************************************************************************\n",
      "epoch: 720 / 800, time cost: 40.42 sec, \n",
      "          Loss: [Train: p = 0.98512, q = 1.06288], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41108],\n",
      "          Effect: [ate-q], [train: 0.06787], [test: 0.06842]\n",
      "********************************************************************************\n",
      "epoch: 721 / 800, time cost: 37.99 sec, \n",
      "          Loss: [Train: p = 0.98520, q = 1.06316], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41470],\n",
      "          Effect: [ate-q], [train: 0.05028], [test: 0.05085]\n",
      "********************************************************************************\n",
      "epoch: 722 / 800, time cost: 37.84 sec, \n",
      "          Loss: [Train: p = 0.98513, q = 1.06302], \n",
      "          Loss: [Test: p = 1.01890, q = 1.41096],\n",
      "          Effect: [ate-q], [train: 0.07670], [test: 0.07728]\n",
      "********************************************************************************\n",
      "epoch: 723 / 800, time cost: 37.94 sec, \n",
      "          Loss: [Train: p = 0.98503, q = 1.06294], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41388],\n",
      "          Effect: [ate-q], [train: 0.05384], [test: 0.05446]\n",
      "********************************************************************************\n",
      "epoch: 724 / 800, time cost: 38.46 sec, \n",
      "          Loss: [Train: p = 0.98509, q = 1.06270], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41058],\n",
      "          Effect: [ate-q], [train: 0.07023], [test: 0.07085]\n",
      "********************************************************************************\n",
      "epoch: 725 / 800, time cost: 40.93 sec, \n",
      "          Loss: [Train: p = 0.98504, q = 1.06259], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41240],\n",
      "          Effect: [ate-q], [train: 0.06331], [test: 0.06388]\n",
      "********************************************************************************\n",
      "epoch: 726 / 800, time cost: 38.40 sec, \n",
      "          Loss: [Train: p = 0.98499, q = 1.06257], \n",
      "          Loss: [Test: p = 1.01893, q = 1.41196],\n",
      "          Effect: [ate-q], [train: 0.07071], [test: 0.07132]\n",
      "********************************************************************************\n",
      "epoch: 727 / 800, time cost: 37.46 sec, \n",
      "          Loss: [Train: p = 0.98497, q = 1.06251], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41331],\n",
      "          Effect: [ate-q], [train: 0.06020], [test: 0.06083]\n",
      "********************************************************************************\n",
      "epoch: 728 / 800, time cost: 38.43 sec, \n",
      "          Loss: [Train: p = 0.98493, q = 1.06351], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41124],\n",
      "          Effect: [ate-q], [train: 0.06861], [test: 0.06919]\n",
      "********************************************************************************\n",
      "epoch: 729 / 800, time cost: 38.68 sec, \n",
      "          Loss: [Train: p = 0.98496, q = 1.06245], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41309],\n",
      "          Effect: [ate-q], [train: 0.05921], [test: 0.05983]\n",
      "********************************************************************************\n",
      "epoch: 730 / 800, time cost: 40.79 sec, \n",
      "          Loss: [Train: p = 0.98497, q = 1.06270], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41441],\n",
      "          Effect: [ate-q], [train: 0.05440], [test: 0.05507]\n",
      "********************************************************************************\n",
      "epoch: 731 / 800, time cost: 37.26 sec, \n",
      "          Loss: [Train: p = 0.98490, q = 1.06256], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41274],\n",
      "          Effect: [ate-q], [train: 0.06584], [test: 0.06640]\n",
      "********************************************************************************\n",
      "epoch: 732 / 800, time cost: 38.25 sec, \n",
      "          Loss: [Train: p = 0.98488, q = 1.06265], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41103],\n",
      "          Effect: [ate-q], [train: 0.08156], [test: 0.08215]\n",
      "********************************************************************************\n",
      "epoch: 733 / 800, time cost: 38.43 sec, \n",
      "          Loss: [Train: p = 0.98480, q = 1.06307], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41429],\n",
      "          Effect: [ate-q], [train: 0.05460], [test: 0.05522]\n",
      "********************************************************************************\n",
      "epoch: 734 / 800, time cost: 42.34 sec, \n",
      "          Loss: [Train: p = 0.98471, q = 1.06208], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41587],\n",
      "          Effect: [ate-q], [train: 0.05089], [test: 0.05160]\n",
      "********************************************************************************\n",
      "epoch: 735 / 800, time cost: 47.76 sec, \n",
      "          Loss: [Train: p = 0.98481, q = 1.06258], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41138],\n",
      "          Effect: [ate-q], [train: 0.06696], [test: 0.06749]\n",
      "********************************************************************************\n",
      "epoch: 736 / 800, time cost: 42.29 sec, \n",
      "          Loss: [Train: p = 0.98474, q = 1.06240], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41243],\n",
      "          Effect: [ate-q], [train: 0.06939], [test: 0.06995]\n",
      "********************************************************************************\n",
      "epoch: 737 / 800, time cost: 38.52 sec, \n",
      "          Loss: [Train: p = 0.98483, q = 1.06254], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41088],\n",
      "          Effect: [ate-q], [train: 0.07296], [test: 0.07347]\n",
      "********************************************************************************\n",
      "epoch: 738 / 800, time cost: 38.31 sec, \n",
      "          Loss: [Train: p = 0.98472, q = 1.06211], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41206],\n",
      "          Effect: [ate-q], [train: 0.07155], [test: 0.07213]\n",
      "********************************************************************************\n",
      "epoch: 739 / 800, time cost: 38.07 sec, \n",
      "          Loss: [Train: p = 0.98479, q = 1.06231], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41869],\n",
      "          Effect: [ate-q], [train: 0.03885], [test: 0.03960]\n",
      "********************************************************************************\n",
      "epoch: 740 / 800, time cost: 40.02 sec, \n",
      "          Loss: [Train: p = 0.98464, q = 1.06233], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41333],\n",
      "          Effect: [ate-q], [train: 0.06568], [test: 0.06623]\n",
      "********************************************************************************\n",
      "epoch: 741 / 800, time cost: 37.84 sec, \n",
      "          Loss: [Train: p = 0.98470, q = 1.06224], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41780],\n",
      "          Effect: [ate-q], [train: 0.04309], [test: 0.04380]\n",
      "********************************************************************************\n",
      "epoch: 742 / 800, time cost: 38.38 sec, \n",
      "          Loss: [Train: p = 0.98466, q = 1.06154], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41510],\n",
      "          Effect: [ate-q], [train: 0.05290], [test: 0.05352]\n",
      "********************************************************************************\n",
      "epoch: 743 / 800, time cost: 37.76 sec, \n",
      "          Loss: [Train: p = 0.98460, q = 1.06178], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41230],\n",
      "          Effect: [ate-q], [train: 0.07398], [test: 0.07448]\n",
      "********************************************************************************\n",
      "epoch: 744 / 800, time cost: 36.74 sec, \n",
      "          Loss: [Train: p = 0.98464, q = 1.06175], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41621],\n",
      "          Effect: [ate-q], [train: 0.05113], [test: 0.05185]\n",
      "********************************************************************************\n",
      "epoch: 745 / 800, time cost: 40.60 sec, \n",
      "          Loss: [Train: p = 0.98458, q = 1.06183], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41263],\n",
      "          Effect: [ate-q], [train: 0.07561], [test: 0.07610]\n",
      "********************************************************************************\n",
      "epoch: 746 / 800, time cost: 38.13 sec, \n",
      "          Loss: [Train: p = 0.98460, q = 1.06180], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41442],\n",
      "          Effect: [ate-q], [train: 0.06966], [test: 0.07023]\n",
      "********************************************************************************\n",
      "epoch: 747 / 800, time cost: 37.08 sec, \n",
      "          Loss: [Train: p = 0.98460, q = 1.06225], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41305],\n",
      "          Effect: [ate-q], [train: 0.06235], [test: 0.06295]\n",
      "********************************************************************************\n",
      "epoch: 748 / 800, time cost: 37.31 sec, \n",
      "          Loss: [Train: p = 0.98460, q = 1.06202], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41206],\n",
      "          Effect: [ate-q], [train: 0.08164], [test: 0.08213]\n",
      "********************************************************************************\n",
      "epoch: 749 / 800, time cost: 37.77 sec, \n",
      "          Loss: [Train: p = 0.98452, q = 1.06205], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41251],\n",
      "          Effect: [ate-q], [train: 0.06760], [test: 0.06817]\n",
      "********************************************************************************\n",
      "epoch: 750 / 800, time cost: 40.15 sec, \n",
      "          Loss: [Train: p = 0.98452, q = 1.06140], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41607],\n",
      "          Effect: [ate-q], [train: 0.05528], [test: 0.05597]\n",
      "********************************************************************************\n",
      "epoch: 751 / 800, time cost: 37.32 sec, \n",
      "          Loss: [Train: p = 0.98439, q = 1.06140], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41285],\n",
      "          Effect: [ate-q], [train: 0.08262], [test: 0.08309]\n",
      "********************************************************************************\n",
      "epoch: 752 / 800, time cost: 37.36 sec, \n",
      "          Loss: [Train: p = 0.98442, q = 1.06207], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41445],\n",
      "          Effect: [ate-q], [train: 0.06184], [test: 0.06236]\n",
      "********************************************************************************\n",
      "epoch: 753 / 800, time cost: 37.70 sec, \n",
      "          Loss: [Train: p = 0.98447, q = 1.06161], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41365],\n",
      "          Effect: [ate-q], [train: 0.06894], [test: 0.06946]\n",
      "********************************************************************************\n",
      "epoch: 754 / 800, time cost: 37.45 sec, \n",
      "          Loss: [Train: p = 0.98441, q = 1.06110], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41310],\n",
      "          Effect: [ate-q], [train: 0.07288], [test: 0.07341]\n",
      "********************************************************************************\n",
      "epoch: 755 / 800, time cost: 39.49 sec, \n",
      "          Loss: [Train: p = 0.98446, q = 1.06106], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41185],\n",
      "          Effect: [ate-q], [train: 0.08184], [test: 0.08226]\n",
      "********************************************************************************\n",
      "epoch: 756 / 800, time cost: 37.54 sec, \n",
      "          Loss: [Train: p = 0.98436, q = 1.06093], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41255],\n",
      "          Effect: [ate-q], [train: 0.07996], [test: 0.08038]\n",
      "********************************************************************************\n",
      "epoch: 757 / 800, time cost: 38.26 sec, \n",
      "          Loss: [Train: p = 0.98440, q = 1.06144], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41392],\n",
      "          Effect: [ate-q], [train: 0.06488], [test: 0.06541]\n",
      "********************************************************************************\n",
      "epoch: 758 / 800, time cost: 37.25 sec, \n",
      "          Loss: [Train: p = 0.98438, q = 1.06141], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41491],\n",
      "          Effect: [ate-q], [train: 0.06486], [test: 0.06542]\n",
      "********************************************************************************\n",
      "epoch: 759 / 800, time cost: 40.50 sec, \n",
      "          Loss: [Train: p = 0.98436, q = 1.06111], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41520],\n",
      "          Effect: [ate-q], [train: 0.06131], [test: 0.06184]\n",
      "********************************************************************************\n",
      "epoch: 760 / 800, time cost: 36.63 sec, \n",
      "          Loss: [Train: p = 0.98430, q = 1.06104], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41535],\n",
      "          Effect: [ate-q], [train: 0.06052], [test: 0.06103]\n",
      "********************************************************************************\n",
      "epoch: 761 / 800, time cost: 37.92 sec, \n",
      "          Loss: [Train: p = 0.98424, q = 1.06072], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41319],\n",
      "          Effect: [ate-q], [train: 0.07065], [test: 0.07115]\n",
      "********************************************************************************\n",
      "epoch: 762 / 800, time cost: 37.15 sec, \n",
      "          Loss: [Train: p = 0.98425, q = 1.06137], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41722],\n",
      "          Effect: [ate-q], [train: 0.05243], [test: 0.05309]\n",
      "********************************************************************************\n",
      "epoch: 763 / 800, time cost: 38.58 sec, \n",
      "          Loss: [Train: p = 0.98422, q = 1.06098], \n",
      "          Loss: [Test: p = 1.01897, q = 1.41839],\n",
      "          Effect: [ate-q], [train: 0.04588], [test: 0.04654]\n",
      "********************************************************************************\n",
      "epoch: 764 / 800, time cost: 39.83 sec, \n",
      "          Loss: [Train: p = 0.98423, q = 1.06087], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41458],\n",
      "          Effect: [ate-q], [train: 0.06964], [test: 0.07013]\n",
      "********************************************************************************\n",
      "epoch: 765 / 800, time cost: 38.07 sec, \n",
      "          Loss: [Train: p = 0.98415, q = 1.06049], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41375],\n",
      "          Effect: [ate-q], [train: 0.07118], [test: 0.07171]\n",
      "********************************************************************************\n",
      "epoch: 766 / 800, time cost: 39.09 sec, \n",
      "          Loss: [Train: p = 0.98415, q = 1.06074], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41400],\n",
      "          Effect: [ate-q], [train: 0.07004], [test: 0.07054]\n",
      "********************************************************************************\n",
      "epoch: 767 / 800, time cost: 37.70 sec, \n",
      "          Loss: [Train: p = 0.98419, q = 1.06038], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41470],\n",
      "          Effect: [ate-q], [train: 0.07486], [test: 0.07540]\n",
      "********************************************************************************\n",
      "epoch: 768 / 800, time cost: 37.39 sec, \n",
      "          Loss: [Train: p = 0.98413, q = 1.06102], \n",
      "          Loss: [Test: p = 1.01892, q = 1.41387],\n",
      "          Effect: [ate-q], [train: 0.07679], [test: 0.07725]\n",
      "********************************************************************************\n",
      "epoch: 769 / 800, time cost: 40.69 sec, \n",
      "          Loss: [Train: p = 0.98403, q = 1.06021], \n",
      "          Loss: [Test: p = 1.01890, q = 1.41592],\n",
      "          Effect: [ate-q], [train: 0.06148], [test: 0.06204]\n",
      "********************************************************************************\n",
      "epoch: 770 / 800, time cost: 38.18 sec, \n",
      "          Loss: [Train: p = 0.98404, q = 1.06023], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41563],\n",
      "          Effect: [ate-q], [train: 0.06281], [test: 0.06333]\n",
      "********************************************************************************\n",
      "epoch: 771 / 800, time cost: 36.60 sec, \n",
      "          Loss: [Train: p = 0.98405, q = 1.06046], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41619],\n",
      "          Effect: [ate-q], [train: 0.06229], [test: 0.06286]\n",
      "********************************************************************************\n",
      "epoch: 772 / 800, time cost: 36.91 sec, \n",
      "          Loss: [Train: p = 0.98407, q = 1.06023], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41715],\n",
      "          Effect: [ate-q], [train: 0.05338], [test: 0.05392]\n",
      "********************************************************************************\n",
      "epoch: 773 / 800, time cost: 37.28 sec, \n",
      "          Loss: [Train: p = 0.98397, q = 1.06055], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41534],\n",
      "          Effect: [ate-q], [train: 0.06626], [test: 0.06678]\n",
      "********************************************************************************\n",
      "epoch: 774 / 800, time cost: 40.14 sec, \n",
      "          Loss: [Train: p = 0.98382, q = 1.06049], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41663],\n",
      "          Effect: [ate-q], [train: 0.05705], [test: 0.05771]\n",
      "********************************************************************************\n",
      "epoch: 775 / 800, time cost: 37.11 sec, \n",
      "          Loss: [Train: p = 0.98403, q = 1.06052], \n",
      "          Loss: [Test: p = 1.01889, q = 1.41777],\n",
      "          Effect: [ate-q], [train: 0.05281], [test: 0.05344]\n",
      "********************************************************************************\n",
      "epoch: 776 / 800, time cost: 37.22 sec, \n",
      "          Loss: [Train: p = 0.98397, q = 1.05992], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41913],\n",
      "          Effect: [ate-q], [train: 0.05130], [test: 0.05194]\n",
      "********************************************************************************\n",
      "epoch: 777 / 800, time cost: 38.28 sec, \n",
      "          Loss: [Train: p = 0.98393, q = 1.06056], \n",
      "          Loss: [Test: p = 1.01897, q = 1.41885],\n",
      "          Effect: [ate-q], [train: 0.04872], [test: 0.04931]\n",
      "********************************************************************************\n",
      "epoch: 778 / 800, time cost: 37.55 sec, \n",
      "          Loss: [Train: p = 0.98395, q = 1.06033], \n",
      "          Loss: [Test: p = 1.01888, q = 1.42108],\n",
      "          Effect: [ate-q], [train: 0.03891], [test: 0.03964]\n",
      "********************************************************************************\n",
      "epoch: 779 / 800, time cost: 40.52 sec, \n",
      "          Loss: [Train: p = 0.98383, q = 1.05994], \n",
      "          Loss: [Test: p = 1.01897, q = 1.41499],\n",
      "          Effect: [ate-q], [train: 0.07090], [test: 0.07139]\n",
      "********************************************************************************\n",
      "epoch: 780 / 800, time cost: 37.17 sec, \n",
      "          Loss: [Train: p = 0.98383, q = 1.05977], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41986],\n",
      "          Effect: [ate-q], [train: 0.04443], [test: 0.04499]\n",
      "********************************************************************************\n",
      "epoch: 781 / 800, time cost: 37.59 sec, \n",
      "          Loss: [Train: p = 0.98381, q = 1.06039], \n",
      "          Loss: [Test: p = 1.01890, q = 1.41628],\n",
      "          Effect: [ate-q], [train: 0.06337], [test: 0.06386]\n",
      "********************************************************************************\n",
      "epoch: 782 / 800, time cost: 37.30 sec, \n",
      "          Loss: [Train: p = 0.98377, q = 1.06001], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41610],\n",
      "          Effect: [ate-q], [train: 0.05939], [test: 0.05996]\n",
      "********************************************************************************\n",
      "epoch: 783 / 800, time cost: 37.41 sec, \n",
      "          Loss: [Train: p = 0.98370, q = 1.05988], \n",
      "          Loss: [Test: p = 1.01893, q = 1.41641],\n",
      "          Effect: [ate-q], [train: 0.06292], [test: 0.06336]\n",
      "********************************************************************************\n",
      "epoch: 784 / 800, time cost: 39.60 sec, \n",
      "          Loss: [Train: p = 0.98377, q = 1.05976], \n",
      "          Loss: [Test: p = 1.01893, q = 1.41580],\n",
      "          Effect: [ate-q], [train: 0.06881], [test: 0.06929]\n",
      "********************************************************************************\n",
      "epoch: 785 / 800, time cost: 37.51 sec, \n",
      "          Loss: [Train: p = 0.98385, q = 1.05997], \n",
      "          Loss: [Test: p = 1.01899, q = 1.41746],\n",
      "          Effect: [ate-q], [train: 0.05820], [test: 0.05876]\n",
      "********************************************************************************\n",
      "epoch: 786 / 800, time cost: 37.51 sec, \n",
      "          Loss: [Train: p = 0.98362, q = 1.05985], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41726],\n",
      "          Effect: [ate-q], [train: 0.06124], [test: 0.06175]\n",
      "********************************************************************************\n",
      "epoch: 787 / 800, time cost: 37.41 sec, \n",
      "          Loss: [Train: p = 0.98370, q = 1.05955], \n",
      "          Loss: [Test: p = 1.01890, q = 1.41505],\n",
      "          Effect: [ate-q], [train: 0.07498], [test: 0.07539]\n",
      "********************************************************************************\n",
      "epoch: 788 / 800, time cost: 37.38 sec, \n",
      "          Loss: [Train: p = 0.98374, q = 1.05971], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41635],\n",
      "          Effect: [ate-q], [train: 0.06424], [test: 0.06474]\n",
      "********************************************************************************\n",
      "epoch: 789 / 800, time cost: 40.08 sec, \n",
      "          Loss: [Train: p = 0.98373, q = 1.05964], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41981],\n",
      "          Effect: [ate-q], [train: 0.05074], [test: 0.05139]\n",
      "********************************************************************************\n",
      "epoch: 790 / 800, time cost: 38.08 sec, \n",
      "          Loss: [Train: p = 0.98353, q = 1.05921], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41931],\n",
      "          Effect: [ate-q], [train: 0.04826], [test: 0.04885]\n",
      "********************************************************************************\n",
      "epoch: 791 / 800, time cost: 36.81 sec, \n",
      "          Loss: [Train: p = 0.98360, q = 1.05906], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41853],\n",
      "          Effect: [ate-q], [train: 0.05652], [test: 0.05704]\n",
      "********************************************************************************\n",
      "epoch: 792 / 800, time cost: 37.09 sec, \n",
      "          Loss: [Train: p = 0.98360, q = 1.05928], \n",
      "          Loss: [Test: p = 1.01895, q = 1.42068],\n",
      "          Effect: [ate-q], [train: 0.04640], [test: 0.04708]\n",
      "********************************************************************************\n",
      "epoch: 793 / 800, time cost: 41.04 sec, \n",
      "          Loss: [Train: p = 0.98350, q = 1.05928], \n",
      "          Loss: [Test: p = 1.01891, q = 1.41528],\n",
      "          Effect: [ate-q], [train: 0.06996], [test: 0.07047]\n",
      "********************************************************************************\n",
      "epoch: 794 / 800, time cost: 38.33 sec, \n",
      "          Loss: [Train: p = 0.98358, q = 1.05901], \n",
      "          Loss: [Test: p = 1.01898, q = 1.41831],\n",
      "          Effect: [ate-q], [train: 0.06069], [test: 0.06122]\n",
      "********************************************************************************\n",
      "epoch: 795 / 800, time cost: 37.04 sec, \n",
      "          Loss: [Train: p = 0.98346, q = 1.05973], \n",
      "          Loss: [Test: p = 1.01896, q = 1.41770],\n",
      "          Effect: [ate-q], [train: 0.06283], [test: 0.06326]\n",
      "********************************************************************************\n",
      "epoch: 796 / 800, time cost: 37.80 sec, \n",
      "          Loss: [Train: p = 0.98340, q = 1.05911], \n",
      "          Loss: [Test: p = 1.01896, q = 1.42371],\n",
      "          Effect: [ate-q], [train: 0.03762], [test: 0.03824]\n",
      "********************************************************************************\n",
      "epoch: 797 / 800, time cost: 38.30 sec, \n",
      "          Loss: [Train: p = 0.98352, q = 1.05924], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41670],\n",
      "          Effect: [ate-q], [train: 0.07390], [test: 0.07443]\n",
      "********************************************************************************\n",
      "epoch: 798 / 800, time cost: 40.64 sec, \n",
      "          Loss: [Train: p = 0.98334, q = 1.05877], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41997],\n",
      "          Effect: [ate-q], [train: 0.05437], [test: 0.05487]\n",
      "********************************************************************************\n",
      "epoch: 799 / 800, time cost: 37.92 sec, \n",
      "          Loss: [Train: p = 0.98337, q = 1.05967], \n",
      "          Loss: [Test: p = 1.01894, q = 1.41532],\n",
      "          Effect: [ate-q], [train: 0.08303], [test: 0.08344]\n",
      "********************************************************************************\n",
      "epoch: 800 / 800, time cost: 38.11 sec, \n",
      "          Loss: [Train: p = 0.98338, q = 1.05880], \n",
      "          Loss: [Test: p = 1.01895, q = 1.41899],\n",
      "          Effect: [ate-q], [train: 0.05522], [test: 0.05580]\n",
      "********************************************************************************\n",
      "Finish training...\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist_p, train_loss_hist_q1, train_loss_hist_q0 = [], [], []\n",
    "test_loss_hist_p, test_loss_hist_q1, test_loss_hist_q0 = [], [], []\n",
    "est_effect, prop_score_hist = [], []\n",
    "\n",
    "for e in range(1, epoch + 1):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "        \n",
    "    p_loss_train, q1_loss_train, q0_loss_train  = [], [], []\n",
    "    for idx, (tokens, treatment, response, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        prop_score, q1, q0 = model(tokens)\n",
    "        \n",
    "        loss_p = prop_score_loss(prop_score, treatment)\n",
    "        loss = loss_p\n",
    "        \n",
    "        p_loss_train.append(loss_p.item())\n",
    "        if len(response[treatment == 1]) > 0:\n",
    "            loss_q1 = q_loss(q1[treatment==1], response[treatment==1])\n",
    "            loss += loss_q1\n",
    "            q1_loss_train.append(loss_q1.item())\n",
    "            \n",
    "        if len(response[treatment == 0]) > 0:\n",
    "            loss_q0 = q_loss(q1[treatment==0], response[treatment==0])\n",
    "            loss += loss_q0\n",
    "            q0_loss_train.append(loss_q0.item())\n",
    "                        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    run_idx = idx\n",
    "\n",
    "    # Evaluation.\n",
    "    p_loss_train = np.array(p_loss_train).mean()\n",
    "    q1_loss_train = np.array(q1_loss_train).mean()\n",
    "    q0_loss_train = np.array(q0_loss_train).mean()\n",
    "    \n",
    "    train_effect, _, _, _, _, _, _ = est_casual_effect(train_loader, model, effect, estimation, evaluate=False)\n",
    "    test_effect, p_loss_test, q1_loss_test, q0_loss_test, prop_accu_test, q1_accu_test, q0_accu_test = est_casual_effect(test_loader, model, effect, estimation, evaluate=True, p_loss=prop_score_loss, q_loss=q_loss)\n",
    "    \n",
    "    train_loss_hist_p.append(p_loss_train)\n",
    "    train_loss_hist_q1.append(q1_loss_train)\n",
    "    train_loss_hist_q0.append(q0_loss_train)\n",
    "    \n",
    "    test_loss_hist_p.append(p_loss_test)\n",
    "    test_loss_hist_q1.append(q1_loss_test)\n",
    "    test_loss_hist_q0.append(q0_loss_test)\n",
    "\n",
    "    est_effect.append(test_effect)\n",
    "    \n",
    "    \n",
    "    print(f'''epoch: {e} / {epoch}, time cost: {(time.time() - start):.2f} sec, \n",
    "          Loss: [Train: p = {p_loss_train:.5f}, q = {(q1_loss_train + q0_loss_train):.5f}], \n",
    "          Loss: [Test: p = {p_loss_test:.5f}, q = {(q1_loss_test + q0_loss_test):.5f}],\n",
    "          Effect: [{effect}-{estimation}], [train: {train_effect:.5f}], [test: {test_effect:.5f}]''')\n",
    "    print('*'* 80)\n",
    "    start = time.time()\n",
    "\n",
    "train_loss_hist = dict(p=train_loss_hist_p, q1=train_loss_hist_q1, q0=train_loss_hist_q1)\n",
    "test_loss_hist = dict(p=test_loss_hist_p, q1=test_loss_hist_q1, q0=test_loss_hist_q0)\n",
    "\n",
    "print('Finish training...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "real = true_casual_effect(test_loader)\n",
    "unadjust = (test_loader.dataset.response[test_loader.dataset.treatment == 1].mean() - test_loader.dataset.response[test_loader.dataset.treatment == 0].mean()).item()\n",
    "show_result(train_loss_hist, test_loss_hist, est_effect, real, unadjust, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second 800 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAD4CAYAAABmBQicAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3hUVdrAfyeN3ptIERALEEjoFsRBiihtWVTAig37qvvZcHcBRXZRcV1REUUxKhqaAgIKCAioiFIMXaSFLp1AejvfH++9M3cmM5NJSCCB83ueeWZuO/fMnTv3Pe973qK01hgMBoPBUJoJO9cdMBgMBoPhTDHCzGAwGAylHiPMDAaDwVDqMcLMYDAYDKUeI8wMBoPBUOqJONcdKErCwsJ0uXLlznU3DAaDodSQmpqqtdalXrE5r4RZuXLlSElJOdfdMBgMhlKDUirtXPehKCj10thgMBgMBiPMDAaDwVDqMcLMYDAYDKUeI8wMBoPBUOoxwsxgMBgMpR4jzAwGg8FQ6jHCzGAwGAxBUUr1VEptVUptV0q94Gd7Z6XUWqVUtlLqFj/bKyul9iml3imuPhphZuGKcxGXEAdAVk4WrjgXk9dPBiA1KxVXnIupG6cCkJSehCvOxVdbvgLgaOpRXHEu5mydA8CfyX/iinMxf/t8APYm7cUV52LRzkUA7DyxE1eci2WJywDYenQrrjgXK/auAGDj4Y244lys2r8KgIQ/E3DFuUj4MwGAVftX4YpzsfHwRgBW7F2BK87F1qNbAViWuAxXnIudJ3YCsGjnIlxxLvYm7QVg/vb5uOJc/Jn8JwBzts7BFefiaOpRAL7a8hWuOBdJ6UkATN04FVeci9SsVAAmr5+MK85FVk4WAHEJcbjiXO5rOXHNRLp92s29PH7VeG76/Cb38lsr36JvfF/38tgVYxkwbYB7ecyPYxg0Y5B7edSyUdz51Z3u5eHfD+fe2fe6l4ctGsbQOUPdy88sfIbH5j3mXn5q/lM8Nf8p9/Jj8x7jmYXPuJeHzhnKsEXD3Mv3zr6X4d8Pdy/f+dWdjFo2yr08aMYgxvw4xr08YNoAxq4Y617uG9+Xt1a+5V6+6fObGL9qvHu526fdmLhmonvZ3Hvm3rMpyL2nNbR/fQCvLPHce8WBUioceBe4CWgODFZKNffZbQ8wBPgiQDOjgOXF1UcwwsxgMBhKNKeTISMj7/o1a2D1apg1q9i70AHYrrXeqbXOBKYA/Zw7aK0TtdbrgVzfg5VSbYE6wMLi7KQ6n4pzVqhQQZsMIAaD4Xxhxw5o2lQ+nzwJVarA3LkweDAkJ3v227ABWrQApQp+DqVUJrDBseoDrfUHju23AD211g9Yy3cBHbXWj/tpKw6Yq7WeYS2HAUuAO4FuQDt/xxUF51U6K4PBYCiJNGkCu3bJq1Ej//s895wIqPHjITcXfvsNbrzRs33YMGjTBh58MO+xLVvKMYUkW2vdrtBHB+dR4But9T5VGElbAIwwMxgMhiAcPQq9e0N8PDRu7L1Na4/2lJMjyxGOp+oXX8i6XbtkuXFjmDpV1v3+O4wYAWlp8NFH8Prrss8DD8Cdd8KWLd7neu+94P0sRlmxH2jgWK5vrQuFq4HrlFKPAhWBKKVUstY6jxPJmWKEmcFgMPjhX/8SjWfDBvjlFxgzBt5/X4RWWBhkZ4u29MYbsG4dPP00LFkic1i//QbjxsGJE3nbHTjQ83nnTjh0CBYs8Kxr29bz+Z57YNs2WLECOnaUfgDMmAG33AITJ4qm9uyzxXMNLFYBlymlGiNCbBBweygHaq3vsD8rpYYgZsYiF2Rg5swMBkMpZ948iImB+vULdty+fVCpEgwaJAJmyBDIyhLNKjfXW8MCuPde+Mc/PHNYYWEe01758pCaWvjvYLd1ww3w008iIB9+WLSttDQ4fRouugjS02Xu7KKLIDMToqLkOKUKr5kppVK11hXy2edm4H9AODBJaz1aKfUysFpr/bVSqj0wE6gGpAN/aq1b+LQxhGKcMzPCzGAwlFpyckToXHwxfPklXH01/N//wX33ydxU+fKefdevh1tvFdNfdDSULevdVvPmsHkzVKwIVauKsCtKtm6FSZNk/iwhAfr1E00rNRX+/W8RWhWCipTiIRRhVhowwsxgMJRY0tLEe++WW0TzWLFChNHgwfDtt3D8eOC5pGuugS5dYPFieP556N/fs23AABF+Z8pjj8Grr4pwSk6GmjVFY2rfXvp74oRofydPQp06Z36+4sAIsxKIEWYGQ+khLU00pdGjRVsZPx7uuku0rIMHRRB88AG89RZ88w3cdJOYBKdOLd5+lS8v5r6hQ2Vu6tNPZX2PHtK/yEgRoocOiQNHMTvpFTvnizArVgcQpdQkoDdwWGsdHWS/9sDPwCBHfMI9wD+tXV7RWn9SnH01GAxnl19+kfmuo0eha1cxtR0/LsJi9GjvfW++GVatEmeMULnvPvEiTEz0eBP+/LNocuvXi/DcsgWeekrW1a8vHoZ33eUxT/buLfvZc1aGkkuxamZKqc5AMvBpIGFmpUr5Dpk0nKS1nqGUqg6sBtoBGlgDtNVa+/EN8mA0M4OheNFanBDWroVrr/Wsz8qC/fu9Y6gOHhSNa8YMuOwy0bKeew7i4uD772G+ZNxyazahPoouvxz++EM+33efzEN16waLFsGbb0K5crI+MtJzzI8/ShaNrl0L+83PX84XzazYzYxKqUZIRHggYfYUkAW0t/aboZQaDLi01g9Z+7wPLNVaxwc7lxFmBkPByM2FjRvh2DGoVg1iY723p6fLPuXLewRYerps27tX5qNmzfKkVBo4UNq55BJxW/fFdnUPhUcfFdfzrCyZi4qJkfmnDz+EMmXEUUNr6Ue5ciIgb7219Jv9zjbnizA7p3FmSql6QH+gCyLMbOoBex3L+6x1/toYCgwFiIqKKp6OGgyljIwMiYl6+GFx37Y5dgw6dxaBcPXVYtr7178828eMERf1JUvEBDfKynEbEyOxVE4aNCAPweazatcWjapBAxGII0fKvNnEiRIoHBsr2txdd8Hhw1C9uvSvUiVxXfeHUtCwoXy+7bb8rorhfOZcB03/D3hea51b2FQnVg6xD0A0syLsm8FQati+HS69VMxpixaJdvT00zLX88QTULmyBPJu3Sru59dcI8Ll8GHvdl54QV6++Aoym0sugd27PcuPPipzTBdd5HFz//13MTdWqCCefpGR3trT//1f3nZr15b3KlUKdh0MFy7n1MyolNoF2Ld1TSAV0bLKYcyMBgMAR45I3NOWLWKmswXBtddChw5wxx3iCj52LDxjVRfxNeeVKydaUH5ccYUIPCetW4tgfP550fKuvx5mzhRBs3q1OG3s2SOZK2rWlLgppeSchpLP+WJmPOdzZo794vDMmVVHnD7aWJvXIg4gx4O1YYSZoSTyww/iufeMp4wVR4+KgDp2zKOFZGRIIG9ysgQC79sH06fDiy96jnvlFbjuOvjvf2H27ML1p0oVSEryXnfNNTBnjpj2du6UV/fusHSpCC/D+cv5IszQWhfbC4gHDiIOHvuA+4GHgYf97BsH3OJYvg/Ybr3uDeV85cuX1wbDuWT9eq2PHPEs//OfWoubgtZ798q6efNkuV8/ef/rX7WOjpbPb72ldZUqnmMK8rr8cq07d9Z60SKtf/5Z69xcrV95RbaNH691Zqas01rrY8e0njhR602bPOt8OXmyeK+VoWQApOhilANn62WCpg2GIGgtJrM//pDg2VGj/HvLaS3BvU8/DfXqwcqV4siwdKlnn0aNJOapoLzwAvTsKef4+99l7is2Fvr0kf507SpOHP40qJwcMQV27Fjw8xouDM4XzcwIM4MhAEePQq1aYtL7+99l3auvSiaKDRtkrmrUKCnrsXGjeALaNGuWt4RHKNxyi8RRjRgh55g7F4YPD+xubiebNRgKixFmJRAjzAwFYccO8ayrVw/Cwz3rP/pI1tepIxpRUXHllTIHtnIl1KgBp05JZooRI+ScDRtKyiSD4WxihFkJxAizC5ulSyWx7MaNIji++koyoV95pQirTz+Fl16Cd9+VuKb9VnnBSy+F116TulEXXwx3313wc48fL4HFQ4aIOTE6WgThhAli/nvgAWjVKnC8lMFwrjDCrARihNmFzaOPSo69sWPFW88O+A0Pl8wUU6fKHFIodOkiGSVsmjQRDz8QN/hGjcSNvWtXcLk8+x09Ku7pBkNpwQizEogRZucX8fEiNK6+2v/27GzRiCIixCli9WopxREeHrrQclKjhrjK33+/ZMg4ckTavP56T+LZlJRzU3PKYCgujDArgRhhVjrJzBSh1KwZ3HijrEtN9QiNjh3l8z33wPLlkt1i2jSZ01q1KnjbDRtKQC9IBvSBA0WDmzNHUiqVKSPnrVnT42RhTIGGCwkjzEogRpiVDFavlqwRaWmSTeLiiyUw2Hay+OMPyaKulAQGjxolGdXB4wXYpo0ktg2V116T4OQ77hAvwC+/lEzq48ZJIlo7fx943O0NBoMRZiUSI8yKnyNHJA9gINPfihWSZumJJ2DyZCmwCOLiXr++ZJhYvFiE2zXXeLKtB+LGG2HBAvncvLnMT02fLtrZ/PkiIBculJIfRqMyGAqOEWYlECPMipYjR+D11yXL+e7dEkdlu5TPnCnVeB96SNItnTol6ZmigyYtC0x0tHghgmhYw4aJoFq6VMyEtWqZXH8GQ3FghFkJxAiz0Dh0SMpu9OolAbqffQaPPALffgs//STCacUKMdM5sT0CC8LNN0vS24suEo2uYUN5nzhR5qu2b5dijU8+KUKrRQvPsbm5RtsyGIobI8xKIEaY5SUnR0rEt24ty5mZIkSKi3LlxCPw9tvhscfyCkQbrUVYOYOVDQbD2ccIsxLIhSDM0tLEJT0sLK+LeG6uZJdISRFXcns+auxY0YzKlZOME6HyxBPw9tue5datJeB4504xN3bpIubHMmWk3ePHxXGjUaMz/poGg+EsYYRZCeR8EWZai+nP5ZJ5qMmTYehQcXTo1cuz3xdfSHDwiy/Cc8/5L1PvjyuvhE6dJJbKxq5/9d//SkqliAgJCj59WkqTVKkiWpQx+xkM5xdGmJVASpMwW7VKCivGxUn8FIh5bsYMcYR45x0RKmvXSlaJwtCrl8RlNWrkKdQ4bJgUWaxcWebOfvlF6lZFREhG98svL4IvZzAYSg1GmJVAzqYwsy9baqqY9ypV8mzbulXiqJKTJSNF586wbJnk6XvoITHLjRsHU6bI/k89JbFVtgt6KLRrJ/Fc5cpJ3r+dOyXwuG5d8UKcNElKh4AIql9/lUrAZo7KYDA4McIsv4aVmgT0Bg5rP1WmlVL9gFFALpANPKW1/tHalgPYRd/3aK37hnLOohBmu3eLtpKaKhqTUmKO+/NPcaTYtUu0qjvvhG++kXinnTvFSy8jQ7JVfP21tFW3Lhw8WLh+vPeetPPtt/Dss+JteOyYuK27XBATI+e/6SYjoAwGQ+Exwiy/hpXqDCQDnwYQZhWRCqdaKdUKmKa1vtLalqy1rljQcxZWmH3zjbiKHzggGoxNmTLwn/94alnZfPwx3Htv/u1efLG0GYi+fUWrmjBB+jB5stSzKk5vQ4PBYHBihFkojSvVCJjrT5j57Hc1MElr3cxaPmvC7ORJ0a78UbmyBAOHgssFa9ZIVou//100tSuvlPx/CxdKdvVvvhET4KBB4khRtaocm5srr4iIAnXdYDAYzhgjzEJpPB9hppTqD/wHqA300lr/bK3PBhIQ8+MYrXXApEdKqaHAUICoqKi2GRkZBe7nu+/Cd9+JwNm6VeawmjaVGK1rrhFtrVw5KaB4+rS4uvfrJybFiAj5bHL9GQyG0kgowkwp1RN4CwgHPtRaj/HZ3hn4H9AKGKS1nmGtjwXeAyoDOcBorXUBUy+ERknRzDoDw7XW3azlelrr/UqpJsASoKvWekd+5ysOB5DsbJmrqlOnSJs1GAyGEkF+wkwpFQ78AXQH9gGrgMFa682OfRohAusZ4GuHMLsc0FrrbUqpi4E1QDOt9cmi/h4lImpIa70caKKUqmkt77fedwJLgdbnqm8REUaQGQyGC5oOwHat9U6tdSYwBejn3EFrnai1Xo849DnX/6G13mZ9PgAcBmoVRyfPmTBTSjVVSoxzSqk2QBngmFKqmlKqjLW+JnAtsDlwSwaDwWAoRuoBex3L+6x1BUIp1QGIAvK1shWGYnM5UErFAy6gplJqHzACiATQWk8ABgB3K6WygDRgoOXZ2Ax4XymViwjbMU511mAwGAxFSoRSarVj+QOt9QdFeQKlVF3gM+AerXVufvsXhmITZlrrwflsfxV41c/6FUDL4uqXwWAwGLzI1lq3C7J9P9DAsVzfWhcSSqnKwDzgH1rrlYXrYv6UiDkzg8FgMJRYVgGXKaUaK6WigEHA16EcaO0/E4k3nlGMfTTCzGAwGAyB0VpnA48DC4AtSIKLTUqpl5VSfQGUUu2t6aRbkWmiTdbhtwGdgSFKqQTrFVsc/TS5GQ0Gg+EC5nwJmjaamcFgMBhKPUaYGQwGg6HUY4SZwWAwGEo9RpgZDAaDodRjhJnBYDAYSj1GmBkMBoOh1GOEmcFgMBhKPUaYGQwGg6HUY4SZwWAwGEo9RpgZDAaDodRjhJnBYDAYSj1GmBkMBoOh1FOswkwpNUkpdVgptTHA9n5KqfVWJuXVSqlOjm33KKW2Wa97irOfBoPBYCjdFGvWfKVUZyAZqWUT7Wd7RSDFqjDdCiktcKVSqjqwGmgHaGAN0FZrfSLY+UzWfIPBYCgYJmt+CGitlwPHg2xP1h5pWgERXAA3At9prY9bAuw7oGdx9tVgMBgMpZeIc90BpVR/4D9AbaCXtboesNex2z5rXYHJyspi3759pKenn1E/Dec/ZcuWpX79+kRGRp7rrhgMhgJyzoWZ1nomMNMySY4CuhXkeKXUUGAoQFRUVJ7t+/bto1KlSjRq1AilVBH02HA+orXm2LFj7Nu3j8aNG5/r7hgMhgJSYrwZLZNkE6VUTWA/0MCxub61zt9xH2it22mt20VE5JXN6enp1KhRwwgyQ1CUUtSoUcNo8AZDKeWcCjOlVFNlSRmlVBugDHAMWAD0UEpVU0pVA3pY6wp7nqLoruE8x9wnBkPppVjNjEqpeMAF1FRK7QNGAJEAWusJwADgbqVUFpAGDLQcQo4rpUYBq6ymXtZaB3QkMRgMBsOFTXF7Mw7WWtfVWkdqretrrT/SWk+wBBla61e11i201rFa66u11j86jp2ktW5qvT4uzn4WN+Hh4cTGxrpfY8aMKVQ7LpeL1atXh7zeYDAYLhTOuQPIhUC5cuVISEg41904K+Tk5BAeHn6uu5GHktovg8FQNFxQwuypKU+RsLdohUpsg1j+N+h/BT5u/vz5fPTRR0yfPh2ApUuXMnbsWObOncsjjzzCqlWrSEtL45ZbbuGll14Kud34+Hj+/e9/o7WmV69evPrqq+Tk5HD//fezevVqlFLcd999PP3004wbN44JEyYQERFB8+bNmTJlSsB2ExMT6dmzJ23btmXt2rW0aNGCTz/9lPLly9OoUSMGDhzId999x3PPPYfWOk8fACpWrMiDDz7IwoULueiii5gyZQq1atXyez5/fUtOTuaJJ55wf48RI0YwYMAAv9/ZPt9DDz3EokWLePfdd0lMTGTcuHFkZmbSsWNHxo8fbwScwXCeUGK8Gc9n0tLSvMyMU6dOpVu3bvzyyy/YGUumTp3KoEGDABg9ejSrV69m/fr1LFu2jPXr14d0ngMHDvD888+zZMkSEhISWLVqFbNmzSIhIYH9+/ezceNGNmzYwL333gvAmDFj+O2331i/fj0TJkwAYPXq1TzwwAN+29+6dSuPPvooW7ZsoXLlyowfP969rUaNGqxdu5bOnTv77QNASkoK7dq1Y9OmTVx//fVBhbS/vo0aNYoqVaqwYcMG1q9fzw033BDwO9vn69ixI+vWraNGjRpMnTqVn376iYSEBMLDw/n8889Duq4Gg6EUoLU+b17ly5fXvmzevDnPurNNhQoV/K5/8MEHdXx8vM7KytINGjTQp06d0lpr/d577+nWrVvrli1b6po1a+r4+HittdbXX3+9XrVqVZ527PWzZs3Sd911l3v9hx9+qJ9++ml9/Phx3aRJE/3444/rb7/9Vufk5Gittb7xxhv1gAED9GeffaZPnz4d9Dvs2rVLN2jQwL28ePFi3a9fP6211pdccolOTEzUWuuAfdBa67CwMJ2VlaW11nrHjh06JiYm4Pn89a1Nmzb6jz/+8Nov2PnCw8N1dna21lrrt99+W9etW1fHxMTomJgYffnll+sRI0bkOW9JuF8MhrMJklLwnD+/z/RlNLNzyKBBg5g2bRpLliyhXbt2VKpUiV27djF27FgWL17M+vXr6dWr1xnHPlWrVo1169bhcrmYMGGCW/OaN28ejz32GGvXrqV9+/ZkZ2cHbcfXdd25XKFCwVO7BXOFL2jf/FG2bFm3GVFrzT333ENCQgIJCQls3bqVkSNHFrhNg8FQMjHC7Bxy/fXXs3btWiZOnOg2MZ46dYoKFSpQpUoVDh06xLfffhtyex06dGDZsmUcPXqUnJwc4uPjuf766zl69Ci5ubkMGDCAV155hbVr15Kbm8vevXvp0qULr776KklJSSQnJwdtf8+ePfz8888AfPHFF3Tq1CnPPoH6AJCbm8uMGTOCHm/v569v3bt3591333Xvd+LEiaDnc9K1a1dmzJjB4cOHATh+/Di7d+8O4aoaDIbSgBFmZwHfObMXXngBEJf93r178+2339K7d28AYmJiaN26NVdeeSW333471157bcjnqVu3LmPGjKFLly7ExMTQtm1b+vXrx/79+3G5XMTGxnLnnXfyn//8h5ycHO68805atmxJ69at+dvf/kbVqlWDzpldccUVvPvuuzRr1owTJ07wyCOPhNwHEO3t119/JTo6miVLljB8+HC/5wnUt3/+85+cOHGC6OhoYmJi+P7774Oez0nz5s155ZVX6NGjB61ataJ79+4cPHgw5GtrMBhKNsVaAuZs468EzJYtW2jWrNk56tH5Q2JiIr1792bjRr+l6UKiYsWK+Wp/5xpzvxguNEwJGIPBYDAYSghGmBlColGjRmeklQF+tbLHHnvMywQbGxvLxx+X6oQvBsN5h1Kqp1Jqq1Jqu1LqBT/bOyul1iqlspVSt/hsu0cptc163VNcfbyggqYNJQ+nQ4fBYCh5KKXCgXeB7khtyVVKqa+11psdu+0BhgDP+BxbHcnJ2w4pvrzGOvZEUffTaGYGg8FgCEYHYLvWeqfWOhOYAnh5WWmtE7XW64Fcn2NvBL7TWh+3BNh3QM/i6KQRZgaDwXBhE6GUWu14DfXZXg/Y61jeZ60LhTM5tkAUyMyolAoDKmqtTxVHZwwGg8Fw1snWWrc71504U/LVzJRSXyilKiulKgAbgc1KqWeLv2vnD+d7CZjp06fTokULwsLCiqwfGRkZDBw4kKZNm9KxY0cSExOLpF2DwVBg9gMNHMv1rXXFfWyBCMXM2NzSxP4CfAs0Bu4qjs6cr9glYOyXHTR9vhAdHc1XX31F586dA+4zcuRI4uLiQm7zo48+olq1amzfvp2nn36a559/vgh6ajAYCsEq4DKlVGOlVBQwCPg6xGMXAD2UUtWUUtWAHta6IicUYRaplIpEhNnXWussxCslKEqpSUqpw0opv/7cSqk7lFLrlVIblFIrlFIxjm2J1voEpdR5WXVy/vz53Hrrre7lpUuXurOAPPLII7Rr144WLVowYsSIArUbHx9Py5YtiY6OdguAnJwchgwZQnR0NC1btuTNN98EpMxK8+bNadWqlTudVjBGjx7N5ZdfTqdOnRg8eDBjx44FoFmzZlxxxRUF6qfNxx9/zOWXX06HDh148MEHefzxxwGYPXs299wjXry33HILixcv5nwK8DcYSgta62zgcUQIbQGmaa03KaVeVkr1BVBKtVdK7QNuBd5XSm2yjj0OjEIE4irgZWtdkRPKnNn7QCKwDliulLoECGXOLA54B/g0wPZdwPVa6xNKqZuAD4COju1dtNZHQzhPyDz1FBR1jczYWPhfPuXM7HRWNsOGDWPAgAEMHTqUlJQUKlSokKcETPXq1cnJyaFr166sX7+eVq1a5dsXuxzKmjVrqFatGj169GDWrFk0aNDAXQIG4OTJk4CUWdm1axdlypRxr1u9ejUTJkzgww8/9Gp7zZo1TJkyhYSEBLKzs2nTpg1t27YN+Tr54+DBg4wYMYI1a9ZQpUoVunTpQuvWrQHYv38/DRqIdSIiIoIqVapw7NgxataseUbnNBgMBUdr/Q3wjc+64Y7PqxATor9jJwGTirWDhKCZaa3Haa3raa1vtioG7Aa6hHDcciCgBNZar3DEGqwkwIU4H/A1Mw4cOJCIiAh69uzJnDlzyM7OZt68ee6cgtOmTaNNmza0bt2aTZs2sXnz5nzOIKxatQqXy0WtWrWIiIjgjjvuYPny5TRp0oSdO3fyxBNPMH/+fCpXrgxAq1atuOOOO5g8eTIRETKuadeuXR5BBvDDDz/Qv39/ypcvT+XKlenbt2++/dmwYYN7nnDChAkMHz7cvXzs2DF++eUXd3+joqIYOHBgqJfUYDAYvMhXM1NKPQl8DJwGPgRaAy8AC4uwH/cj83E2GliolNLA+1rrD4L0bygwFCAqKiroSfLToM42gwYN4p133qF69ep5SsCsWrWKatWqMWTIkCIrAbNgwQImTJjAtGnTmDRpEvPmzWP58uXMmTOH0aNHs2HDBrdQKwpatmxJgqUKjxw5kkaNGjFkyBD/O2dnQlYGWKbEevXqsXfvXurXr092djZJSUnUqFGjyPpmMBjOL0KZM7vPcgDpAVRDnD8K547nB6VUF0SYOWf4O2mt2wA3AY8ppQJ6FmitP9Bat9NatyvKB/HZoDSVgOncuTOzZs0iLS2N06dPM2fOnDP+/h07dmTZsmUcO3aMrNNJTJ82zb2tb9++fPLJJwDMmDGDG264IWj9M4PBcGETytPffoLcDHxmTfwVyVNFKdUK0fZu0lofs9drrfdb74eVUuHor3YAACAASURBVDORCPTlRXHOc4HvnFnPnj0ZM2aMuwRMXFyc+8HtLAHToEGDQpeA0VrTq1cv+vXrx7p167j33nvJzZXgfGcJmKSkJLTWXiVg/M2ZtWnThoEDBxITE0Pt2rVp3769e9vMmTN54oknOHLkCL169SI2NpYFC/J3WKpbty4jR47k6quvpmrFCsQ2vwLbt+j+++/nrrvuomnTplSvXp0pU6aEfB0MBsOFR74lYJRSHyMR242BGCAcWKq1znf2XynVCJirtY72s60hsAS4W2u9wrG+AhCmtT5tff4O8YCZn9/5TAmYs8fIkSOpWLEizzzzTP47h8Kh3cR9MYXV23bzzvjxRdNmITD3i+FC43wpAROKZnY/EAvs1FqnKqVqAPfmd5BSKh5wATUtl80RQCSA1noCMByoAYy3FD07Cr0OMNNaFwF8EYogM5wvGPd7g8FQcEIqzmnFEtjzVsu01mc+YVIMGM2sFHNoN+RkQe2GEBHckac4MfeL4UKjpGpmBU2fGEo6qzHAk8Bm6/U3pdS/z6iXBoMv5SpaH4yTh6EYOH0C1i09170w5MOZpE8MxZvxZqC71nqSFfzWE+hd+O4aDH6IiIKwCDAei4biIP7fMPMtSD55rntiCE6h0yeGWgKmquNzlYL1zWAIgcgoqFwdwsLPdU8M5yOnLGfpXN9yW4YSRqHSJ0JoDiD/AX5TSn2P2IA6I0HTBkPRkZ4Cp49b5kajnRmKmDLlIPkEhJkSjiWcwqZPDCmdVTxwFfAV8CVwtdZ6aqG7egFSkBIws2bN8kpfNXz4cBYtWnTGfTh58iTjC+nynpCQgFKK+fPFqbR///7ExsbStGlTqlSp4v5eK1aswOVyccUVV7jX3XLLLaGdJCNN3nNyCtVHgyEoD70Bz3wMFXwMS+kp8PMcd+aZkJk5Dv77QNH1zwDkTZ8I7CGE9IkQRDNTSrXxWbXPer9YKXWx1npt4bp74WHnZgyFWbNm0bt3b5o3bw7Ayy+/XCR9sIXZo48+WuBj4+Pj6dSpE/Hx8fTs2ZOZM2cCkul/7NixzJ0712v/zz//nHbtCljrLydb3k1m/KJlewJMfgn+bxJUqnaue3PuiCorL1/mfQAblkOdS6BJ/sm83SQd8ZguDWeMUup/WuunrM9Paq3fAtBaa6XUh8CQ/NoIppm9EeQ19sy6bgB44YUX3CVYnnnmGVasWMHXX3/Ns88+S2xsLDt27GDIkCHMmDEDgEaNGjFs2DBiY2Np164da9eu5cYbb+TSSy9lwoQJACQnJ9O1a1fatGlDy5YtmT17tvtcO3bsIDY2lmefFeeg119/nfbt29OqVauApWa01kyfPp24uDi+++67M84TGRhjWiwWdq6T92MHzm0/zjXffggj+0Oad+gOaVYKt+zMgrVXtTZUNhUcihBnysJ7fLaFNMoIqJlprUNS7UodH/8z77oW10KHmyAzAz4flXd77A3Q+gZIOQXTXvPedu8r+Z7SXwmYbt26MXPmTH7//XeUUpw8eZKqVavSt29fevfuHdA817BhQxISEnj66acZMmQIP/30E+np6URHR/Pwww9TtmxZZs6cSeXKlTl69ChXXXUVffv2ZcyYMWzcuNGtIS5cuJBt27bx66+/orWmb9++LF++PE+BzRUrVtC4cWMuvfRSXC4X8+bNY8CAAUG/7x133EG5cuUA6N69O6+//nq+18hQTFx8qbyXr3xu+3GuWW9lw8vN9l5fRu5TwgqY13XnejhVpBWqLnRUgM8hU7oy85ZS/JkZs7OzKVu2LPfffz+9e/d2F+bMD7v0SsuWLUlOTqZSpUpUqlTJXZOsQoUKvPjiiyxfvpywsDD279/PoUOH8rSzcOFCFi5c6K4flpyczLZt2/IIs/j4eHcS5EGDBvHpp5/mK8wKZWasUNk8HIqDXGsOUp/nXnw5OZCaBJWqB9jBMl/7mrEH/B36PwnhBXwUmnu1qAmzKlGHOT7bQi0kF+cLT5gF06SiygTfXqFySJpYKERERPDrr7+yePFiZsyYwTvvvMOSJUvyPa5MmTIAhIWFuT/by9nZ2Xz++eccOXKENWvWEBkZSaNGjfyaBrXWDBs2jIceeijguXJycvjyyy+ZPXs2o0ePRmvNsWPHOH36NJUqVSrEtw5CRCSERxlrY1Gz8Ud5P3FI5oVKIyP7w/W3QZfBgfeZ/yGsmg8vTIayfpJZ2DLMV5iFhXk8HJdPl+DqXkOLpNuGAlEFWIPnCeD0yQhpIt34qZ4jkpOTSUpK4uabb+bNN99k3TqZ26hUqRKnT58udLtJSUnUrl2byMhIvv/+e3bv3u233RtvvJFJkya5y77s37+fw4cPe7W1ePFiWrVqxd69e0lMTGT37t0MGDDA7QBSpISFQ8Uq5zSV1XlJjXry7uvFd6asXw5JZ1E7WTYteIxYpjVgyw3kDat93i1++FKE5cGdsGUlJOQ/oASg2VVQq0Fo+xpC4XqtdROtdWM/ryahNFAQb0YvjDdj6PgrAfPkk0/Sr18/0tPT0Vrz3//+FxBT3oMPPsi4cePcjh8F4Y477qBPnz60bNmSdu3aceWVVwJQo0YNrr32WqKjo7npppt4/fXX2bJlC1dffTUAFStWZPLkydSuXdvdVnx8PP379/dqf8CAAbz33nvcfffdnpW5uWLGskw1zjmzmjVrhhZakJ4icUBF/dC90KllFXAPaH4rBNlZ8NWb0CgahviZYy4upr4Kg4f531arobxHlPG/vVxFuceUz/g9caO8J58UgRYqWptsNUXLTCCozMmPgImGrSDpQGit9Q1ncuLiwCQaPkcc2StVoi9uWvg2ju6HzDR5KEWaRMNFxq/fwjcfwJMToFqdomkzOwteuQ1uuAM6hxhHeCb8e7BoXtXrwt8CxEoujIMVs+H5yVDOj5kxO0vCP2yHD5vPXoIdCXDncJhshcGMDMHyMLJ/6PuWcEpComGl1G9a69Zn0saF581o8E/qKTh5GC5qUvAsCVkZZ37+C8VR4Wyz3TKgHNpddMLMHgCfLc3ENiEePxh4n62r5D35hH9hFhEpr6KibQ9Ys7Do2jPUU0qNC7RRa/23/BoI6amllIpWSt2mlLrbfhWkl4Yi5M9ECdgMRm6umFQKgh1/c86EiTHZFAu2tuwvYLjQWMLs12+KsM0zpN2N8h5IwM56W7Sp08cL1u7KubDUT8Ij22xrcj0WFWmIA4i/1+pQGgilBMwI4G3r1QV4DegbwnGTlFKHlVIbA2y/Qym1Xim1QSm1QikV49jWUym1VSm1XSll8kA6yc2GlKTg+5w6JqPYrAIEgpaxHna+cwqhUK0OVLyAs0vY7N0qD8zjf57rnngoDmFma2apIaXMOztUqiHvgRxANlvF7LN94szs0kMRUdC4JTT0MTHP/wiWTsmbZm3LSnk3loSi4pjW+hPfF7AT6BhKA6E8uW4BugJ/aq3vBWIILXN+HFIuJhC7EA+WlsAo4AMApVQ48C5wE9AcGKyUah7C+Qw2UdYkuHOUmpPtf1+bM0kjVa4SVK5R+OMBKlbNf5+Szu5N8n5497nthxPbBBzQy68Q2B6nMa6iazMQod6Xf+6S9/zuc19vxlv+T+a9GrWAa/4Cnf7qvb3f4/J+0tvTl0OJ8l6U1/XCxj3yVkq1Vkq9rpRKBF4GtoTSQCjCLE1rnQtkK6UqA4eBfH1StdbLgYA6vdZ6hdb6hLW4ErDcrugAbNda79RaZwJTgH4h9NMQiMx0+fOlBnH5t7cV5s+Zelr+7CmnQniYBCAiEiLLFP88jNbiuVYcD6Galht8lVpF33ZhsQtSFqUWFRYmGTPORlYRpzBr0z3wfjuspASBfle3Z34QTergDli3zHudLbjfDpDT1KQSLSruUUqNUEr9jlgB9yAOil201u+E0kAowmy1UqoqMBGxX64Ffi5sjwNwP1KIDaAesNexbZ+1zi9KqaFKqdVKqdXZviaEC5X0VHm3/9i2uTEjNfAxZ2KGOnlIHpZJh+FYkEn6YGgtGl5kANfqQKQli6DOzgpt/6wMyd6Qn6m2MNiCvCTNo1S/SN6r1g6+X0HIzhJzt60NFSebfvJ8bnV94P0uaizvAZ1ctNebmyVfiGl4/3bYvBI2/ei9ffHn/pu7tDXUu8xjBTmXbFmZV3MsfWwBbgB6a607aa3fBgo04gylBMyjWuuTWusJQHfgHsvcWCQopbogwuz5whyvtf5Aa91Oa90uIqJkJjSxS8BER0fTp08fTp4sXLXbuLg4Hv/HSwG3/+Uvf+Gqq66CnGwWLP2B2PYdiI2NpWKdi7niuh7Edr6Bu+++m6VLl3qVbomNjWXRTysL+/W8KROCUMzKkMS3zlFyekrhspBnZYgQCdUcZc8JhhehZ5vNDiup78EdRd92YalqaYnBtMWszIKV3rEHR4X5veL/Db8UwHFkmcP5Iu6fgeckK1aV3zaQtljBMmP7ejTu/V3e01PgTz9xZhkOR6qR/WHNd/JZ556ZFSHpKIx/Ek4V0CHFH1Nfhff/78zbObf8FTgIfK+UmqiU6koBvcJCcQD5Wil1u1KqgtY6UWu9vpCd9dd2K+BDoJ/W2v5n7MfbjFnfWldqsXMzbvxhMdXLl+Hdt8cV3hxXtgLUrJ9n9cmTJ1mzZg1JSUnsPHCIG13XkbBmDQkJCbRr25bP33mDhAWz+TQuDoDrrruOhIQE96ubK8iotyCEksEj7bRoiU5NOisD0B437FDJN/ODD8VpxbTNjCUpqa8teIJprvPeh7cCpzXLizVwaNOt4P1J3AQnCuAg4y8z/VE/j4P0FBEwgcypT02QubEqBcx076vRLp8u7zvXwb4/xLReGFbPh8N74Oevg5v/Q8XO/l9K0VrP0loPAq4EvgeeAmorpd5TSvUIpY1QzIxvAJ2AzUqpGUqpW5RSZ+wapZRqiBT8vEtr/Ydj0yrgMqVUY6VUFDAI+PpMzxeU1NOSu664STvN1a1bsX/ndjh5mB07dtCzZ0/atm3Lddddx++/yyhxzpw5dOzYkdatW9OtWzfvRMHhEX5Ngl999RV9+vRh0KBBTPlqlqy048WU8mgkgeYM3Ga3M5wEsItsBsMWeM6Rrd2vgnqHuWOeQtw/03KIKGjoQijUtnIfqrCS4+m3b6u87/8j8D5ZGRBZgL+0+zcqxMggIxX2hDSfL9glbJz4iyM7vEfe928veJ+C4Sto6jSS9x5D5D1Y6Zhl00Sb87UabPhB0mgB/DwbXjORTjZa6xSt9Rda6z6IIvMbIVrtQjEzLtNaPwo0QUpa34Y4gQRFKRWPzK1doZTap5S6Xyn1sFLqYWuX4UANYLxSKkEptdo6XzbwOLAAsaNO01pvCuXLhITLBZZ2QlaWLH/2mfzJUlNleapl2khKkuWvvpLlo0dlec4cWf6zYC7YOTk5LP7xZ/r2lInsoUOH8vbbb7NmzRrGjh3rLpzZqVMnVq5cyW+//cagQYN47TVH2ZmUJL+CNz4+nsGDBzN48GDiZ1h/FHvuRus8QuKHH37wMjPu2GuNdlVICaoDkx7CCNE2aRVJIU67jQI+WIvD0cQuLzJ1DLzmW5LpHNEoWt6DZYXf9BMc2x/672Hv5i/+KhQOhChwAoWW+JuTvM7KRBJIQ5/6mmWiDDCnG+h+8I3prHeZvNsu/cEGX273fZ/r+lMRZw155mMY9kXRtlkC0FqfsKaRuoayf0iTTEqpckAfYCCSP+uTEDoSJMU1aK0fAPzWHddafwOUoIjMM8POzbh/316aXXYp3a/pQPLxI6xYsYJbb73VvV9GhmgN+/btY+DAgRw8eJDMzEwaN27s0+Bpr4nuQ4cOsW3bNjp16oRSisjwcDb+/gfRNesDkT5/JvnTXnfddd4Vok8dheQkCC+AMMvOFE2sWl15iGSkhlbk0BZ4R/bkTYFldzU3R/qdX2mOiKiCZSCxtVXftEZFwe+/FH2bZ4p9fUOp15WTHWKWDOtHcmq3m3+WvJqXFGEUTZof81vD5v4rZts5Pf0Js9PHYYvls+ZrbrWDn8uUg7pNguewvKYfNLhCPtsJiYOZt5u2EY3RN6NOperiPFOuomTc2b35zHI9noWwFqVUT+AtpBzLh1rrMT7bywCfAm2BY8BArXWiUioSmUpqg8ibT7XW/ymOPoYyZzYNj6fJO8ClWusniqMzZ4WlS2HIEPkcGSnLfXrITVm+vCwPHCjbq1SR5b9asSc1a1r795Gbr2qlkEaz9pzZ7j170RFleDduMrm5uVStWtVr3mrLFjG/PPHEEzz++ONs2LCB999/P9/qztOmTePEiRM0btyYRo0akbhvP/Gz5ub9c0SVCyystAZ0wbSlowdk5Fq2HJSv5GinEFTyiVM7vMcTyxMMe4QcqnnUvibF4QBS7SLP54goSyM+A+1zxWzRJs7EO9IWOKHMKYbqEWpf81aO2nfTXoOP/xH8uIJeC39OKTpXcjT6smdz4GO2OXKi+/bhr0/JXFq9y6Db3XCtd2JtBr7geV8x2+M1uNs6X7DfRueKydn3nNGd5D0tWTTF3OzCm6Vzc+Qe+eqtwh0fAiHG/t4PnNBaNwXeBF611t8KlLHiidsCDymlGhVHP0OZM/sIEWAPa62/t2LOLmxSTonH2vGDBboJy4fDuFdH88b7kyhfrhyNGzdm+nSZUNZau8vAJCUlUa+eOBN88km+SjDx8fHMnzePxMREEhMTWfPTcqZ8PTfv8z0zyHyW7c5fkKwhYZZgTD0twic9GXJCeCDa9aac2kJ4hAhbexQbqkNHVFlxiAmULd0X++FTWAecYNgeg+GR0LQ1rPseXvorHCykC7sdI3YmMXFrLe+7YILKLmUSilYN8ruXryy/F4TuCakU1L0ULmsLiz7L/7poP+3m5vo/3/bfrO1+ftdQBwMHtku2D98+g5iOIa+jRbBB0U8z5f/ge+2bxMBVfeSzbcYsrAOHLSjXLy3c8aERSuxvPzwWuxlAV6WUQp5CFZRSEUA5JDi6WCaUAwozpdRzAFrrBYjbpHPbv4ujM6UGp/kjJSn0EeexA7RudDGtml1B/Ky5fP7553z00UfEtGpFi+bNmD17NgAjR47k1ltvpW3bttSsGcD7SmvIzSVx1y5279rJVY09ZsfGdWpSpVIlfvnVj9nLeoj7zpnNWLDYbji07wJQtry8Jx0JTYj54pWhJEtMPQWNdzt1DE4eCT05sr1fqA/ugmC32e1OaNtdPPcA9m8rXHstr5P3Mxk/VrG88Wr7yXOQlSHzr1db2elC1cwy0mQQZ5dMCQ+XOK/L2+d/bHiEaIs/fgWTXvTeNrK/Jxs9+P9f7f8DdvzmWc7MgPXLPKZHe47QiZejkU+bC+LknHu3ytzhrg3e22f55L797hPZt2EzSX9VLUj8XvOr7ZN6r9/xG6yc41muVqfgXpY2RTLvTIQdq2u9fKuThhL7697H8ntIQnwiZgApiNv9HmCs1roI4hHyEsyQPgjJwwgwDJju2NYTeDHPEaWVqHLBtZY8OP4c2ZnIzRrY3m0XwLSZM/ULOa52Q+bPny8P49RTcPGlAPTr149+/fImPRkyZAhDelgmisw0OHaARhfXY3/CL97CJCebtQtmu13Fly6cD8cPyDatcblcJCX5BA2npwTPSh4Qe/BlEUqORlv7c/Y5I1U0PHvOonItyA5hLiw7S/bLyfaeX0tPkXW+9dFsT8r85uIAfp4DCybB8C9DE5Z7Lc/BBR/LXFXjlsH3XzlXcv+N+Mr/fIntgXomZkb7+/sLmp71jgQJ/+VvcGmstwk6PQW++RBufsC7cnPCEuk3eAvZClUdJt8AZGbA0X0iPPf+DrGu4PtXqQVV60hQvhPn9Zj/kWifFzWRfvpLq+a8tr6DJTsmMCvDfxC4P+/c5dMtIZLPHFe9y2Qu0Vfg+NZNa9is4MkCbIpGmGVrrdsVRUN+6IAEP18MVAN+UEot0loXoHhcaAT7h6oAn/0tl24Kog2kp0KmTyaNgt5Qvu71SoU++VurAdRs4BlFZ2daDxHnH9b6Y9gP7lDqg7lNNwX4LvY8m5NQrqXzj5udKQHUmRnycLTNnRWrBM5aYdemAo/zh1PTOn1cBHOw6gKhfM2Fcda+IQqTug5HnQPbxWGgbhPPfKIv8z+S90DC6kfLi/ZMzIz29fH3UK5jFbScNQ5qN/R2fji4S0xXB3wCwOdM8Dz0D2wX7fPIXhGEV/UO3pecbBGSUWUBJRlfghER6emjE+f1sOfPosoEHpDZA5EYlycjii+B/n/+Bmc164kw3rU+uKnU9jr2fT74hg+sW1r4eLWiEWb5EUrsr3sfy6RYBXEEuR2Yr7XO0lofBn4CikVwBhNmOsBnf8ulG51LyPLZX8BnQa9GerLchNlZ8sfMTAv9gRlZRv649h/anf3C4Wxgu9e7s104tRCfzqaelj9S8omCfxd/2k0o8VtO4Zp0TLSyLMvJxb4OR/ZKDkV/HN7tcA7xk6YoWJkPu9RNKGbGgiZPtmOQbCpUgYfegPmTvM1KeRCTcR6hZnsGFnbUDnIdwZME2UndSz2ffX9LWwD4Pix9zcmnjsk99Mfq/IN/7TmwdcsAHbiysx3WkHLKU6fMqx3HdfLVBv/wUy2kSSzUuxxaXOunrXxu+FQ/ac8O74HBlmEqmCft6gV5+wv+BeeZpqMqTLWL0Akl9vdrwI5HuQVYoqXy8x7EeRClVAXgKuD34uhksCsQo5Q6pZQ6DbSyPtvL+dhPShk5Ofm7JNvagF+hU0BpZu9+eLcUTQzVtVxrGQ0fO4iX8E056dkOnklwp8AL1NWThySnoj2RHYr5zcZfto5QHGLym5vR2pNDMWQcX8xfFhK3Z2EBgqzb9vAcGwq+v+Ov30gl41NH4Zd5effvfKun/ZcHwMRnvbfXuFi+y5kUlbwiyDyWMx3Vj1/BHsczxs6ykZ/p+chejxC2nSd+/xW2J+Td197PThsVSDNLPSX37ukA6bKcQt8eXF5veSD7+6kqV5f52C9GSz1AvwS4IZz/narWvPSOBM8AI5jWbGuNwf5TdohNYedFo8rAi1PgH1Py37eQBIr9VUq9rJSyy4F9BNRQSm0H/g7YpbveBSoqpTYhQvHjoswi5SRYpekzjJ4tTYTwsPIt6xEW7qiOHOLDLrKsjHgzUj1OJM5jfWNNdK48+MMjPJ6DIPnibHNe8gl54OXmeI61/+zZWZ6ksDb+3PUBIiIgO6JgD047XqxqHelfRqr/kawvzhF8uYpW/jvH3FtBTCdlKuQN1PZ3/MEd8l3tkXzZfOZ3QBww6jX1vvbB2LTCe/nADk8292ZX5d3/htvl5e6jj6Zy+rhokFmZoZmK/WHHmflek0O7Yc5473VZjsGJLeiST8g9FBbuqQnmxBmQbwdDT7HCiEb6BAf7Pvjt2mE/fy3XqWwFj2YfKN9mkxio5UjnZie2toWOP6Fw/KAnk4ivZlmtjmit5SrK5xOHxAW/Tfe8SYTbdIMlVuJhW9N2ni/pqJgeL2sHFSrL98vOyqtZV68rZsqwcHHT/+HLMzMln4Vkx/5if7XWwx2f0xE3fN/jkv2tLw6KVTctNaSnyEMjv4eoc4RVoRCBirXqy2jbSVk/qXlscnJk5OvPdOfUPrIzxc3dFlQVrNyAOVmS2eGkNXdUq4G3sLJNnLaJKze7cM4GZcpbQci64CbXMuUkPsu+Lrm5+Y9Sq9f1jHr9BYz6PrDs3zUzDfcIPBQNdMtK+H6Kx+SWfBK+fDNw/kg7qS9AjXreDyh/1yXhe1g133G8T8b3P9bIe0o+iamzMgJXAbBNrr739g8z8u7r1Jjte0lreOU2mP02zH0/7zHa+XtZx9ju9774Dgps0/aCj8W1/oXJnm05Ae7FyjU8GfIBoi3ToT8zqo1z3s/3OvzlCRG6FzWCflb47G+LYcwdYh6+a4Ssu+F2jyCrUMVjznT+xn/ukorWtskwO1N+G+f3SE/xBF7n5ni0Yec+I/vDJyMCfx8nGWmy/5Qx+e97nmOEmRdBnsSRZbwFiG0CKV9ZBERuroxMg5UWyUzPO5+jc0W7iPBTy8t+SLgnhx398x2pZ2c4nDgcDyIInPzX7mt2hsdE5vugDhb4a7d7aJdoPilJnj6ePu7ffJqe6vFSjConD63sTM+DLulw/mbXshU8g4CIKKjV0KNhOrE9+exRe6XqnmsaSijBrg2S29C+rku+gA3LPbFbec7nEKxNW3tft59n591/1jhJ8puVIZ57l/hUOa5/ubznN2qf9A94fYj/bfa8je+9bQf9gv+5JPvarV0k7+uWQmPL7d3tco446dj3gT1QsoOFfalYFVq5PMs/B0m5Gsikn5Xpya8JnvPYwsXvQCjE+XA7j6U9z7gjwdP+Eke6qBoXe7Qtp6nU7oM9n7vxR7HAOE3vcf+CuROgYy9ZtoWw/Rvb321XiJY4+z4uidlnzjJGmDkJplVkZciD3tfDztaa7D+RjxaVmJhIdLT1EDi6D04fZ+Qb4xg74UNZl5EqJ1bWZ38PLncSXse6sHCo1ZAhTz3HjLlSCu6BBx9g8+bNeefQbC3k6D4fxwf5kyds3Mw3P1p/Bt95qkO7A07Uu/46mNXrNuTdoHM5uns7keUrMmHCBAAee+wxYmNjad6qFeUujSa2ex9iXT2YMXUKQ+5/gMaXXUZs977Edu/DNa4b/J7PzbGDntHv8QPSZ6frfJny8rCxg5jtaxpZxjMIyAghO/82SzOyr5nd3vxJMPKvnqBmG1sI931MKhc7hZktmPyRky0mKd97y67knJ+2HKzkjO2hePFlgfe50qpK7+VqbwkzW3uqUc+TzLf3w579GjYTR5VLWng0pj93wR9+HDfAWyO2B28164mAdMaYBTIzbvpRgtFt7LRSNtHX5T3GeW/4tjnnPTnv7s15f89r+8OnfjSk43+KQLu8vTucBvDOhQrQumvec9qeoM451JadPfdHMOclgJ9mwX8fDPx96G6EXwAAIABJREFULmCMMIPgpr7cXI/5ReeKJuYs8ZGb422eCdaWjTNrQPnK8pC1a3wFy97vHGBmpEhuQwcfTniP5s2b503kaxfl1Bpy8zqpJmzZyjeLrIeCr5dfbrbsl53pJ2uGnz9SldqgYfqcb7mqfTvi4+MBePfdd0lISOCbzz7k0ksakvDdHBIWzuaWmyTp8uv/fI6E774m4bs5rFi8UExugUqpZKRYTgJWNoiMVO/MJTnZcj3tB0NYmIywM1I92eH9eZTl5nri07y+puV5+r0zmavOW1fLnledO0Eekk6zoy0wQNIrOYNzNfLb+7psB8qGYt9vySe9BYA/ypST+y1YcO/6ZXB5O//lVmyatJQ+ArzjyGZnOzBUrSVahq/DSE62p7/HDsDvK6H3I7JsmyIrVffWcG7/B0x7XX6/+lfk7YtT6Nr1wMLCpf/5BR/7ej/aWlh2puezTaAwk4ZXWvPbwU9FPUtA+cmN6sVFjT3nClZAFyRo2zngLEmFYM8xRpiBw0Tl5+GcctLzkIoqL6Y0X4+9Ak/ees7j6t2f50eOokOvAVzeqTs/rPwVEI3uui430ObGfrTpdjMrVqyQKaka9Xn8lTe4IqYN3Qbew+FjnpGcq1sPVq9eDZFRVLwsxm0KmTFnHkOe+ScA0z/+gOjoaGJiYujcvSeZmZkMf+1Nps6YQWz3PkydPY+UlBTuu+8+OnToQOuef2H2d0vh8B7SEn9n0MCBNGvWjP79+5OW7sccaE1Gx8+eyxuvvMT+/fvZt2+fZ3t5nyBmtwemz5+yfCWPpnLqmCf+zCloThzyXHtngLUtkG1hFhEl2lp6avCR7OnjIsx8R+ho/2ECvqZD26EhN0fukc63edzfnSmYPh8Fnwz3LOtcOH0iryPLgo897dmkpcCHL4gm4bwPfefbbLIyxRTl23/ngGrbGgnwdWoZdS7x3r+jI4bMed71y6Uvttny89FwRQePRvjmUPiP5eSSlSFpm8pXku22efLipjJ/aFOznpj8Vi/wHhDYOK+HbZqtXlce8rs3ezRIX65oL22fOCTXNjeHPCZ5J5t+8m8ubdhMBjJbV4nnZiBsr01b+J46Dq39WB1WzfcMAgqSNBvk+hqAC1CYueJcxCXEAZCVk4UrzsXkjfGgFKlZabjiXEzdKKUtktKTcE3pxVe7ZN7haOZJXJ/3YM5uSf30Z6ojKNc9vxWCN5/zgZybTXZ6Gr/O+5L/vfQPXhorCUNr167NdwsWsnbBbKZ+9AF/+9vf4NBuZn72EVu3bWfzqpV8+tZrrFi9Vh7UTmyto2x52RYR6TbvvPy/d1gweybr1q3j608mEhUVxcvPPMnAPr1I+G4OA/v1YvTo0dxwww38+uuvfD/7S559aTQpqam89+kXlC8TyZYtW3jppZdYk+Cn1lTqKfbu2c3BQ0focOWl3HbbbUy1S+qACDs/WtGzr7wmpsfufbhjyH1i3rQDfZNPeDK0OJMPO+cNNYHz9rmvifZ4W+rcvBqd/UDL8jErBsponpkOM/4LM96QZd84s6gycLdVGdxLq/NFyxzsPp+aY7YgdJofU5PkIXnysOdB22Uw/PVJ/03bgeM7fFzlG1zhY/r0+X6+zhpbf/Ufd5eaJAmGbbNvTpZoP3bfkk/I/f7bYo/n4cJPZOBwdJ91bcO8ta1xUgqJyjVk3skX58Anqqz01e7vx/+AD33KX13eTsyYra6X5dnvyHzd/u349aBtdrVo8FXr+J+Dmz/JE3ztFD72YMD2ILXnKzPT5Pse3CHXwdeT9uQhjwC2qzkEyvnYrqe3xcLW3osjcXYp44ITZn7JyXIUJwwycg9Uq0trz5/Jxw1XWTkUfUd+yvHw+OuNMlpr2yqaxD1yU2dlZfHgww/Tslsfbr3/YZkL0zksX7mKwb1vJDw8nIsvqsMN117lME1Y57Af6LZ5JyfHLUCvbdeGIQ89zMSJE8nxsjh6/rQLFy5kzJgxxMbG4ur9F9IzMtiz/wDLf1nFnYMHw9EDtKpXi1YtfBwWAFKSmDptKrf1uRmAQYMGuU2N0iffuRD5LGbGOSR8N4fPJ77n8cS097XnboIFhx5KFGcUXzLSZCLeOQ+jlJi9bFPt4b0eQWdXjLZzFmodOGRh4w+eB65vstjFn3sS1NZ2ZLK4tLWYoG5+UO6XQLdcxaqSgcJpunZrsp7flO/jYfLL/tuwH+C+mseAp0VztPn+C0m9ZOMrWPf87t+D13eO5+Rhmcc6ddQ79+Lsd2D669Y+lim9UQt54P8YwDXdX3op8BZmxy3tvNtd/vcF+e1OHoHpY6UwqD0w8XJ2clyfmx8QIeGbtNjpRWkPqpz9rttEYhPtPJF29pBpr8Mb93vm053PkbpNvL/TRY3hqffhMZ+ckDZX94FBwzzL9S+XOct/TfO//wVEASJkzw+WDlnq/hwZHinLVoBo+RNHWNrjI/fIqkrZKiztN81twqpZtjpLe1vuuWERXFTeYQJR/kdINaLgxInj8sex5saOnzxJ4waeWJkyUaJhhIeHkW1pBW+++SZ1atdi3drV5IZFULa844GWk0WekXSZ8h6BGhaGUkrMQRmpUkLGMr1NeHUUv+w8wLyFi2jbYxRrvvkyzzXSWvPljOlccWUzGTE659Ey0jzpvJwPlVoNxKni1BHip07jzwMH+HzWHAgL58CBA2zbto3LLrssb75FvyEOQRLDOklPFS0g9RRigw00f+CnjfKVvR/Edr/KV/ZoLC2uEfNbmfKSrqnLYBEcgdiw3Hv56H5I3CifnXW+crLkwdbhZnkFIiVJhHjqKc9ofKGVmDwn21vDz0yHNQtFC3GmpXKbDn2uwfE/4YtXvNc5H8y+GSm2BjCnBZuzya+i9CUtRDuzqX+Fx6MQAguzS5pLnNZHwzzXxR7sgFwLpzZ9cJcnBi4nRzToXRssJ6oG0s+K1eReSkuGr8fLAPGkw/KiwiR/pW+fnN+/Sk2pNm7/LnUuEe3ervJtF+t00rKzOFg52wmUxs2+Jr8tFoEWEem5vwzFp5kppSYppQ4rpfxebaXUlUqpn5VSGUqpZ3y2JSqlNjgrUBcrmWlWvJXP6DAz3fvh69QKvPLtac+fyaeNitVqULd2LZYsXQa1GnD8xEnmf/8DnTq0zdsmuP+ASUlJ1K1dm7DjB/ksLo6cnByoUJXOV7Vn6tffkBMewcFDh/l+xS9++laFOrVqsGXTJnJzc5k5f6F7/Y7E3XRs2ZyXX3yeWtWrsvfAQSpVrMDpZGvUGFWeG6/pwNuv/gdtCZLfNor7cOeO7fniSwmE3fj7H6zf4njwhEdCbg5/7NhFcnIK+9euIHHDWhITExk2bJhHO/ONmTt5SISF7XxQsXrgwpnHDngLrOxMz+jXdmzx5zSSR5YpKxA9wrN/eKSYf8IjPO7OP82CxZM9CXgDCbKa1sDEaYZr2tq7r07zZ+JG0RQXxsGGHzymqqZt5DvaXpR2tgrnHJA7tCAnb4zdnPdg6qve62wnFd9BweLJ5CE/z7gqfuavfAcQ7XvKu+3JF4xjB70F8r2jg8f/RZaFR/4nJtJD1jVpEiPvvl6NTuHglfBAQ8/7JLascTT0eUQ+120Ct8u8svv6aw33WQHg0Z38V4h2/t+P/wnfToQjloDOTPeOEbQdaJwc9JlXS1giTj2BqlFv+EFi8nydlD57yf/+FxDFaWaMQ7LrB+I48DdgbIDtXbTWscWYzTl/fB+8zj+aLbzKVpAHiz3K982+rzWfvvUao14aSWxMDDfcdhcj/v44lzZyTLCHR0qsGcif8Mg+Hn30UT6ZPJmYbn34fX0CFSpUgIrV6H9TDy5r3IjmsW24+6nnuLpta6uvyZCbKxqZgjHDnqH37XdzTd/bqFvXMptFRPDsK6/S8prORMe25pp2rYlp0Ywu11zF5m3bxQHk67n866nHyMrKpFWrVrS4riv/eu1/ADxy9+0kp6TQzHUTw//7Dm1bOcpt/LkTko8TP3su/fv29WQvAQYMGOBtavQlJ5tnh70oc2ZXX0tsx6vJzMx0Xz83vp5e5SrK6Lp2Q085Gqdm7OudV70u7pRW/uLpsjPld7QzeSRulFdWhve9cN0A73gpW7tweso1ifHu+2+LPZ//v73rDq+qyr7rvPQKIfTepStFQIqggF2wYHesYxl1ZtRxnNH5OTI6fRzLjM4oDvaCFbFjwY6CNBFphiKdQCiBhJDyzu+PfXbOueee+/ISEhLMXd+XL6/ee94tZ5+999prt+xI3sWcmcAr9wJ/Op9eT0wC5r8HPPdn+m43NVHzxLzpez3RRsvdzD07Z/v1O/r3mTClq5jcYX7GpQfZdQD9H3Kifq1tD20EAF0E7tJUtPHJC3pSPvEKcsjNRZld/3b6tTSu4kLtvXDuivuZMbhZJ+D9XbEMtu3lNGutvTv2um1ja3R8rywZYK92wwp6fNZNwLiLvR4XszR5u2wUOVT9xWv6s2UHdK0p15PZHrGdE22EqLMwo5Ty01gdRZWCcr4Q4tS6GkO1kZjsvZn4Rosk0uRRXkr1NgWGYHRJsbfNiE3nLTuAPj174KOXHSthAB+/9DRNwAeK0LxZM6yb+zFQXooePXpgyayZACQQScTf/v0fYO9OCCHw4J/upNh6tIJWgWpVV1BQgGbNmgGFOzH5tJMx+ayzyLhmNaNJeu8uvPq//5A3Y4RlmuU0xddvv+oZ1yN//yOFWzdrunhaWiqmP/4/8qSEIIbcAa/Bv/Pmn1MNTsHmSsMyYMCAyi7anTu0x9LZHlUcPHHPH71jymyq2XeRiFc6zERKGv3+pGSaKBKSSJIpPZvOS6XnoiawSAIZvaLdZJyi5UYn5nKA5wdm63FIqaQYHvfus1fo2PQYTCEqVnTggtfzfusXj+41VD/OX+8NYQHUh8ssfI1WAEceR6FDnri+/Uy/P2CsW+PSJmkw5X3p5zSGSs/V+D3tWPLKaFxqE0CycnV/tmPP1eSGijIae4sOXmp7PBqdQujfMPw04J4rvCFtm3TTYwjwj0uBkWdo2vunL3nHznjy9+RxzZlJjEvGynm6dmzMeeQBlZcCF/2fUWCuMPx04H6LLWh6RP1GawNPA6Z/W1aT13nMJGK8tu1GXbnnvq0XI2Y49fzb9HY2qEWGKXQw7XZaLJryYJzPa9U5vo7sjQANlQAiAbwnhFjgaBTngRDiam4qV15ew+7BfIM3aeFdPbF+opkITkmzBFIlkRoYxYVehlNVoroZTXXC2Adjwqko9+YFuLuzuoknnH8p+vftjS5duvg1I1kpvrL4OhpbmzAtS3uKNoQgL9BU+zDRvL2eCKvTWsf8bZFE8qKYxm+O1Tz20Qr6LSX7aEJKSiGDUnaAzhkbjIREem/fbuVxqEknMcUg/hiwV72P3qpLAxib82hiOlCsO2az6O37TwIzHtBEEsAv+Gt68Cnpfo+qvAyVx5fPp0dOLdu/Gr/iz+QFmGDiyppv/N4L4/MZxPZjSbG/Xgy8PdX7mVYd9e+790r9+jv/A/58vr9GKxYm/ZyMbtvu5KEMGEshVQ7JcYhyV76uz2vfE0jLoMUmq+2YiEbJoJ50pff1ZV9qijzgLVb+5AVtPCsq/C2Dgrw4Zg8HtY1Z8B7VGvIiYe6blOsM6pnYogPpOs59W5NwqmoJdTBajj9SNFRjNkpKOQjAyQCuF0IcG/RBKeVUKeUQKeWQxMQaOpo86e7d6Y5rM9KyqOZpv9Xqwi40NsNhLu1AG/YqWFrtQKLl3oS8yYwDgNRMvD/9STw3TU1APIExC668lFbWjIoKv6ExPdKcVkCu0j60CRqJSRQKKSlyG8TEJFQaC5dklCvv4kJqBtUYRaMIpPvt3aUNdGkJ3eDRcr2YYHZiUgoZxpJ9inavtsdNPQFveYO9yi/cEZv4wWoX3QfRf64Zat1FG7RYiiOpGf4C7PJS4PWH6LHLmG1YaeVNBNU/2aFH89rk7+/a5iW/5P9ARoWJL65apxOvCB5/EIKYp8mpOprRczD1gXvkZv0+e11pmTp0u3EVHddIAl0TLa06uNadyaByDipHhR9ND6hjnxjtdBzXmCuvCJCeY25bChF+abT2MQ1Q0R5dGP/1u8Cc14LbI331BpV3vPOofs28/9t09ZJ6AIpIvPzP0Csz0CCNmZRyk/qfD2AGqFtp3aFMaQOW7qfJMKgKX0S8HgTD9r4SjBAB39AsjGujaDewz1GbJqN6xQ94V3W21iJPDOZKMiGRPL60LH8z0LRMf+dkcwLfucVQzzAMLatySGVgXN2X9+3WnqxdqFtSRBNlVYr1xYU0KVVUALLCG7IyFxKmASovDV75msy2SoUVw6BJ6T3nbCTMQmSXYrwNu9D41fsp5AjQRMVhOrsmaM92v+EvL9MTcode6nvG9bDya68xG3YKEQc+94aLPeUCfE7ZQ+vSX59fLiEBiLXHlHFG/g/xdw9g5Lbxhj1HnkleyIL36PwWFtD1YNcGvvlf+l9e6s015q9XlPkKrWiSnKa0EtX1zXkru5Ri7Pmkej9wvHusrvWS614HiGTDi5Rlc3T+1fTE83+g32mCj699/379jtcote3uvR8LNulz12Mw1R8mJHpr8Krq8t0I0OCMmRAiQwiRxY8BnADgoPinsiqW1oFir1Ate2f2aiiovYmVN4LpIfIkGasvlN25GlDeWUDY1AgvesbL0kHRqJZ0AmiitI1ArPBnSZG+ecyeUvYE4WrGyEWyLuzcUlkuEBPcVmTbWu8KNdZkGpPCX6RrmypDsMb7Sh6o8jph4sGxk2OP04Zr8nvjv/rxE4oocczpNBmde6v/850VqSY9ixYgue10FwTTeG9Z4z3OHD4z80OAl/r/6cs0HqaId+ytj8f7TxKTTkoqKbD1OJd/Vb1edwBtx+yZ9sUM4OLf63YsQ08B3v4f8MFT7u9v+t77XETImG3Oo9AvQAuYgs3EUDTHt30DsNzIQXYfSIr2ZqG9RzXFcf0EXceAJrhsWEEhRYDKOGKBrw/TW2Y2pokJlwBX/0M/N0scTr6SCuTNe6/7IOA3T8fedyNAXVLznwfwJYAjhBAbhRBXCiGuFUJcq95vLYTYCGrk9n/qM9kAWgH4XAjxDYB5AN6SUr4btJ+qkJqaioKCgqoNmgvVvXkrYYQbzHb11ekGy6tVl9ZjeakVCpMUDty/l1aEbFz37NBGzPRu7PxbPEhIolCnOTmZRjy3rdGMUBk9l5I9EKMezPVZ47zZK9qyA26v1ES0wgqbScqVZRp5yqI9kFKioKgEqZnZujar93Dg0rvp96Rn6waQQfDJYMHLqmMUF9I56D2cPAYT65ZqVfaSYlqVszc5eIL+3OpF3hAaw861mKokxYXkLbAx+cRRaFta4s8dAeQFVFdqSQ9KPzR1BTv18Xqk3Qd6v2bvTwhgwqWaJGFi11bvfgBdsA5Qbg+SPENGn2OAo5S8lCv8HY16yV1BYGWTHZu82we8z121eiwmbSI92+vRsobl0i8ov/n6f7xCznkLqx5jI0BdshkvqOL9rQDaO94qBOBYrtQM7du3x8aNG7F9u+MGZbhalu9WYStb1YGRmOzPlTG27CTWXCSBVlAc/rJYhAD8Uj6MHfv8pICUdO3VZBR5a1hSd2mSQuU2jYaX5vc3bQ8eu4k9ZfrYRBK0x2QjIRHYpYgX+/cCBcU0cSYmAfm7aVIQwj1JArqNTmEBGcBIROcXCop0uDIh0btaFoLo93u2a7Fm8xgBwNad3gUFQB7Phi36vKjtpkYk2rfrQP2v2najnFXeIppwK5KIMBALVeVHecJc+AEtPl77l9sAtuxIVGw+v+uXUx4zKUUzRQH6TN9RpCRvHhMT1cmpyGjw9R6Ek6/y5nrGXUy5ps79NNW9xyDN4pv1hP7s5jzv+Tz9OuDhm4LHkJBEocJlc3SodOipwLy3KHflytEOGAss+Vh7ebztCZfQdbF4NnDL43TuLvmDVyU/LQM4/U7gYSOfxw08TfQdQVEHznGaMIkxrgWXS1h87bdkoEYqEenm7UjE+WWjisnOjU67DbjyL/5tNSL86BVAkpKSiOEXC1Nu9z7vMwIYdjPwzN16FQu4Dc/4S4LDJFNmUDNHriWZeD0wS13wQ06ibXP48dxbgRf/rr/boZd3BZqQBPz8QeD+a+j5TY8Cr73q7nvU+xhg+Zf6e537EvPt5KuAWY9SaMP8XUE4/Tpg1n/c7w09lSaVfbsoGW8Wpp59M/DOvfQbrvyLVnafMsOt8t53FHDWjcDdKqzXZ4TOUV18J/DK/e4xjDkP6H8kUN6SaPTP30/7/uhpb3iU8bP7qZ+UTeCxaeUdexMzcMNK7R2YBnLIiWRY7H5clYr8Ecqf2WoRTD7IzCGPyWXIAArpDT+djsPWtToUuGqBl6DUdQDlvWxjJiWFDfuNBuZ5yyCcGP8T4IOnad3DUkvtevjDfIxjz9GU+CEnUBiU9SnnKPHlPYYHNuosbczMMN8Hz1BuLjGZ2sqYmo4A3SPzjaBMYhKF2Ft30caM81RBdVZ2Xpebkhbt0TVxfHzte6l1F380xaV4IoS/1MLE6T+jRdc8g5rP4OPIi+Of/4dyaAve18Zswwp/XaQ9Lpe32sjQ4HJm9Y6OvYHxF5MnwiE1Zk7JKPBLq9uuKcfjwi6DpWau3Macow1Zxz7ehofp2f581MTrKOfB2J1Pq0sWozXBhgwgRiDf6Cx2G0TrHXyC9/kbAYYMoAmdFc09aijQhqHX0Ni5LA71ffe599iYZIu2Xb2aeCa6HwU89AvS9mvZif5WzQeOOs4d0k1KBk68zP+6TSvnAtWgUOz8WcCaJXqyGzSe1NrZ07vmn24pJj6++3ZRmNCETYopL/P3MzPzrv2PJWO11xpjUgpNfHNmkjK8qzzCZgJyaYrpmQX0sANA9W+MD5+lvB6fS14omNe9KeNkk18qyskTPeo4Egk2w+HzrexC2+7A03fR+TnjF/QalxBEo0R2MsPHNz5CHr4ZauVjOWemXqjc+1NSyJ9jLU76jQb+e6P3NTO60GMwHYsOvYhNGYRWnck75a4KJqIVlO+64UFSQMnOpUiBjNI9vn+fXycT0J5ZjVMhPz6ExgzQeYuLf0831xN30HM2VKbXkdOSVsMMW0bHxn4HHXfcxV7DxHJJHIbKakZeGIONm9nheO5bwNRf6+8G1XSZK3kO3VWU042YmqEVvkXELQUVpB044wFvx1/Grx7T6gbtj/B6sn+7xPtZ01iYDRcBymWMPJMmv96Goe9p1GttXUeT09fvUpPO9j3IC9640u9Bp2cDH02nidfF/DLzcUFEHxPb1pHBklEgbzFNxCxB5FJ6B4K1BrNy/bWG5aV6sq0krajfNOpsEgqe9zbw5B36O9f/izxTNqr9RpHXYHdVsNuQvDuNwnGtO2tjZi94zNzRv6/Tj+e8RrT6WDlY02tISQN+/zLQZQCF9vqNpFqyH5bpRURaln8bzdvRYkQIytXa+UIZJfbkpOv1a1m5VIjOBmjgOHdLGUCRpqwwZRBRievx9u+l63bPDne9Il9THz5LYdAgTzctkwzXynnAe4/TOYhWUBTmwRvcizkOz4bNOSsRGjNAXyzz3qELrrDAbYS6HQW89E+tmddnRNXbPv+3/teyc701J7y66q/K6bat84YjiguBWY/p5zdOpQs+EiH69oAxNDYTWc28XXfNCbyinKSSSop08ak0ClF/rrykXsNI2f3Su+m5mczespo8WMC776wcHdrZarER7fAeG1IX+o8mz3PXNq/iisnwfPtRPcF/v1DXapmNLxljzydDt3i2PyeTletlosXThdoEkxr4+HxuiDczvR6gia/I8DwqIf3e4fN/pokM0MeQ/yenUriWQ1SMFh1oxc45woLNFMq0J2Xuk8YoLSFD9uSdlJvJtAyriFCozIbtyTNunKpJC4CexJOMdi2JpOWJo46nPNTjv9PH0cXw27GJFnSRCBUWm2odLTuRd7RxlZf5x2HrkiLaZ9cjKUyZnu1tlgq4oxXP/9n9+0ZMAlp31R5T3kLKWdngvPTaJXT/mgovJt5/ipiuc2bSwqzsgD7XRXtoAZbbzvudjr1pgREWT1ciNGYArQqbtvQyhFwXSWEBhcR4Uo6Hncge06iz9WtLPvXG8rmezBTYfdZSNDexYxPdINEKKuAcfAKt0NIy9aScng1MvhkYptTCzAl8zLl+1hWgw5HT/0rdgNkQcyjn1Gu8n+eQUAuDxzP7OR2i+vQlN2GEV6x9jqFGji48/Qca857t1AmZYapYNGmuV6Yr5rkVxPn48++1a38A1UvMWOlHy6tWfHfBXDwwTE8BIK/JNuJ2GxUTIkLeC6CP5WzVuYE9iWPPIZr5lDPp3HF+5as3vNuyjcTw07U3XlZKk29GU6/2Iu/XPAcM17EE6D4qLyVDbirqdB1A237gWlqsbV1LY7aLib8L8GxL97uVMbJz9WLtM38XCADA/71IOpjRCvL8bO/cdZ26ipzb9fR3EV/0oVdlpLqwRYUTElFJ3BIRalNUsInyigAZ4s79vAQxV6+5RobQmAHEdrJpwZ+86J/wefV8klJDCLrp2vWknlUASdkA3tX66kXw0Ih5wt1mqnvHwDOGQnZJEa1qN31P3iSHsratownZFYU44mi/PJOJ7RuocHXnVmqUyL+7SXNvbc5r/6b/7KlmNCEDZobTuJ29udrnFevqb4L7hAHA337iTayz58ooK9XGLIid2W80TQJmOM4Fk1V3we3eXlzxopXZs0x5qx9N9+9n6Mn0eKJl6ABagaeka8+hbXcd4ktJ9wrbAnR80zJ1Hd2KubqezYZN+olG9YKE86lfzHCHQ81eZ1Xh7UfJO9611csUXjmP6Pg2g+8tKw8dhIQk9wIybyGd/1jF+GbngeMu8NcsxmplY4INfZCXVV30G+X/TaPOojxa536US+SxDzmRvN5TrvLm7vqMAG7+X+2M5zBGaMwATR03Me+eW85/AAAgAElEQVQtb0W/iU59tbFyYcJPgJ/8HvjjeZrdZaJzP+/NNFlRf5d+5v1c6y7Ar6bFHvsHSnJnzLnkhZmT8mO30++wsSlPN0qMhWfu0h5q72OIbbnbQSVe9iUxFX+q2Jid+tIKv3k7WmXe/Chw2d3+761f7mdp2TDzGC2sSo79+4DjVL4zqAi8aI/fy4p17n79JBl7Nia/VAWxPQbTJBOE3LbeIl1mLv7wnfdz5WU6j9mpr+5EzSjYRCEzJntsWkWlAm/8l8KHPB5GtMIdNgT8na9tuK6NA8W1M1F36U8TNeCdrAu2uD8PkOdoayuaSEymOrPWXf3vrV4c3DwXoOagjH4jaaHaY7BeIAWxe+1jWN2wXlXRm36j/NdVciotUM77DRkuJtx88DSFqp/9o5dJG486TSNAaMwACht+7ajLdjXTA8jwdennfg8gAsmm7/3ewpATiRQRSSCyAuAOD7ARFRGviLG9mkxM1qs2rgMDtPyRDRZwNYtJTZh5DoAmVN5m8R53HpFRsEUz2CIJ1D7jQAnw8K/IW9u1jSaGQUbh79k3Ubjp1GuAXz9Bv9dm2vExTEkHPrbqvKLllFxPSNQTmR0iWznPHyLLsIgu5oSzaRWFLJmQ8YAK7VSU+6WiPL9/s3c/TBLQO9Hb+ewVMvazHvPWNTHSs7yeRN5CCulxePHXT+r3XKFDRlqmX8UmXgQxSG3YHZFPUbrgGU01e88MNc55DYEYdzGp5wchMRHoPUxrSALA8RfGHh+TX7as1q/lb6D9dB9IedT+xxJpx/Z6W3UGzrNUWqpSr7FRlUBA6QE/QWf9Csqj/f1S0gTlcX3+Kj3fts5fO/lfS2C6ESI0Zi7YCucmUjMp3LFW5WeCVuuP3up/rbiQcjNrviGNuJYdKQ+34H3v53LbkvcQiegQTG47YNIN1jiHao/SNHQseAt4DRuvMoNkelzMKL4Zf1jm9soAWuX++zo9MW9cSQy24kLKJcx+Dnj2bsrt8Gq9TVdN6V/6GYXSZNRqpAgdJk1J966KR0+mibyijOrHuJPz6BgSVLcqI2AbN3PC+WEZMP0v/sWNuXLvMZgmUVtvk7eTmkkkAU+YWv0QLpvIaEJlBC7Y44tGdcufp//gNcb2tXrMRP143dLY+TgG09wZGU2s1iYWTrhMP27RgVTwGZXGSupFwohJ+n2XnmerzuSFNGvtf89EQhJ5qc2NhUKLjsGfB9yaqK+qukVWQGEDZYc/O/eFT1WkOio+jInXByuJLPqQhJYZV/2diDBfzKDrac5Mdw2d7SGGgsOhMfOh59HASMNANWnhXaXeNJXCXVwn5NInZNhirWbeobxMr77NVSNAq7W23cgo8aptxET/Rb1jozZmZtKY8x+At0HlR8/TRFtRrvN05s3uoi0HUX/NViM5Lb3vcbmCKV0E0A3Ik5mIaAP8wzLg8YA8z0fPUcjO3lbRbm1gvnqDanTO+AXw8XQKzbggIkRdj4V46nbWLwe++SSYjn71PxTTzLEqZ+/ONtou9ByiWp5U6LAjk1wGKcFcU22/aUvgvquoxIQLbm0ceRwZDhNmqLdZG8rDfmeErsxSFIBo9YyZD1Hek0k9nCOT0OfalKVy6WumZ5G01yO3kFRTECIRytOu+w44+af0WlCUAQAuuoPo/10swxyJ0DXD+cKgRUVGE+BfFovTvD66D6TjmZUb2wPObg4cfbL7vbVLKL/622eAa+8l42wbfFdBdCzdyEaK0JgBmnY85ETKcbx6n35vz3ZvQtye3BdaXpWJIFmeYyZS/JvBNwgzEdcuoSLO486nGyo1g8oG7BV74Q4dgnAVZALe4tUDqslkeRmthtMyvdqPdrgDoNAke1Mm3npEf9ecDG97zv9Zxiv30soaoEnNXOXauaWLDMJGZyOkyyvcHQZdf/4sqtvbupZWupxHNJGaQcSESII37MXg2qZ4tPgOKM3EoHxf3iLy7MySglho3t6dn92/TwlOV+h98THj8PPcN6ng9txbgTN/Sa9FK6isoafRpJ1Dc/t2+7sZvD2Vwt/p2cSorSj3Egw4x8fXGrdrycwBFn1A59UOqXfsrceamkGkCx7/lBmkYMPoruSu9u2i+8sMRTOYQCQEeZtBNXuAZotWlNN2mX189EkAhKpVC+iwYGLhh/7Xeg7Rx7lgM+Ww9hbE9oBnPRY7vApQaQn3QVtrsXJduc+q+iQ2QoTGDKDJBKBJ8UAxrS5Pv86/um3ZkW7cwp2kvNFjsLdNi43d+cSMs5GSTq1HGLwNptEDOowQidCFa4YRuM19QhLlmDr3I6ahXTvDYzBRUkQ3ed+RNFmaTQ559X/NP4kFmJ1LdUBcT2fmZw4Ua6q+2V8tJY1kiILA3sqwU2M37+x6JIUlAbrRGa270nft3zr72diNDUecQXmROTPdWpzX3gtc9sfaoTi/PVXTpk3POAhFe7zGmcErcjOkxKv2JR/r15q3o3AjL4qe+xMdM9PYFu+l8HX7nm724NEnkdEpLfHnoUqKiF131Djv60Eh3TtfpZY0vDhb9x0RlBKT9fhND6dZGyI1lJdSVM/lxbAXHIlQPnqRw9AweNvTlVbh1rVU49a6CyrDn/F44K6wekoaqXm06uwNS7bqrIylA9s3eM/FBEM84KI7KEf2yr20AFrysV9Rx3VNBnl6jRihMQPcnZ7bdPXXDe3ZQSu98lKlgRf1as25kNuWvAHTc1r6OTyxeL6xTD273fl0gxds9q96+yrjsm8XKamPOIMmxK4DvP2aBp9A4Rsb5/7aT/YANOHlsdspjNWpL4VZmAk25lzv51nuymzgOeuJ2GoQzdsSY639EaRfGNSs8+7J/t5jAIV3ew1zt9vgcJbL82qnekRtckgDAcC3n1GOxJZbqinYK+HCcu+b3qd2MbmJzBwKe5u6jzb27KASiv8Z4cNn7/bW3e3cQt6IGcIa/xNd1F1YQNdZy05+MYDSElKcSUzyXsdmIb+JJZ/QmFp1IgOZlkFlJ31HUljuD2cD/zRYi+b1IiLuHBGHCuPJWbnCcr/4j27HE4m4w50m7BQBQIuvnVuJmGGHFfuOdKuAuGB2k+gxyC8aPO5ib2rDJAMBdF9z7SHDLqquZQghThJCrBRC5AkhfEoQQogUIcQL6v25QojOxnsDhBBfCiG+E0J8K4SoRgv6+BEaM8C9ep56i39lxoli7qmUt8jNbjL1Eh+8gVbWJj3czHUBOlxna7BVlOsQmxmGesEQJN6xEXjuj1SovHen90Ze8J7XQDJ6D49NiWejwB4X/8bm7bySV2yEN39Pk0zb7sCXM/3U7o699ffSs1U3gr3e3+4CCzQzOBzMi4PLVGE5h6B4BWsqkgw5ETj+IiJOxAKLRbfvAZzza+97JsEhCPYky+d34Qf+z170O/p/ytW6q7KJlp1ogQIQKSIjW+VIhA45cTQhowlN/nZHAldH5X27KHzNWP2NDkN/+AwZtOVfuusdP55O4sVmmD2Ipj7jAaKOH9hPXl20gs7l0s/IwMmol3TzjlEjJYRbuJujFi6vOx6Y4fYx5/kXLexlxgozDxiroxd225VIxF1Y7sKWNXSvMFHLNmZJKZrQ1PVI77n99ZO0CNlihFn7jvLK39UyhBAJAB4CcDKAPgAuEEL0sT52JYBdUsruAO4D8Df13UQAzwC4VkrZF8BYAHUSIw2NGUCJ4Cc+Axarm7giSs+fUuy3snJ6vlRpNRbuA15YDCxXuYTiA/T+SnWh9xwFvLkWyFc3e3kS8OTnwBoV3mrVH/jdA8A6lkHqA4wdC3zwDj3PV+NZt4Uu5q27gafmAFkqF7BqLfD8AmDohcSE3FAAXHQV8MLDZNzW7aDv7yqim25NPj3fo4zStH8DI4cD+5RBW7mF3i9WRmz5ZuCMc4C3VP3S0o3AC4uAp/9Mx2rJBvo8z0dPPQN8VKAbCi5YBzxlTJpbkoA3lMJGSRHw57uBc86ngujUdGDO98CLygC27Q58vgp42VBj+WQF8Op8PUHf+yBwxRXE1DzpSmBdMrAmXXuhj04H3lLkkH27gbv/DrxrKKJ/vhF4z/Ba3lgEfKTGl54N/GMqsFGtni/5A3DPNBoD493vaYyMF+cC89bp589/Bbys1OrXLQWenQN8bShEnHgyHaPWXchLtq+9h98Fpqti69XfAsOGAEvWAZDA2bfStbJKXUvb84Grf6Wvvbb9aXtrdpCHWpGqnqvPr1yurq0dlJvdsZeeb1Ci2vmFdO43KW9p6256f6vKs331JT3PV+SJDQX0vINSctmktrdqBUUx1uQDt/wV2K6atr74HL0fdO3lqe2VqPlu6Ub1XL2/L4eurQp18S3+gd5n8LXHpRFfr6Hj/4rKg3+1GrjpDlok9BgMrNhH54+N/Kyv6dpjFZvPvqdrDwCSU4CHpgEzDUP2wXd0/QhBRvu9pcB8Q5nj/WXea++tb4C/3kdRhx+WAVdfDdx2GzD5Fnp/5kLgrrv14uidlcBaw4Cfdy4w+TjgdWW8XpwLPPp4XefQhgLIk1KukVKWApgOYJL1mUkAuGbkZQDjhBAC1Fx5iZTyGwCQUhZIKetEg6sum3M+JoTIF0I4u0QLIXop1/OAEOIW672YLm2tw2SEmTAFT00PQkQo5CACQhVvPUITL39n6Cm0rZzWxHyKRGgSB/wNJwEj9Ca0aCyEVwHjQDF5J6ZqOl/Q7Xu6Q22JybQi/eh5N9Ouk0G0sG+OslJgr+XluVb/LqxaQN9v01V3Iti/l2j1PywDegwhFmnTVuTxdh/kDV0ClKtYoZobmi073p1Gq/zUDGDseXSszTzmirm6HQwTXFznjc/V/n000exTE9JTd/rJBhlN/PlUu5Gknfew9Q4B4ItXgf/80vva2TdTOM9UPuH8m/m7OIfafTA8YUuuJYwkkhfFNP7jXeHOAEQiQHac9WkTb6AQF2tOjlaybRk57pDguqUUojNzPmmZdL7Hnh9MZGKPrEUHb5jOzuMxTIFtwOvdHCim8F7/Y8nTSkql/3yOzFCsSaIpj8EgFBHNjkxK0mIHQazD/XuBMiM64vHOhA6D7t7qJWatW0rjt1nU3BqqbtAOgCkeulG95vyMlLIcwB4AuQB6ApBCiFlCiIVCCEfNUu2gLvsHPAHgQQABzb6wE8AvAJxhvmi4tBNAB+1rIcTrUkpHy95aQue+wOdziK4rQTJVl40GJp4EvPY90LwN8H9DdWihWQ5w/Wk08R45lsRcLzPya5mpwK0X0qS4fjnQri0w5WdEx96xiSbXOXOp0LFgEyD3AB9/rHt9DRkGdGxDVPkvZgCtmwJP/50mgTkA2uXQ/vr1AxbPADrkAr+5jyjGWwFMnAz89CYq3h53MYBngK4taaIrLCAj0t0oED2iDf1lpgHbAfRuC1x4CTHVAKBfe/orUoytAR3or2V7YF8BcM6ZwGnqZmrWBhgMYHBnvf0uSUCXTjR5ZOcCw7tR3ou7aY/uRTqQn75MucKJ15Hh4gT+mF60EBg4jtQO7rqbygFWK+/rust0HvGUq4iA8h+jduoklW/5+UPAPZcDI9sAMEoSTh+o6/H27AAGWiH90a1ADdAVrptMBd+v/ZvKEM4dRoxPVsu/6ULg2n8Cf7mIJp6LRtDvZkN+icp3rFTep3nttGgHXHi0ziMlJQK3XkQGfN1S4K2H6Fp56R7yJoaPB4YeT40+ASAjGbjjKlqMcMnH764ALvsZcNdsYMR4IMdYmDXPAj78EHh6Cj1vmQ3cejF5Notn07Vnjq9dDvDcNDJG0QpaZEw6F7hPFUu3Tgdef4W85LxFdN3d/Sg9Xglg+EDgViXgO+Ujuu7OPgeY/Csas4gA/TpRuHrtt/raS1MGbOxQoPWftDzcT68CYJCYBnf2XnunHe8lTw3vZkiNPQeMMHKv+3YBo4yw78TrKaz7qFpMjJgIdOwFtFbPk9OA8X3pcfeBwHtPACf0o9QALxZPGkD1oZ+9QgbzVEWiGjSBCvqnKt1TFmOe/jKRefbuJAbksKZAhw46fTBZ1RWykTx3mB57zZEohDDrE6ZKKacezAbNbQMYBeBoAMUAPhRCLJBSxmDw1Ax15plJKT8FGayg9/OllF/DHz+Nx6WtfbTvSTeUySjMyiWB0hYdtCGbcCmtzJkFGKTpJqX2bpLTqCZqxybyZsb/hMJtTN2281rHTqbxdB+kE81NW7rbo/OKVUbhIUp07gfc/jwlphmTbvCTWkxWl1kvZnsWtDP6l5hMAscjjbwOg3twuVbl0QoqBh92GuklMrFlxVxKqhfuIENm/i7Grq1U7zRlhh4nS11xXds3HxNpJshjTM0gdqmLRcnn09SK5NZANjaupJXw4tnAObcAl97lbU1zFlPkjWujsMDde86GEDqfedIV5K2u+UaTOXhiHneRGvdqfaz6jCDJMVsiKVpBHny0nOqurjY6FgNez7Ntd/IK1hmlEib7DqB83fS/uifQOa9RF4ekFH0NVOXBs07oPZeTNFfPwUQ+AjTpiD3n958CNiynPCjgJb3YGDGJCFrmuQFoXCvmubs8m9iy2quGL+EVA89tSwu0m//nZfSuW+plWyanej081oE175GWnYikwkQX89px1pmpaz9W54n4US6lHGL82YZsEwBTAaC9es35GZUnawKgAOSQfCql3CGlLAbwNoBBqAM0xJxZPC5tJYQQVwsh5gsh5pfHCgPEg9IDwGPGxZugQjWmEbFvTJukwJBSr/ZT0vXF+dO/0URjtu9IVAbliKNpJbjsSyJvDJqgw4XN2rhrYzhRbIYVeXJLTqUJJ7etNtI2JdmcYE02lhlWZXYbb7e8lLwSNrRmyINvUFdx8gdPU9j05CtpUm2lmHMp6RSiMYkH5uTAxsdmoPFzDjvu2Eh5GrsDNOPdaeT5mW1ZGBMupf/m+U1N938OoHPE9P5olIysObbvFwKLZnvDSAD95qDtcQ1XJKJDy6Ul/o7ZvB8+zl+9QSzWn0yh4wqo0osR+vxsWaMN1vrl/nYz7z+p2se0oPOQkAj0N2oL1y71Xl/P/ZFYpSaJyDxfDL5eVi8mAwe4KfF9jgFe+Bst8Pg7H1sCzR176W3mb/A2KrVxlOrXtncXkaqi5bRfXpxEIlXLTAHAD8u9n1vxFeWwWWd0x0a6/1cv9tfumWHn9570djBISqH6VHMxkJRMmqmv3kdzh9kTj5Vk+h+rw7PsmcWj8HLw+BpADyFEFyFEMoDzAdg32esA1E2EyQBmSyklgFkA+gsh0pWRGwOgTqJsDdGYVQtSyqm8okhMPMioqV1/1Labl62Ynk0hyAP7KVTRvicZLFf/JRmlyWXKDFppMtWW4/EmK4wn16NPppUo3/AV5YYqfJnOpXUfqB+37kJeWFqWXv2ZtN5tP1D+gFvQ2Cr1ZusTnpyu+aeXfcjSRr2t2i5Wyzcnaf59QWEPc9JPSCQChIsGndNKlxmUllAOyFZGsI0Zw+V5dRlAQsCzn3NL/3CJhVlqkRLAtDTzL6/cq8ZijO39J/1FzoC3R52Jgs3aSzA/P/s5f87FVFBhZDWj0gPGe08oOTFjkcGLk+xcYhvaOP4iuq5251PkYJyRY1u3lASOT7N7mhnes6vGsZXS2dy1TV9PLmPWpb+e/G2PXFj3SySB8k2xmuLyPniheWC/upeieh9VUfMBSguYxmyT8t6btKQFCI955oNU1mLWV5rGzGaamtqSjKJCChWvmEvjM7/DufvMHODUq0nG7sTLSQXlEBgzlQO7AWSYlgN4UUr5nRDiLiEE66dNA5ArhMgDcDOA36rv7gJwL8ggLgawUErpULg+eDREYxaPS1s3MMNl/UYpkodxcxUXEmEBUOylKN0kLo+JV1PskQ1RjQwrV9bGdpl51X0grVL5My/9Q9P1f/hO31iDJmjJpu4DaaWY3YyM2ZQZQIcj9LZ5vPw/KMEOEKECoDDi4An6N7+plNpNEVtAq/ybCWqefGxCBMPV8oUnH3OCPrDfa3SiDq+bJ0hb1DcphY4jo0kLyrft3xssFMvyTR7vNMAzY6abibbdvZM9n16TKMLEBbu1kFlHmJblLcOwIwF8jDKa0F9KOoWp/3oxMM0o0J/1BIWieg0Dbp6mz5HpTU28Xo+lYBNdy5FE/+KC6yqHnOBdKJl2x+XpsDeXlUNElMv/5NUNZc3G3fnGNaA22nMIjYM9Sg61xUPNt8shJl4PXP9vrcUIUXXRtEuZXwi6Hx+4xl9SYnp7/Y+NLUhcUe4naBXt8S5cTMIQ90rjEOcFt1GtmWmQXQvCWoSU8m0pZU8pZTcp5Z/Ua7+XUr6uHpdIKc+RUnaXUg6VUq4xvvuMlLKvlLKflLLOCCAN0ZjF49LWDRKTdGhw6ee0WnLdPEJQQntzHv1tWuWV55l4PSXAp/4auOtsCkGw91A5YavtJqX4K/zNG40NU1KyloKa+aC7caALlZOMWtlmNnXXNgE6VMIeKsv2MOxJmGP/5uTOYc8dm/Tq3pzQXSviSgNvvLZxlVedxAVm6vEEy86uANBBGe1hp9G5ePNhawcWeJJPTNIF5WwAzoijzqxpC0soV+3LFCjOVaQTVjY54TKvVy8Ui/DSu3WvM3Oh0KyNzpEkJdOxzs7VCx5m0wH6Gmp/BG2TPTpTNuyDp3XI8YOnyduJlusxu/qDeeTcjOPpCvvxIq9ULWw69fEaaj5vH033GzNeLJaVercVT9G0rX6fke1dmIw8019nxoLNHXsH90XLytERB1t+zSz2rkphZFMehffN+8mOOnC9W2aOvjaZqQpQTvPTl+lx7+EUTWnkqEtq/vMAvgRwhBBioxDiSiHEtUKIa9X7rYUQG0Eu6f+pz2QHubR1NU4fOLEOkAvvunlERPfEat6OVtNNjAaUKelENzYp/7zy58mJL9ar/uE3mHwjRKM6p5WUokNgB4qBL60uwkGoNGZqH0V7glUweGVYtJsS5GY4qm13iv0zxl+ijaLZZbd9T/KYklJoYdBjMNHlR0xSpACHQeHfy4XAgP9zplYjIyWDDC4Xlld2DxaotGw7t9DEU2p4z3bSvM8xJM7L+73gdtKY7NwPuOMlKpYFtCfoCivvLwJef8h4Qe3fNMhcnM+hyZzW3v5dMkrGIitHXx9muHbXNk0uKSul3OrOLUbnhIgeW0IiXWuj1EKCF0zmQsY0fiZmP0//2TtnrF3q9ZZNL5tDYWyoAc3Qs4W0Gea9xcaFRY1Xfq32ZWmhmuHPIJQUeUPNCUnwGN42XcjADxhLffoAYKUi861fTu2E+Jo2y3OS04KNqYhob61VR93EVkT8hdgr59FvM3OX9nb5vr34Dt2lgF+772pqwMr51OVfBZ/LRoS6ZDNeIKVsI6VMklK2l1JOk1I+LKV8WL2/Vb2eLaVsqh4Xqvd8Lu0hA7OoAB1eAbwsx0gEaNaKJrcbHgR+o6oPOG/x0j+AvMVAgvI4klL0BMoswY69KGxnK84DtJoG6OZgD0xKb51Zddu08+9waQAyePw5rcmgmdj2A7VvZ3TsTaGN0Wd7yR4H9qsbS9Jf3iJSct9fRDlIF8ZdTHmasefp18yVam47qguykZxC7Ele7Q87lZQzOhyhQ3rfL9CeI8uW7djo3U6Ljt6V+9LPaCLmFjzcR+yo42hibNPV64kDNGGzR5uW5Zfp6thHkxgYK+d5SwgAnTurKqfDq/VuA/VEKIQmPyQkekN/yakUgrYNlAsHivQ2PGMzFmdn/MLrZfExNVvQVIX+o2kB2KI93XcjJvll1oae4h1Lmy5eKakLf+ffbnGhPj4JSRSeMz3KzaspNH3UcUS37zsKHqMpItq7G2MY54pyb+NWE2aea99uHaGQUV0naKJZa3gMrL144+/8sFzPGQveo/92Dg4AZvzL/1ojQ0MMM9YvhPAatKRUEh02i5OFoBonezVksvFWfEWU7eMuoJvJJHUApC3Ysbf7Qm/dmYpIU9N1Ert4b3wMLBtMxee8kitnxagwQqH2ZFpRpkM+gNK3i5AhMgs+zfF+84ke86IPgFZGvsVEwWYKcxUayWyzQNilnelCYhJwwqW0unf1pLtItZmxpbzs4/rq/VQsvXMr5V+4bcucmXQctqyh33zCZUTNB7zHq1Mfr9I/7+OYid4Fiav1CBumnFZ+mTUZ9eoLAvRbhfHd/fvII07LpN9pdzrn0DAjO5cYtiaylBfHjVLZs+AJ94TLyBCYWKPyreax5WstloGLVuh83MizdEhy0AQydLwo4X2vX+E1eFUJOXOzT/Mcs4L9rMcpVGd3N5BR5QXfSIsQxoAxdB/zOTeNWue+ukvG2qVeaj3Xq5m4+PfAFKPZK59PDi+zh/3Oo9TtAQD2WMxWE2z0GzFCY+bC2TcRfb5td/Kuln6uW5MPPZUmLleO4NhzvPmblh11nQyvqjhsVFhANUGmGCyjtIQ6WXfsTatWgHJddmuIeNC0JSWLY7HJGOwl5q93ewZMRkjLdLelAIxwiUUvBoK1/JhK/94T+rUEY/9mriAWlnxChegH9nsnr2ZtqBaoaUvKR117r1cZ3rWgAPx0a8aBYhLKfe8JXcdnHq/RZ/t/64YVFBY0jYkrNMSGqXk74OZH/R4eXz98nDes0I+PPI7UXdp01R6azSrNzqXeWcNOI0LG8Rd6++xl5ujroN9IkvPiUCgblKQUaj5rsn/P/CUZUZO4wONyNeQEyEMqLtSMvH9eoUtWohV0TDkawEbty5nEwOU87MOODst8jZ98la6RM5V2JOjcbltHnntQO5nlXwEv/gPeL6rtT5lBYtxHHE3H0yR0bF1D9+7PVdi5rNQbleBaTBPZucAtj+vFjnn9xNJRPfFy+m/nCRshQmPmQnYuhb0iEfJWmOUHeLv82hg0nla5A8cRhdYEhynTrJCBq7nnhhVkCJq21KGcjCbxta2w0bYbCfSyPJGHXNJLU/YBYPQ5xOLqPdwbw+cVKOch9u8L7hbAE9fxF/nV/ue/6/88oErA8RIAACAASURBVJPpZlK9qXFzuqS5XNj2A01Q897WNGqAJsLsXKK65y2kBYe5fVcODAjmi7Tq5KdEmxP29wsphGjjQLF7kdCmmzZadi9U9uR5McILCt7fsjk0cf70bxSmTUyi4951AIXY7FzMnh0UVTj+QvIgVy0gT6VNV/Im9+3yXpMfPkM9uwC9rbceoTCsKXnWdQBw5V+8ixCekNd86//NPBaAmIvvP6W9NIDIKIU79ETOZAkhaLFlhjxtjFcGzGTAJqeSsDNAYTuXjBxAXufgEygFkLeI8meMFdY53bCCcnvfL/QufEZMouPA53TWY94i6iAS1LI5Op/qKpR2deLudhRwzb3ufniNDKExqwr2CpsliPqNdrdkT0wipQ1bCXvEJFrNVSoIsHKHo5Mz32glRVoPrrxMr74yc7yh0OrANGbtj/DeIHt3kgxTRraePNt2196mWR9TFJBwrmo17oJJo2dkZFM4qU1XnX+oCnwshfAbUoAmpy9mkFdsd1c2cfmfyDgEJfu3b/S/Zk5QH09397kTEbcaRiy6OY+hMkyc7P9OWiZdE+VlZIwWfkC50Yoy/29Yv5xyuh8pkgfn6Mb/hEo8Rp9NnQYYm1dr2bB4tTgZTDoJCo/zbzAL9/m1y/9E3l7l7+Rzq46z6U3a4GtvudG9ISkZGHoy5dsikeDFWN+RtPg7djKVl5isYTvX+pmS1HrlXjqu/Y+la4kJGxxmtecQ17xRWkLhRO44YYepze2Zi6///BL47GX3b2lkCI1ZVbAnGs6LxasiUCUcxownjVmP6zY0Jfv0SnjMuTT51ARZRhlA1wHeejCT5dhN3TCb87Qag5mHCurBxRPJyvnx1QQBesVsorwM2LAyuFt3TAhvzoKLvTlxvmWNN+xjr/I79XEXtjI2rKA8qimWm9MaOM+hiW3WVYkIHXP793Y9UtcJ2ZPsmYogMnoyGS2+NhKSiK2Y05o8nPuvBl42ZKq+elPt0zoHfH4qvS31/qY8yl2Ou9gbCjXbtfQ5xjsRV3V+meIe1LOOv79zqz/q0KkPheO47ID/x3NNsQdl9/z6YRkt2A7sD45yVJaJxFFUbUKo+SCe8bmiMWXW4qt9Two7mmDG57m/Bs6/TRvNijKECI1Z1bBXtnzhrF1atbZbzO2q/w5bVjmhlZcRgeSSP1AoqbJwNOItjK4OkpJ1Y8t9u7yEEE9nAKEJEwxzBR3keTFrc9dWnXznerWgxpeuiWXfLjLgrq7QgTAOJov6jjjDaCpqUNhNj5gndhuRBBqzWWc2cDzl3QZP8IaS0zK8ngvTps28mBBenb7jLqQQbndD6Nj2fvjYJCQS2YNzlZEIGcDsZtpTNAk0/D07NBXUd232s8C/r3ceBg/MBVxVEzeXQwQtfHgs894ONi682KqcsF03jAXOadmkCGbyDj5Bv8bHnUPZHCZ1Xd8uGTSGELTQtfOsKen+ujVXaYzr92c08XporMSTmkH7mz+LnsdxSBoD6lI1/8eBoBv2yr8cXG0H52y6OMIJPKFVKE05vog5Z5VQzVWjifIyXf8z+3mt5wd4J7r1y0m0l5Hbjm7whESlFBEwBg6HpWXpli/9RtOElZbp/o5LAYTDdNVhaTHrLhLRoZ2taylUlJrhZf2Z9V8uXUGAvLc7XtQTVLM2wKSACb/0AIXvGGwsPXVmuXp8AB2PUWfRRMqyYra3z01dl35GbWGGGBPxuqVelZrEJPLy1nyjj6lNNrCNWTyyTuZYzAVcUN6JwZ91kZwAPUaz83MshRqASFY2sciG3f6FwcedjdLIMyn/eWA/SVcB2iPj45TdnHJ3gF8mLSXd27A3u7m3PQ1AHlZJsdeAmY16GS6WsRAU+l3yqdZsBIAHfhY7Z9hIEXpmVYEnCntSbdoiuG4qHnQ4gm5M12ovXU3Knawbm1tXmMXF1YUZfhPwsjJN9X672zDTl1lGKyifxDmGijKg11DqRJCQQPkvswO0icQk4MQrvBRxnuhsqapYGHISebKd++ni9DXfAM+rVjIc7hIR7bkB3tCrjWfuIuIIQHTxIBTt1hNb6y5+VZe23fWiJDOHJrkta0j1fdmXFMI9ZpJX8QPQub/0bK2FaaJDb32NsvfGjwF/TtZenB13QfBvsmF6HZN+7v+NNio7OgS4Dt2OJM+3XQ86PsNO9edHOZTLx8UOWV6qRH9Pu1aPJ2ii5/Gw4ZpwCdHt0zLJEI2/hDxsQBs+c/Fg576GGmFmIagI2va6ivb42bKu6ygWuYu9Uu5k7ft9oWsGhMasaggBnPebgwsputCkBRkyU5mCkaw8M9tomQSHmsK8aXoP17kI2oF+GKQtx8YwaEXP9UYFVunC2POC640iCcAxp3vFctn7dNViBSEljUKKbbtR3Q+DyR4cFhTCewztAnHG7nwijSx8n55/8JRfcd78DYxOfbwahr7PRsjLYmWM7z4ntt6Jl/nPLa/0uYWLyYoTEaBtV69nlpBInia/Nu8d7/bY8+EasvY9getiFNx2G+iXP5twKTDw+ODvMJimbxJKbEipc4nDT3cIK1ue0uY8VeSswIQqKf0LARuclzKvqWgFkVxS0rRaCu/37Ju9NW32YqzXcC9RqnAHfDj1GlJt4dB+83a6zZEJIcjTHXGG9/X3niD5OiA4f8wKNY0coTGLB5+/qhXPjxhaO9vcuQWY+W9g4/f+96SkfAqv5Blcc1MYo3iyKpi5ABEh5W0O6XGbDkArntuoKKc8T1CJgs0+ixcP3uANa7LRZb27eLDkE9UXbaflgRqsuavvoYnHzP8FtZx36V9WBNTKmce113D/Kn5znp5ES0soJ8j1TUHdiAFdrrBW0dtNj1hGSSGC46c9BtN+ysv0xGvXKKVnUY8+lu9avVg3unThxMvI6zH3XVxIx9kUEnDB02vPgfz1ZKC3b6AxP3AthaNNcMiQQ5rffkrHhPNeU1UB8/tP6lZFTQNqrjj/ZvYkKy+jVj32IiUSAb5+h0hYDNvDbNcduPVJys9lNCE2o00c6nAELSC4uDtW3u3Wp4DxllxXrGsDoH3bRJdGitCYxYNNhsFx1XrUBMy4chVfC0EyOjY99+hTiG12MAbVXPmvX04lBGffSM9Nr63HYCr6PPUaeszvbd9A3lyQZ8b5PlZEjxc7NnlbpDBZJGhicoGLcJd+5tXFZMx/l+qmUtN1/mPi9brRow8BItMumMcjb6G7EJcnJnuCGj05YP/QK3o2lraS//plNKle9y8K0yUkkQfCnqHdFqlwJxkE9rxXzadFQIde7hV+y44kIWWO4YsZdJyDiuAZvEiwQ9YMZvV1O1JT0oM+20SFEMvLaSFgSzqVlujoyTFWdwcGG3g+pgCCiwlB94cp/+aKEhTtoTBx0R4SW7DVVBjLVSmBKxLDmPOaVaQN7fkBOq1hdnZYv8Lf3LeRIjRm1UEkwQrL1Qaq4cEkp1Ad0MEQQEwwM44Vye3f1qQF1bNl5+pV+frlNJkEeTM84QV14I4XzNZrUcP8oOsYbV1HnsjeXdpbaNI8+HgGdUxwwTRmX8zwKmHY3zU7J0yZ4ZbeYoyeDPzsfp1LsluP8L4ryshIfvMRMSmDyEnbN1DYituhcDh43MVaxDgItmBuUJsfRov2RB83u16b4OOR204zeG2KemU/M/Wcf1feIv2ZzBw6hks+Vp8NuPbY0zb71FUVsTcVVFyaiB88TUo++QHhZxt2p3cTH0/XRp1hCh3zgpJD6Jk51Ez4nf/Ft+8fOUJjVh0MGEO5jtpADaNxtQL2SniFykKmtvTRrq0khLvgPU1E4HBM0ITBRq464cEgbFnj9rDigWlsB6kmn0wR35xHrL+zb9Zt6l0w5Zvs12ykZmjNPkB7XyZJwhQEBuIjt0QiFPLl3E2G0Qg1MZk8qi2rgUd+RbVlvE1uXll6wL89QOc2+ed8v8CtOmGifU+1f/Wl9IBQM0MI8tBtI2i+DxC5iI+xbSC5HQ2LRbuuOxHxhl+5yNsGe1nS9CjVGAK98ypQeX3GeSMHMXqDYHri/NsnXk/lOkzGClpYNjKExiwenH0zhdwWz/a3sa8x6tGaMbGEE9YtFDXdZorF6pkWFGbkep0gBlt1YYvAxgs2uqMnawICExkSVNfq/qNjK5VEEmjC5pwR4KdeM4TQOo2A7j3nMma8T1usNxaycqhhrGkYmrWm5ztUXml3PpWMXH2PXsXbXRnMdjH0Av37YgYw7baqxyGjxPCbMkMvgmoKvka+/UznxGzlFmbycUjTNXHvLdDKPECwUsmAMVTs3s0oCq8OmcpVwlEVY9OGLYlVFUzNRb5vs3Iob879zEI2I4DQmMWH/qOrRxGPB0ywqKqupi7AtU9fqZ5ogbkP40a3w2ZB1HyebM02HQeD6uQHM5XXkpjkZn6OOYd6lQWVCNho3o4S/EeOpQXNyDP9MmVBYIkuU/qK9TFtTyIedO5HZQ6mAclfT8QQXrEnJZPxbdtNhyPtliq8XzZ21ZGokpLCfFyse7DgMSQm63CaJ5/lgNl1wLUtILh/WpLqoG4uYCIJZDCCRKWbtNCNL+06s5rApdkZCx16kRcGeA3ma/+qfhuoHzlCY1ZfaNON6lrqQyCUDROvhjnkZOfMWneh0FJisg5BHnsOTYhBHg17c7Haxrtwzi1UIGoio4k2UPFg0HiqV+t6pJ7MzRxTJIFyK/GuxstKgUduARZ/RAsaVmCPhZR0oOfRtFiZMkMfhxYdDFJGEnDnK5T/PFi06UoT/JATvaGyylyTXWfG3qHyrI8+Kf598XGrzndigXO2XQeQoR91tpdRCwCDlVfNbYDKVRhy/E9ooXOFqiEcd5FW86hOGU0kQmxeV3lGSjrVSnLI2OUVVtczq+4iBtChzFVfu98PHTMAdagAIoR4DMBpAPKllD6ZCyGEAPAAgFMAFAO4TEq5UL1XAYClttdLKavR8e8wQXIKrYqDqN51ifQsMk4cfquc2627IimZ2Fl/Ol+/Fq2IfUNyeG+To+QgFvo66MVFe7wMx6qQnq2ZbFyoGtSqJh4U7qBV/rI5ZIDefJhW6bHabfQefnBF7dVBZg6pkiQle0OhgP79i2d7CRgcKuPi6q4DqNHofVfFt88pMw5uzCYqvecILTpsWjp9SP1XF2m/0bQw6HokGRKzeW1Qbq6qMRRscodMJ15HnhnvwyznYPQaRt5xVYvS9keQygsfdxe6D/TnDNd+C7ypetiZ72U01QaYc8KNHHUpZ/UEgAcBPBXw/skAeqi/YQD+q/4DwH4pZZyxoEOInkcfXI2Xifz11HivSXNSEzmUyFf1amyUuIA2KKR3w4Oa/nvchYbWoQM1Uc2PhYxqeGZLPqHGmjc8qENvB1NgzizPwgJqe1JSVLW4dE5rNwNz+wbKox2MaoyNfbuCpaI4fG3LJKWmk0FiQ7J2qW5HdKjBShYs5eUCE674NGY2BTLNqUG98eEzVHC8Ym6wsLELfD5d5JfZz1FLpMp+eg4XaNip3i70QeBwbqx0Bdf+eRBw/f78IcovVidy8SNHnYUZpZSfAtgZ4yOTADwlCV8BaCqEcPRGaEBo3ZkUF2oD69XNs6Ue495ckFsV1b9Jc6BjL/3ZWHkWNsyxKMjx4vbpRGiIF1yAnrdQh1KrklyKB0KgclKpKkz05cxgNt3BGNYguOoUAV0PaRNWigqJ9ciGJG8R5XHadPP2tjsU4FxtrLwxFzinBZBNeNFUUa4XXPE2cwUQk5tfsJkMLYfYzXIAxq58YNHsqrs7cE/E6uq5mvemybxNTSdvMm8xjSFEvebM2gEwizM2qtcAIFUIMV8I8ZUQ4gz/VzWEEFerz84vL6+iWv5gcfyFuq35waKmShm1gev+RaGnSUoNnpPf29Yd/LYrczW10B4nOcUtwFr1ICjsM2XGweUkpRXi8j12oKQImPeW+73qiPrGg8m3AFf93f0en1Ob3LN9PfDuNGCuUtrgHl3jLgoI89UhmLQRD6km6HpKTqXC+gFjdZ1ZVcXcJqpaYOzZrnNlLpLIx8+Tkk+8i9LWneMfG+C9Zmz9xh+WA8/8AXh7avW2+SNFQyWAdJJSDgFwIYD7hRCBsRkp5VQp5RAp5ZBEW+2gIWP46dTaPkivsC7RsgMl0Jm23X0Q5c8G1kLsnUNzHMo8pKjlhQGvirNyjILnanpXJg28Jp3CY6HfyGD2H+cabckpPj/s0VWXwFCbYKOzI0b5BRcRB2liAqqPmPE81mdt8O8PCp1nN0fM64pzk1X1FKtkkVZzcWZeM/bCLhqgKNNIUZ/GbBOADsbz9uo1SCn5/xoAHwMYaH/5sEdqOvXJcik6HGowgeBg64YA0qI76QpSgD/UqA0hZhPpTahubsBY3ZQyuQoq+8DxRONnmC12atsziwUW3W1q1Zkxvbwyr1SPEQIu6P5+YfBnWEkmaHjlZeQ9ffuZfq0m95TLmP9qGnDdA7o+0dWwla+LlCr2yZ4la2zGCya1pGV5O0x7th3SGYH67Wf2OoAbhBDTQcSPPVLKLUKIHADFUsoDQojmAEYCCIilhGhwEIK8zvoA17bVRj0QQHTxGx+hxylp1Km4KtULu99Z83YUBtu9za+rWJfgY2E3ce3cj5qlch0c56Sq21m5NsCebyzjw5+pan2SnEbNXIHqG4z0bHdoko8he0SuXPGES4kRyjnlqhCU4wxCdm4MBmkd5GAPY9QlNf95AGMBNBdCbARwJ4AkAJBSPgzgbRAtPw9Ezb9cfbU3gEeEEFGQ5/hXKeWyuhpniB8RBo0ndlfQCvZg0GMQ/dUEPNFVZQhrE+yd2hqZQngbdvYeTqUHTWqBKFNdMDmnV4zC+H6jSd2jKsHpEROpTnLV/Gp2JweF6WxNSBNM2nCJBCclEz0/Xlxwe/XGBpDnJWUMhnDomQF1aMyklDG7/kkpJQAfm0JKOQdAjGKMECECkNm07mpu5r5Fgq6/ekwX8FYLh3jC4bzR8q8oRxqE3sOB3zwDpNSSN1sdxBMWruozlTk/6DYr1cWB4tgeE4cIY7VvqQrtepAuY7wKMozCAuDen1JBuM3sbdqCwo9Hn+z+biNDQyWAhAhRfSz5BJhyJrApr/a3fTA6eJk55C3E0rqsbbRVjU6r8rgSk6i78qHM5zG415op+WWDQ3uB5SDKmH30HHDaNfS4JkYtZnF+LYTzpKzZdvi8bHZc07ltgd88pUPGjRyhMQvx4wHX7tmt62sDB0MqYWJN5BCmqDnfk1pNlfZDiebtqIv7cTGCOL2GEhEjyKPh88Ksv5R08jari1j999hrY9m3mmBzHtU/Vhf8u1wtlcrLqJdadfNwP1KExizEjxB1mBivSbSQmzrWVh+6eMBSR3an6YaG3sO9nZ9tCBFbtDoSofAdd54uO1B1nzUbU2ZQ37UgsJL/gUPoWTPYM3PV2W1cRb3U3vhvnQ9DCHGSEGKlECJPCPFbx/spQogX1PtzhRCdrfc7CiH2CSFusb9bWwiNWYgfEeowL3UwRe7rl9P/QxnK26AkohrDqt0M4Y05j1rl1Or2a2EbuW1rNq5YtYmcTzzYRrhVQAiRAOAhkARhHwAXCCH6WB+7EsAuKWV3APcBsFtu3wvgnbocZ2jMQvz4UBeyUSxYfDCFz3UxriDUppxXQ0dJkW5LM+YcosrXJljCrvNB8NKEqFk9WGV3aZ9Wu4E6JxcNBZAnpVwjpSwFMB0kR2hiEoAn1eOXAYxTYvJQKk5rAXxXl4M8jCQzQoSoApV5ojooRB9zDjHKUmpQK5aVW4tNXeMEF/MeKgX/+kZtFPwHgT3qGkmrKezYRH/nVDPKJkRwnVntrY0ShRDzjedTpZSmRpZLetCuR6j8jJSyXAixB0CuEKIEwG8ATABQZyFGIDRmAIBfTv8lSstLIYRAREQQEREkRBLoTyTox8ZrkUjE81l+HIlEkCASkJSQhMSERCQlJEFAIBKJVP6v3L7atvk9831727FeM78f73eEEBCH0luoawwaD+S2A7rWQWVHh166X1Z10XNw9TsM1xZqQyOzoUNEgIHH1+32zf81wSlX1V7DWhsH75iVK/nAusAUAPdJKffV9VwTGjMAMxfPRHFpMaSUiMooojKKimiF/pP0X/4IZWPiMaSJETLKHiMIUWkMgwyny5DyPkzDXtVjAVH5Xd9j1/eWTK/RfnyPjd9W08cCAsO3rUL7kn2YueDlg95evI+bbPwObQBsW78URemp1d6OCc/5Ns570GuV3zlUCyUh6jbS1rYbcNkfD64r/NBTam88jGZtqD9d3eu7BkoPOj6zUQiRCKAJgAKQBzdZCPF3AE0BRIUQJVLKB2t7kOLHNEFnZGTIoqK6YxxJKSsNnIRENBpFhaxANBr1GcHyaDnKKspQVlEGKWXl5+3Pmc/N/57Hxn7M/cX8juv9aPW/U/lbyssq9y0hK3+TlPRnjy/ov4SsHIt5TKrz2LeNg3h8KK7/E1NaYlRyLu7Yu7zO92XiuOTm+Kh0xyHdpwuxjGDU8hzZAJpGMebrENjbfDz2ywq02vlx4Oequ82afK42thmVUd81Gc+ioHlmc8y9fW6Vn3NBCFEspQyMzSvjtArAOJDR+hrAhVLK74zPXA+gv5TyWiHE+QDOklKea21nCoB9Usp7ajTQKhB6ZtWAEAKJCYlIrG318xD1BjbGNTWsPPnwYiDW40m1sI3qPr68ht/lSda1cHE+NhYGrteDXmMPm/fF3/f8t1+3ns8o2I3V6am4ss+Vzs/VZJvV/VxtbENCVnrH9jbt32EbuCZpNeiyHSdUDuwGALMAJAB4TEr5nRDiLgDzpZSvA5gG4GkhRB6oj+X5wVusG4SeWYgQIUI0YlTlmR0uCKn5IUKECBHisEdozEKECBEixGGP0JiFCBEiRIjDHqExCxEiRIgQhz3q1JgJIR4TQuQLIZYGvC+EEP9S4pRLhBCDjPcuFUJ8r/4urctxhggRIkSIwxt17Zk9AeCkGO+fDKCH+rsawH8BQAjRDNSZehhIF+xOIURNOiKGCBEiRIhGgDo1ZlLKT0E1B0GYBOApSfgKQFMhRBsAJwJ4X0q5U0q5C8D7iG0UQ4QIESJEI0Z9V/+6BCzbxXjdByHE1SCvDsnJyXUzyhAhQoQI0aBR38bsoKHUnacCgBAiKoTYX8NNJQIor7WB1R7CcVUP4biqh3Bc1UNDHRdQ87HF6I56+KC+jVmQgOUmAGOt1z+uamNSyhqHTYUQ8+tQObrGCMdVPYTjqh7CcVUPDXVcQMMe26FAfVPzXwdwiWI1DgewR0q5BaQBdoIQIkcRP05Qr4UIESJEiBA+1KlnJoR4HuRhNRdCbAQxFJMAQEr5MIC3AZwCIA9AMYDL1Xs7hRB3g9SZAeAuKWUsIkmIECFChGjEqFNjJqW8oIr3JYDrA957DMBjdTGuAEyt+iP1gnBc1UM4ruohHFf10FDHBTTssdU5flSq+SFChAgRonGivnNmIUKECBEixEEjNGYhQoQIEeKwR6M3ZkKIk4QQK5U+5G/rYf8+/UohRDMhxPtKl/J9lvKKpWVZy2PqIIT4SAixTAjxnRDilw1kXKlCiHlCiG/UuP6gXu8ihJir9v+CECJZvZ6inuep9zvXxbiM8SUIIRYJId5sYONaJ4T4VgixWAgxX71Wr+dS7aupEOJlIcQKIcRyIcQx9T0uIcQR6jjxX6EQ4sb6Hpfa103qul8qhHhe3Q8N4hprEKhsad4I/0AtwFcD6AogGcA3APoc4jEcC2AQgKXGa38H8Fv1+LcA/qYenwLgHQACwHAAc+toTG0ADFKPswCsAtCnAYxLAMhUj5MAzFX7exHA+er1hwH8TD2+DsDD6vH5AF6o43N5M4DnALypnjeUca0D0Nx6rV7PpdrXkwB+qh4nA2jaEMZljC8BwFYAnep7XCAFpLUA0oxr67KGco01hL96H0C9/njgGACzjOe3AbitHsbRGV5jthJAG/W4DYCV6vEjAC5wfa6OxzcTwISGNC4A6QAWgsSodwBItM8pqDbxGPU4UX1O1NF42gP4EMDxAN5Uk1u9j0vtYx38xqxezyWAJmpyFg1pXNZYTgDwRUMYF7TEXzN1zbwJ0rBtENdYQ/hr7GHGuDUgDzFaSSoeB2hl2Eo9PuTjVeGJgSAvqN7HpUJ5iwHkgwSoVwPYLaVkGR9z35XjUu/vAZBbF+MCcD+AWwFE1fPcBjIuAJAA3hNCLBCkZQrU/7nsAmA7gMdVaPZ/QoiMBjAuE+cDeF49rtdxSSk3AbgHwHoAW0DXzAI0nGus3tHYjVmDh6SlVb3UTwghMgG8AuBGKWVhQxiXlLJCSnkUyBMaCqDXoR6DDSHEaQDypZQL6nssARglpRwEarl0vRDiWPPNejqXiaDw+n+llAMBFIHCd/U9LgCAyj1NBPCS/V59jEvl6CaBFgFtAWQg7CTiQWM3ZkHakPWNbYJa4UD9z1evH7LxCiGSQIbsWSnlqw1lXAwp5W4AH4FCK02FECwAYO67clzq/SYACupgOCMBTBRCrAMwHRRqfKABjAtA5aoeUsp8ADNAi4D6PpcbAWyUUs5Vz18GGbf6HhfjZAALpZTb1PP6Htd4AGullNullGUAXgVddw3iGmsIaOzG7GsAPRQjKBkUVni9nscE0Bi4u/aloJwVv+7SsqxVCCEEgGkAlksp721A42ohhGiqHqeB8njLQUZtcsC4eLyTAcxWq+pahZTyNilleyllZ9A1NFtKeVF9jwsAhBAZQogsfgzKAy1FPZ9LKeVWABuEEEeol8YBWFbf4zJwAXSIkfdfn+NaD2C4ECJd3Z98vOr9GmswqO+kXX3/gdhIq0C5l9/Vw/6fB8XAy0Cr1StBse0PAXwP4AMAzdRnBYCH1Fi/BTCkjsY0ChRGWQJgsfo7pQGMawCARWpcSwH8Xr3eFcA8kMbnSwBS1Oup6nmeer/rITifY6HZjPU+LjWGb9Tfd3yN1/e5VPs6CsB8dT5f9sxmEgAAAHdJREFUA5DTQMaVAfJimhivNYRx/QHACnXtPw0gpSFcYw3lL5SzChEiRIgQhz0ae5gxRIgQIUL8CBAasxAhQoQIcdgjNGYhQoQIEeKwR2jMQoQIESLEYY/QmIUIESJEiMMeoTELESJEiBCHPUJjFiJEiBAhDnv8P70MHjPW/53vAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "real = true_casual_effect(test_loader)\n",
    "unadjust = (test_loader.dataset.response[test_loader.dataset.treatment == 1].mean() - test_loader.dataset.response[test_loader.dataset.treatment == 0].mean()).item()\n",
    "show_result(train_loss_hist, test_loss_hist, est_effect, real, unadjust, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
